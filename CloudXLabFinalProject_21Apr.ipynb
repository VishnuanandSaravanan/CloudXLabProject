{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79073937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import pandas_ta as ta\n",
    "from pathlib import Path\n",
    "#from tvDatafeed import TvDatafeed, Interval\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import boruta\n",
    "from boruta import BorutaPy\n",
    "import yfinance as yf\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pydot\n",
    "import graphviz\n",
    "# SOM & Sklearn library\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "# Import VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator \n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.losses import BinaryCrossentropy \n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy, AUC, Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization,GRU\n",
    "\n",
    "# kerastuner\n",
    "import keras_tuner as kt\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d309e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cba1d8c-21e3-4edf-b3cb-21395da0c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESF = yf.download(\"ES=F\",start='2023-05-01',end='2025-03-31', interval='1h',progress=False)\n",
    "#ESF.to_csv('D:/CloudxLab/ESF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56cc0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/CloudxLab/ESF.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e46cb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-01 04:00:00+00:00</th>\n",
       "      <td>4191.50</td>\n",
       "      <td>4191.75</td>\n",
       "      <td>4190.00</td>\n",
       "      <td>4191.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 05:00:00+00:00</th>\n",
       "      <td>4192.50</td>\n",
       "      <td>4194.75</td>\n",
       "      <td>4189.50</td>\n",
       "      <td>4191.50</td>\n",
       "      <td>4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 06:00:00+00:00</th>\n",
       "      <td>4194.75</td>\n",
       "      <td>4196.00</td>\n",
       "      <td>4188.50</td>\n",
       "      <td>4192.25</td>\n",
       "      <td>6294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 07:00:00+00:00</th>\n",
       "      <td>4191.25</td>\n",
       "      <td>4195.00</td>\n",
       "      <td>4189.75</td>\n",
       "      <td>4194.75</td>\n",
       "      <td>6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 08:00:00+00:00</th>\n",
       "      <td>4186.50</td>\n",
       "      <td>4191.25</td>\n",
       "      <td>4184.75</td>\n",
       "      <td>4191.00</td>\n",
       "      <td>7214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30 23:00:00+00:00</th>\n",
       "      <td>5593.00</td>\n",
       "      <td>5594.75</td>\n",
       "      <td>5581.75</td>\n",
       "      <td>5594.50</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 00:00:00+00:00</th>\n",
       "      <td>5580.50</td>\n",
       "      <td>5593.75</td>\n",
       "      <td>5574.25</td>\n",
       "      <td>5592.75</td>\n",
       "      <td>23879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 01:00:00+00:00</th>\n",
       "      <td>5585.00</td>\n",
       "      <td>5592.25</td>\n",
       "      <td>5580.50</td>\n",
       "      <td>5580.75</td>\n",
       "      <td>14562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 02:00:00+00:00</th>\n",
       "      <td>5582.50</td>\n",
       "      <td>5591.25</td>\n",
       "      <td>5579.00</td>\n",
       "      <td>5585.50</td>\n",
       "      <td>9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 03:00:00+00:00</th>\n",
       "      <td>5578.25</td>\n",
       "      <td>5583.75</td>\n",
       "      <td>5574.25</td>\n",
       "      <td>5582.75</td>\n",
       "      <td>7637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10933 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Close     High      Low     Open  Volume\n",
       "Datetime                                                             \n",
       "2023-05-01 04:00:00+00:00  4191.50  4191.75  4190.00  4191.25       0\n",
       "2023-05-01 05:00:00+00:00  4192.50  4194.75  4189.50  4191.50    4698\n",
       "2023-05-01 06:00:00+00:00  4194.75  4196.00  4188.50  4192.25    6294\n",
       "2023-05-01 07:00:00+00:00  4191.25  4195.00  4189.75  4194.75    6110\n",
       "2023-05-01 08:00:00+00:00  4186.50  4191.25  4184.75  4191.00    7214\n",
       "...                            ...      ...      ...      ...     ...\n",
       "2025-03-30 23:00:00+00:00  5593.00  5594.75  5581.75  5594.50   17130\n",
       "2025-03-31 00:00:00+00:00  5580.50  5593.75  5574.25  5592.75   23879\n",
       "2025-03-31 01:00:00+00:00  5585.00  5592.25  5580.50  5580.75   14562\n",
       "2025-03-31 02:00:00+00:00  5582.50  5591.25  5579.00  5585.50    9310\n",
       "2025-03-31 03:00:00+00:00  5578.25  5583.75  5574.25  5582.75    7637\n",
       "\n",
       "[10933 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e74878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>10933.0</td>\n",
       "      <td>5150.781967</td>\n",
       "      <td>627.354960</td>\n",
       "      <td>4068.75</td>\n",
       "      <td>4521.75</td>\n",
       "      <td>5205.50</td>\n",
       "      <td>5711.25</td>\n",
       "      <td>6165.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>10933.0</td>\n",
       "      <td>5155.834812</td>\n",
       "      <td>628.070349</td>\n",
       "      <td>4083.75</td>\n",
       "      <td>4525.25</td>\n",
       "      <td>5209.00</td>\n",
       "      <td>5716.75</td>\n",
       "      <td>6166.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>10933.0</td>\n",
       "      <td>5145.182452</td>\n",
       "      <td>626.601260</td>\n",
       "      <td>4062.25</td>\n",
       "      <td>4517.50</td>\n",
       "      <td>5199.75</td>\n",
       "      <td>5706.25</td>\n",
       "      <td>6155.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>10933.0</td>\n",
       "      <td>5150.715083</td>\n",
       "      <td>627.437186</td>\n",
       "      <td>4068.50</td>\n",
       "      <td>4521.50</td>\n",
       "      <td>5205.25</td>\n",
       "      <td>5712.00</td>\n",
       "      <td>6165.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>10933.0</td>\n",
       "      <td>63884.163542</td>\n",
       "      <td>94774.948605</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6068.00</td>\n",
       "      <td>15296.00</td>\n",
       "      <td>102596.00</td>\n",
       "      <td>2091064.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count          mean           std      min      25%       50%  \\\n",
       "Close   10933.0   5150.781967    627.354960  4068.75  4521.75   5205.50   \n",
       "High    10933.0   5155.834812    628.070349  4083.75  4525.25   5209.00   \n",
       "Low     10933.0   5145.182452    626.601260  4062.25  4517.50   5199.75   \n",
       "Open    10933.0   5150.715083    627.437186  4068.50  4521.50   5205.25   \n",
       "Volume  10933.0  63884.163542  94774.948605     0.00  6068.00  15296.00   \n",
       "\n",
       "              75%         max  \n",
       "Close     5711.25     6165.25  \n",
       "High      5716.75     6166.50  \n",
       "Low       5706.25     6155.50  \n",
       "Open      5712.00     6165.25  \n",
       "Volume  102596.00  2091064.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5317b6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Close     0\n",
       "High      0\n",
       "Low       0\n",
       "Open      0\n",
       "Volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d25143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index,utc= 'TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f747e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all factors\n",
    "df.ta.study(ta.AllStrategy)\n",
    "# AllStrategy = ta.AllStrategy\n",
    "# print(\"name =\", AllStrategy.name)\n",
    "# print(\"description =\", AllStrategy.description)\n",
    "# print(\"created =\", AllStrategy.created)\n",
    "# print(\"ta =\", AllStrategy.ta)\n",
    "# df.ta.strategy(AllStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0560a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>VTXM_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>VWMA_10</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>TSVr_18_10</th>\n",
       "      <th>WCP</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>ZIGZAGs_5.0%_10</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZIGZAGd_5.0%_10</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-28 17:00:00+00:00</th>\n",
       "      <td>5630.75</td>\n",
       "      <td>5633.00</td>\n",
       "      <td>5618.75</td>\n",
       "      <td>5632.00</td>\n",
       "      <td>174057.0</td>\n",
       "      <td>5661.333333</td>\n",
       "      <td>5680.177744</td>\n",
       "      <td>5642.488923</td>\n",
       "      <td>18.844410</td>\n",
       "      <td>5676.998297</td>\n",
       "      <td>5713.6375</td>\n",
       "      <td>5757.060797</td>\n",
       "      <td>3.030610e+07</td>\n",
       "      <td>-289516.717266</td>\n",
       "      <td>41.091296</td>\n",
       "      <td>...</td>\n",
       "      <td>1.405306</td>\n",
       "      <td>5672.262205</td>\n",
       "      <td>5661.292394</td>\n",
       "      <td>-24642615.50</td>\n",
       "      <td>-1.064921e+07</td>\n",
       "      <td>2.314032</td>\n",
       "      <td>5628.3125</td>\n",
       "      <td>-90.697674</td>\n",
       "      <td>5670.350000</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>-2.633574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 18:00:00+00:00</th>\n",
       "      <td>5628.75</td>\n",
       "      <td>5636.50</td>\n",
       "      <td>5619.75</td>\n",
       "      <td>5630.75</td>\n",
       "      <td>143085.0</td>\n",
       "      <td>5643.833333</td>\n",
       "      <td>5662.538116</td>\n",
       "      <td>5625.128550</td>\n",
       "      <td>18.704783</td>\n",
       "      <td>5669.975476</td>\n",
       "      <td>5708.0875</td>\n",
       "      <td>5752.725476</td>\n",
       "      <td>3.031678e+07</td>\n",
       "      <td>-242010.490013</td>\n",
       "      <td>42.999767</td>\n",
       "      <td>...</td>\n",
       "      <td>1.375986</td>\n",
       "      <td>5667.881518</td>\n",
       "      <td>5656.732734</td>\n",
       "      <td>-24970470.50</td>\n",
       "      <td>-1.296109e+07</td>\n",
       "      <td>1.926573</td>\n",
       "      <td>5628.4375</td>\n",
       "      <td>-92.248062</td>\n",
       "      <td>5659.177273</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>-2.345638</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 19:00:00+00:00</th>\n",
       "      <td>5624.50</td>\n",
       "      <td>5634.25</td>\n",
       "      <td>5617.25</td>\n",
       "      <td>5628.75</td>\n",
       "      <td>295029.0</td>\n",
       "      <td>5634.483333</td>\n",
       "      <td>5653.074464</td>\n",
       "      <td>5615.892202</td>\n",
       "      <td>18.591131</td>\n",
       "      <td>5663.452339</td>\n",
       "      <td>5702.5125</td>\n",
       "      <td>5748.202339</td>\n",
       "      <td>3.027339e+07</td>\n",
       "      <td>-214380.003569</td>\n",
       "      <td>44.818261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.375211</td>\n",
       "      <td>5660.624908</td>\n",
       "      <td>5650.222595</td>\n",
       "      <td>-26203976.75</td>\n",
       "      <td>-1.488171e+07</td>\n",
       "      <td>1.760817</td>\n",
       "      <td>5625.1250</td>\n",
       "      <td>-94.444444</td>\n",
       "      <td>5648.995455</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>-2.169653</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 20:00:00+00:00</th>\n",
       "      <td>5602.50</td>\n",
       "      <td>5625.25</td>\n",
       "      <td>5602.25</td>\n",
       "      <td>5624.50</td>\n",
       "      <td>85426.0</td>\n",
       "      <td>5626.100000</td>\n",
       "      <td>5644.985055</td>\n",
       "      <td>5607.214945</td>\n",
       "      <td>18.885055</td>\n",
       "      <td>5656.280342</td>\n",
       "      <td>5695.5875</td>\n",
       "      <td>5743.280342</td>\n",
       "      <td>3.018982e+07</td>\n",
       "      <td>-210177.640213</td>\n",
       "      <td>46.766461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.406639</td>\n",
       "      <td>5658.242543</td>\n",
       "      <td>5647.042187</td>\n",
       "      <td>-28105848.75</td>\n",
       "      <td>-1.746749e+07</td>\n",
       "      <td>1.609038</td>\n",
       "      <td>5608.1250</td>\n",
       "      <td>-99.818182</td>\n",
       "      <td>5636.631818</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>-2.342159</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30 22:00:00+00:00</th>\n",
       "      <td>5594.25</td>\n",
       "      <td>5600.00</td>\n",
       "      <td>5580.25</td>\n",
       "      <td>5590.00</td>\n",
       "      <td>22300.0</td>\n",
       "      <td>5616.533333</td>\n",
       "      <td>5635.642718</td>\n",
       "      <td>5597.423948</td>\n",
       "      <td>19.109385</td>\n",
       "      <td>5647.083490</td>\n",
       "      <td>5688.4000</td>\n",
       "      <td>5737.458490</td>\n",
       "      <td>3.019914e+07</td>\n",
       "      <td>-186387.509316</td>\n",
       "      <td>48.882431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432119</td>\n",
       "      <td>5591.500000</td>\n",
       "      <td>5645.744790</td>\n",
       "      <td>-28299001.50</td>\n",
       "      <td>-2.028136e+07</td>\n",
       "      <td>1.395321</td>\n",
       "      <td>5592.1875</td>\n",
       "      <td>-91.222571</td>\n",
       "      <td>5625.177273</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>-2.249456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Close     High      Low     Open    Volume  \\\n",
       "Datetime                                                                  \n",
       "2025-03-28 17:00:00+00:00  5630.75  5633.00  5618.75  5632.00  174057.0   \n",
       "2025-03-28 18:00:00+00:00  5628.75  5636.50  5619.75  5630.75  143085.0   \n",
       "2025-03-28 19:00:00+00:00  5624.50  5634.25  5617.25  5628.75  295029.0   \n",
       "2025-03-28 20:00:00+00:00  5602.50  5625.25  5602.25  5624.50   85426.0   \n",
       "2025-03-30 22:00:00+00:00  5594.25  5600.00  5580.25  5590.00   22300.0   \n",
       "\n",
       "                           ABER_ZG_5_15  ABER_SG_5_15  ABER_XG_5_15  \\\n",
       "Datetime                                                              \n",
       "2025-03-28 17:00:00+00:00   5661.333333   5680.177744   5642.488923   \n",
       "2025-03-28 18:00:00+00:00   5643.833333   5662.538116   5625.128550   \n",
       "2025-03-28 19:00:00+00:00   5634.483333   5653.074464   5615.892202   \n",
       "2025-03-28 20:00:00+00:00   5626.100000   5644.985055   5607.214945   \n",
       "2025-03-30 22:00:00+00:00   5616.533333   5635.642718   5597.423948   \n",
       "\n",
       "                           ABER_ATR_5_15     ACCBL_20   ACCBM_20     ACCBU_20  \\\n",
       "Datetime                                                                        \n",
       "2025-03-28 17:00:00+00:00      18.844410  5676.998297  5713.6375  5757.060797   \n",
       "2025-03-28 18:00:00+00:00      18.704783  5669.975476  5708.0875  5752.725476   \n",
       "2025-03-28 19:00:00+00:00      18.591131  5663.452339  5702.5125  5748.202339   \n",
       "2025-03-28 20:00:00+00:00      18.885055  5656.280342  5695.5875  5743.280342   \n",
       "2025-03-30 22:00:00+00:00      19.109385  5647.083490  5688.4000  5737.458490   \n",
       "\n",
       "                                     AD     ADOSC_3_10     ADX_14  ...  \\\n",
       "Datetime                                                           ...   \n",
       "2025-03-28 17:00:00+00:00  3.030610e+07 -289516.717266  41.091296  ...   \n",
       "2025-03-28 18:00:00+00:00  3.031678e+07 -242010.490013  42.999767  ...   \n",
       "2025-03-28 19:00:00+00:00  3.027339e+07 -214380.003569  44.818261  ...   \n",
       "2025-03-28 20:00:00+00:00  3.018982e+07 -210177.640213  46.766461  ...   \n",
       "2025-03-30 22:00:00+00:00  3.019914e+07 -186387.509316  48.882431  ...   \n",
       "\n",
       "                            VTXM_14       VWAP_D      VWMA_10    TSV_18_10  \\\n",
       "Datetime                                                                     \n",
       "2025-03-28 17:00:00+00:00  1.405306  5672.262205  5661.292394 -24642615.50   \n",
       "2025-03-28 18:00:00+00:00  1.375986  5667.881518  5656.732734 -24970470.50   \n",
       "2025-03-28 19:00:00+00:00  1.375211  5660.624908  5650.222595 -26203976.75   \n",
       "2025-03-28 20:00:00+00:00  1.406639  5658.242543  5647.042187 -28105848.75   \n",
       "2025-03-30 22:00:00+00:00  1.432119  5591.500000  5645.744790 -28299001.50   \n",
       "\n",
       "                             TSVs_18_10  TSVr_18_10        WCP   WILLR_14  \\\n",
       "Datetime                                                                    \n",
       "2025-03-28 17:00:00+00:00 -1.064921e+07    2.314032  5628.3125 -90.697674   \n",
       "2025-03-28 18:00:00+00:00 -1.296109e+07    1.926573  5628.4375 -92.248062   \n",
       "2025-03-28 19:00:00+00:00 -1.488171e+07    1.760817  5625.1250 -94.444444   \n",
       "2025-03-28 20:00:00+00:00 -1.746749e+07    1.609038  5608.1250 -99.818182   \n",
       "2025-03-30 22:00:00+00:00 -2.028136e+07    1.395321  5592.1875 -91.222571   \n",
       "\n",
       "                                WMA_10  ZIGZAGs_5.0%_10  ZIGZAGv_5.0%_10  \\\n",
       "Datetime                                                                   \n",
       "2025-03-28 17:00:00+00:00  5670.350000      5630.046629      5630.046629   \n",
       "2025-03-28 18:00:00+00:00  5659.177273      5624.947242      5624.947242   \n",
       "2025-03-28 19:00:00+00:00  5648.995455      5620.911379      5620.911379   \n",
       "2025-03-28 20:00:00+00:00  5636.631818      5612.200220      5612.200220   \n",
       "2025-03-30 22:00:00+00:00  5625.177273      5602.300180      5602.300180   \n",
       "\n",
       "                           ZIGZAGd_5.0%_10    ZL_EMA_10     ZS_30  predict  \n",
       "Datetime                                                                    \n",
       "2025-03-28 17:00:00+00:00      5630.046629  5630.046629 -2.633574      1.0  \n",
       "2025-03-28 18:00:00+00:00      5624.947242  5624.947242 -2.345638      1.0  \n",
       "2025-03-28 19:00:00+00:00      5620.911379  5620.911379 -2.169653      1.0  \n",
       "2025-03-28 20:00:00+00:00      5612.200220  5612.200220 -2.342159      1.0  \n",
       "2025-03-30 22:00:00+00:00      5602.300180  5602.300180 -2.249456      1.0  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy dataframe\n",
    "data = df.copy()\n",
    "\n",
    "# define target (label)\n",
    "data['predict'] = np.where(data['Close'].pct_change(-5) > 0, 1, 0)\n",
    "\n",
    "# drop unwanted columns\n",
    "data.drop(['HILOl_13_21', 'HILOs_13_21', 'PSARl_0.02_0.2', 'PSARs_0.02_0.2', 'PSARaf_0.02_0.2', 'QQEl_14_5_4.236', 'QQEs_14_5_4.236', 'SUPERTl_7_3.0', 'SUPERTs_7_3.0','VIDYA_14'], axis=1, inplace=True)\n",
    "data = data[200:]\n",
    "\n",
    "# backfill columns to address missing values\n",
    "data = data.bfill(axis=1)\n",
    "data = data[:-5] # to take care of 5day ahead prediction\n",
    "\n",
    "# check last 5 rows\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259099b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Close                           0\n",
       "High                            0\n",
       "Low                             0\n",
       "Open                            0\n",
       "Volume                          0\n",
       "ABER_ZG_5_15                    0\n",
       "ABER_SG_5_15                    0\n",
       "ABER_XG_5_15                    0\n",
       "ABER_ATR_5_15                   0\n",
       "ACCBL_20                        0\n",
       "ACCBM_20                        0\n",
       "ACCBU_20                        0\n",
       "AD                              0\n",
       "ADOSC_3_10                      0\n",
       "ADX_14                          0\n",
       "ADXR_14_2                       0\n",
       "DMP_14                          0\n",
       "DMN_14                          0\n",
       "AGj_13_8_5                      0\n",
       "AGt_13_8_5                      0\n",
       "AGl_13_8_5                      0\n",
       "ALMA_9_6.0_0.85                 0\n",
       "ALPHAT_14_1_50                  0\n",
       "ALPHATl_14_1_50_2               0\n",
       "AMATe_LR_8_21_2                 0\n",
       "AMATe_SR_8_21_2                 0\n",
       "AO_5_34                         0\n",
       "OBV                             0\n",
       "OBV_min_2                       0\n",
       "OBV_max_2                       0\n",
       "OBVe_4                          0\n",
       "OBVe_12                         0\n",
       "AOBV_LR_2                       0\n",
       "AOBV_SR_2                       0\n",
       "APO_12_26                       0\n",
       "AROOND_14                       0\n",
       "AROONU_14                       0\n",
       "AROONOSC_14                     0\n",
       "ATRr_14                         0\n",
       "ATRTSe_14_20_3.0                0\n",
       "BBL_5_2.0                       0\n",
       "BBM_5_2.0                       0\n",
       "BBU_5_2.0                       0\n",
       "BBB_5_2.0                       0\n",
       "BBP_5_2.0                       0\n",
       "BIAS_SMA_26                     0\n",
       "BOP                             0\n",
       "AR_26                           0\n",
       "BR_26                           0\n",
       "CCI_14_0.015                    0\n",
       "CDL_2CROWS                      0\n",
       "CDL_3BLACKCROWS                 0\n",
       "CDL_3INSIDE                     0\n",
       "CDL_3LINESTRIKE                 0\n",
       "CDL_3OUTSIDE                    0\n",
       "CDL_3STARSINSOUTH               0\n",
       "CDL_3WHITESOLDIERS              0\n",
       "CDL_ABANDONEDBABY               0\n",
       "CDL_ADVANCEBLOCK                0\n",
       "CDL_BELTHOLD                    0\n",
       "CDL_BREAKAWAY                   0\n",
       "CDL_CLOSINGMARUBOZU             0\n",
       "CDL_CONCEALBABYSWALL            0\n",
       "CDL_COUNTERATTACK               0\n",
       "CDL_DARKCLOUDCOVER              0\n",
       "CDL_DOJI_10_0.1                 0\n",
       "CDL_DOJISTAR                    0\n",
       "CDL_DRAGONFLYDOJI               0\n",
       "CDL_ENGULFING                   0\n",
       "CDL_EVENINGDOJISTAR             0\n",
       "CDL_EVENINGSTAR                 0\n",
       "CDL_GAPSIDESIDEWHITE            0\n",
       "CDL_GRAVESTONEDOJI              0\n",
       "CDL_HAMMER                      0\n",
       "CDL_HANGINGMAN                  0\n",
       "CDL_HARAMI                      0\n",
       "CDL_HARAMICROSS                 0\n",
       "CDL_HIGHWAVE                    0\n",
       "CDL_HIKKAKE                     0\n",
       "CDL_HIKKAKEMOD                  0\n",
       "CDL_HOMINGPIGEON                0\n",
       "CDL_IDENTICAL3CROWS             0\n",
       "CDL_INNECK                      0\n",
       "CDL_INSIDE                      0\n",
       "CDL_INVERTEDHAMMER              0\n",
       "CDL_KICKING                     0\n",
       "CDL_KICKINGBYLENGTH             0\n",
       "CDL_LADDERBOTTOM                0\n",
       "CDL_LONGLEGGEDDOJI              0\n",
       "CDL_LONGLINE                    0\n",
       "CDL_MARUBOZU                    0\n",
       "CDL_MATCHINGLOW                 0\n",
       "CDL_MATHOLD                     0\n",
       "CDL_MORNINGDOJISTAR             0\n",
       "CDL_MORNINGSTAR                 0\n",
       "CDL_ONNECK                      0\n",
       "CDL_PIERCING                    0\n",
       "CDL_RICKSHAWMAN                 0\n",
       "CDL_RISEFALL3METHODS            0\n",
       "CDL_SEPARATINGLINES             0\n",
       "CDL_SHOOTINGSTAR                0\n",
       "CDL_SHORTLINE                   0\n",
       "CDL_SPINNINGTOP                 0\n",
       "CDL_STALLEDPATTERN              0\n",
       "CDL_STICKSANDWICH               0\n",
       "CDL_TAKURI                      0\n",
       "CDL_TASUKIGAP                   0\n",
       "CDL_THRUSTING                   0\n",
       "CDL_TRISTAR                     0\n",
       "CDL_UNIQUE3RIVER                0\n",
       "CDL_UPSIDEGAP2CROWS             0\n",
       "CDL_XSIDEGAP3METHODS            0\n",
       "open_Z_30_1                     0\n",
       "high_Z_30_1                     0\n",
       "low_Z_30_1                      0\n",
       "close_Z_30_1                    0\n",
       "CFO_9                           0\n",
       "CG_10                           0\n",
       "CHDLREXTl_22_22_14_2.0          0\n",
       "CHDLREXTs_22_22_14_2.0          0\n",
       "CHDLREXTd_22_22_14_2.0          0\n",
       "CHOP_14_1_100.0                 0\n",
       "CKSPl_10_3_20                   0\n",
       "CKSPs_10_3_20                   0\n",
       "CMF_20                          0\n",
       "CMO_14                          0\n",
       "COPC_11_14_10                   0\n",
       "CRSI_3_2_100                    0\n",
       "CTI_12                          0\n",
       "CUBE_3.0_-1                     0\n",
       "CUBEs_3.0_-1                    0\n",
       "LDECAY_1                        0\n",
       "DEC_1                           0\n",
       "DEMA_10                         0\n",
       "DCL_20_20                       0\n",
       "DCM_20_20                       0\n",
       "DCU_20_20                       0\n",
       "DPO_20                          0\n",
       "EBSW_40_10                      0\n",
       "EFI_13                          0\n",
       "EMA_10                          0\n",
       "ENTP_10                         0\n",
       "EOM_14_100000000                0\n",
       "ER_10                           0\n",
       "BULLP_13                        0\n",
       "BEARP_13                        0\n",
       "EXHC_DNa                        0\n",
       "EXHC_UPa                        0\n",
       "FISHERT_9_1                     0\n",
       "FISHERTs_9_1                    0\n",
       "FWMA_10                         0\n",
       "HA_open                         0\n",
       "HA_high                         0\n",
       "HA_low                          0\n",
       "HA_close                        0\n",
       "HILO_13_21                      0\n",
       "HL2                             0\n",
       "HLC3                            0\n",
       "HMA_10                          0\n",
       "HT_TL                           0\n",
       "HWM_1                           0\n",
       "HWU_1                           0\n",
       "HWL_1                           0\n",
       "HWMA_0.2_0.1_0.1                0\n",
       "ISA_9                           0\n",
       "ISB_26                          0\n",
       "ITS_9                           0\n",
       "IKS_26                          0\n",
       "ICS_26                          0\n",
       "INVFISHER_1.0                   0\n",
       "INVFISHERs_1.0                  0\n",
       "INC_1                           0\n",
       "INERTIA_20_14                   0\n",
       "JMA_7_0.0                       0\n",
       "KAMA_10_2_30                    0\n",
       "KCLe_20_2                       0\n",
       "KCBe_20_2                       0\n",
       "KCUe_20_2                       0\n",
       "K_9_3                           0\n",
       "D_9_3                           0\n",
       "J_9_3                           0\n",
       "KST_10_15_20_30_10_10_10_15     0\n",
       "KSTs_9                          0\n",
       "KURT_30                         0\n",
       "KVO_34_55_13                    0\n",
       "KVOs_34_55_13                   0\n",
       "LINREG_14                       0\n",
       "LOGRET_1                        0\n",
       "MACD_12_26_9                    0\n",
       "MACDh_12_26_9                   0\n",
       "MACDs_12_26_9                   0\n",
       "MAD_30                          0\n",
       "MAMA_0.5_0.05                   0\n",
       "FAMA_0.5_0.05                   0\n",
       "MASSI_9_25                      0\n",
       "MCGD_10                         0\n",
       "MEDIAN_30                       0\n",
       "MFI_14                          0\n",
       "MIDPOINT_2                      0\n",
       "MIDPRICE_2                      0\n",
       "MOM_10                          0\n",
       "NATR_14                         0\n",
       "NVI_1                           0\n",
       "OHLC4                           0\n",
       "PDIST                           0\n",
       "PCTRET_1                        0\n",
       "PGO_14                          0\n",
       "PIVOTS_TRAD_D_P                 0\n",
       "PIVOTS_TRAD_D_S1                0\n",
       "PIVOTS_TRAD_D_S2                0\n",
       "PIVOTS_TRAD_D_S3                0\n",
       "PIVOTS_TRAD_D_S4                0\n",
       "PIVOTS_TRAD_D_R1                0\n",
       "PIVOTS_TRAD_D_R2                0\n",
       "PIVOTS_TRAD_D_R3                0\n",
       "PIVOTS_TRAD_D_R4                0\n",
       "PPO_12_26_9                     0\n",
       "PPOh_12_26_9                    0\n",
       "PPOs_12_26_9                    0\n",
       "PSARr_0.02_0.2                  0\n",
       "PSL_12                          0\n",
       "PVI                             0\n",
       "PVIe_255                        0\n",
       "PVO_12_26_9                     0\n",
       "PVOh_12_26_9                    0\n",
       "PVOs_12_26_9                    0\n",
       "PVOL                            0\n",
       "PVR                             0\n",
       "PVT                             0\n",
       "PWMA_10                         0\n",
       "QQE_14_5_4.236                  0\n",
       "QQE_14_5_4.236_RSIMA            0\n",
       "QS_10                           0\n",
       "QTL_30_0.5                      0\n",
       "REFLEX_20_20_0.04               0\n",
       "REMAP_0.0_100.0_-1.0_1.0        0\n",
       "RMA_10                          0\n",
       "ROC_10                          0\n",
       "RSI_14                          0\n",
       "RSX_14                          0\n",
       "RVGI_14_4                       0\n",
       "RVGIs_14_4                      0\n",
       "RVI_14                          0\n",
       "RWIh_14                         0\n",
       "RWIl_14                         0\n",
       "SINWMA_14                       0\n",
       "SKEW_30                         0\n",
       "SLOPE_1                         0\n",
       "SMA_10                          0\n",
       "SMChv_14_50_20_5                0\n",
       "SMCbf_14_50_20_5                0\n",
       "SMCbi_14_50_20_5                0\n",
       "SMCbp_14_50_20_5                0\n",
       "SMCtf_14_50_20_5                0\n",
       "SMCti_14_50_20_5                0\n",
       "SMCtp_14_50_20_5                0\n",
       "SMI_5_20_5_1.0                  0\n",
       "SMIs_5_20_5_1.0                 0\n",
       "SMIo_5_20_5_1.0                 0\n",
       "SMMA_7                          0\n",
       "SQZ_20_2.0_20_1.5               0\n",
       "SQZ_ON                          0\n",
       "SQZ_OFF                         0\n",
       "SQZ_NO                          0\n",
       "SQZPRO_20_2.0_20_2.0_1.5_1.0    0\n",
       "SQZPRO_ON_WIDE                  0\n",
       "SQZPRO_ON_NORMAL                0\n",
       "SQZPRO_ON_NARROW                0\n",
       "SQZPRO_OFF                      0\n",
       "SQZPRO_NO                       0\n",
       "SSF_20                          0\n",
       "SSF3_20                         0\n",
       "STC_10_12_26_0.5                0\n",
       "STCmacd_10_12_26_0.5            0\n",
       "STCstoch_10_12_26_0.5           0\n",
       "STDEV_30                        0\n",
       "STOCHk_14_3_3                   0\n",
       "STOCHd_14_3_3                   0\n",
       "STOCHh_14_3_3                   0\n",
       "STOCHFk_14_3                    0\n",
       "STOCHFd_14_3                    0\n",
       "STOCHRSIk_14_14_3_3             0\n",
       "STOCHRSId_14_14_3_3             0\n",
       "SUPERT_7_3.0                    0\n",
       "SUPERTd_7_3.0                   0\n",
       "SWMA_10                         0\n",
       "T3_10_0.7                       0\n",
       "TEMA_10                         0\n",
       "THERMO_20_2_0.5                 0\n",
       "THERMOma_20_2_0.5               0\n",
       "THERMOl_20_2_0.5                0\n",
       "THERMOs_20_2_0.5                0\n",
       "TMO_14_5_3                      0\n",
       "TMOs_14_5_3                     0\n",
       "TMOM_14_5_3                     0\n",
       "TMOMs_14_5_3                    0\n",
       "TOS_STDEVALL_LR                 0\n",
       "TOS_STDEVALL_L_1                0\n",
       "TOS_STDEVALL_U_1                0\n",
       "TOS_STDEVALL_L_2                0\n",
       "TOS_STDEVALL_U_2                0\n",
       "TOS_STDEVALL_L_3                0\n",
       "TOS_STDEVALL_U_3                0\n",
       "TRENDFLEX_20_20_0.04            0\n",
       "TRIMA_10                        0\n",
       "TRIX_30_9                       0\n",
       "TRIXs_30_9                      0\n",
       "TRUERANGE_1                     0\n",
       "TSI_13_25_13                    0\n",
       "TSIs_13_25_13                   0\n",
       "UI_14                           0\n",
       "UO_7_14_28                      0\n",
       "VAR_30                          0\n",
       "VHF_28                          0\n",
       "VHM_610                         0\n",
       "VTXP_14                         0\n",
       "VTXM_14                         0\n",
       "VWAP_D                          0\n",
       "VWMA_10                         0\n",
       "TSV_18_10                       0\n",
       "TSVs_18_10                      0\n",
       "TSVr_18_10                      0\n",
       "WCP                             0\n",
       "WILLR_14                        0\n",
       "WMA_10                          0\n",
       "ZIGZAGs_5.0%_10                 0\n",
       "ZIGZAGv_5.0%_10                 0\n",
       "ZIGZAGd_5.0%_10                 0\n",
       "ZL_EMA_10                       0\n",
       "ZS_30                           0\n",
       "predict                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9997abd4-cfa7-4284-844a-2147bc93f313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Close                           5.169401e+03\n",
       "High                            5.174461e+03\n",
       "Low                             5.163787e+03\n",
       "Open                            5.169329e+03\n",
       "Volume                          6.388173e+04\n",
       "ABER_ZG_5_15                    5.168943e+03\n",
       "ABER_SG_5_15                    5.179725e+03\n",
       "ABER_XG_5_15                    5.158161e+03\n",
       "ABER_ATR_5_15                   1.078200e+01\n",
       "ACCBL_20                        5.141156e+03\n",
       "ACCBM_20                        5.168063e+03\n",
       "ACCBU_20                        5.194484e+03\n",
       "AD                              1.698248e+07\n",
       "ADOSC_3_10                      9.991163e+03\n",
       "ADX_14                          2.842791e+01\n",
       "ADXR_14_2                       2.842565e+01\n",
       "DMP_14                          3.140142e+01\n",
       "DMN_14                          3.353531e+01\n",
       "AGj_13_8_5                      5.167682e+03\n",
       "AGt_13_8_5                      5.168414e+03\n",
       "AGl_13_8_5                      5.168845e+03\n",
       "ALMA_9_6.0_0.85                 5.169107e+03\n",
       "ALPHAT_14_1_50                  5.168287e+03\n",
       "ALPHATl_14_1_50_2               5.168010e+03\n",
       "AMATe_LR_8_21_2                 5.644109e-01\n",
       "AMATe_SR_8_21_2                 4.355891e-01\n",
       "AO_5_34                         2.096616e+00\n",
       "OBV                             4.920883e+06\n",
       "OBV_min_2                       4.888988e+06\n",
       "OBV_max_2                       4.952180e+06\n",
       "OBVe_4                          4.919953e+06\n",
       "OBVe_12                         4.917149e+06\n",
       "AOBV_LR_2                       5.274049e-01\n",
       "AOBV_SR_2                       4.725951e-01\n",
       "APO_12_26                       1.012876e+00\n",
       "AROOND_14                       4.659969e+01\n",
       "AROONU_14                       5.340431e+01\n",
       "AROONOSC_14                     6.804623e+00\n",
       "ATRr_14                         1.078262e+01\n",
       "ATRTSe_14_20_3.0                5.166804e+03\n",
       "BBL_5_2.0                       5.157717e+03\n",
       "BBM_5_2.0                       5.169128e+03\n",
       "BBU_5_2.0                       5.180539e+03\n",
       "BBB_5_2.0                       4.398335e-01\n",
       "BBP_5_2.0                       5.239965e-01\n",
       "BIAS_SMA_26                     3.700773e-04\n",
       "BOP                             2.806142e-02\n",
       "AR_26                           9.955267e+01\n",
       "BR_26                           1.015616e+02\n",
       "CCI_14_0.015                    1.213525e+01\n",
       "CDL_2CROWS                      0.000000e+00\n",
       "CDL_3BLACKCROWS                -9.321402e-03\n",
       "CDL_3INSIDE                     6.524981e-02\n",
       "CDL_3LINESTRIKE                 2.796421e-02\n",
       "CDL_3OUTSIDE                   -8.389262e-02\n",
       "CDL_3STARSINSOUTH               0.000000e+00\n",
       "CDL_3WHITESOLDIERS              1.304996e-01\n",
       "CDL_ABANDONEDBABY               0.000000e+00\n",
       "CDL_ADVANCEBLOCK               -1.472782e+00\n",
       "CDL_BELTHOLD                   -3.728561e-01\n",
       "CDL_BREAKAWAY                   0.000000e+00\n",
       "CDL_CLOSINGMARUBOZU             2.153244e+00\n",
       "CDL_CONCEALBABYSWALL            0.000000e+00\n",
       "CDL_COUNTERATTACK               0.000000e+00\n",
       "CDL_DARKCLOUDCOVER              0.000000e+00\n",
       "CDL_DOJI_10_0.1                 1.706749e+01\n",
       "CDL_DOJISTAR                   -1.864280e-01\n",
       "CDL_DRAGONFLYDOJI               4.064131e+00\n",
       "CDL_ENGULFING                  -3.076063e-01\n",
       "CDL_EVENINGDOJISTAR            -7.457122e-02\n",
       "CDL_EVENINGSTAR                -2.423565e-01\n",
       "CDL_GAPSIDESIDEWHITE            1.118568e-01\n",
       "CDL_GRAVESTONEDOJI              3.570097e+00\n",
       "CDL_HAMMER                      4.185309e+00\n",
       "CDL_HANGINGMAN                 -3.113348e+00\n",
       "CDL_HARAMI                     -3.914989e-01\n",
       "CDL_HARAMICROSS                -1.994780e-01\n",
       "CDL_HIGHWAVE                    1.845638e+00\n",
       "CDL_HIKKAKE                    -3.448919e-01\n",
       "CDL_HIKKAKEMOD                  1.864280e-02\n",
       "CDL_HOMINGPIGEON                5.592841e-02\n",
       "CDL_IDENTICAL3CROWS            -2.516779e-01\n",
       "CDL_INNECK                      0.000000e+00\n",
       "CDL_INSIDE                      1.269575e+01\n",
       "CDL_INVERTEDHAMMER              4.847129e-01\n",
       "CDL_KICKING                     0.000000e+00\n",
       "CDL_KICKINGBYLENGTH             0.000000e+00\n",
       "CDL_LADDERBOTTOM                2.796421e-02\n",
       "CDL_LONGLEGGEDDOJI              1.745899e+01\n",
       "CDL_LONGLINE                    2.032066e+00\n",
       "CDL_MARUBOZU                    4.101417e-01\n",
       "CDL_MATCHINGLOW                 1.677852e+00\n",
       "CDL_MATHOLD                     0.000000e+00\n",
       "CDL_MORNINGDOJISTAR             4.660701e-02\n",
       "CDL_MORNINGSTAR                 1.584638e-01\n",
       "CDL_ONNECK                     -9.321402e-03\n",
       "CDL_PIERCING                    0.000000e+00\n",
       "CDL_RICKSHAWMAN                 1.086875e+01\n",
       "CDL_RISEFALL3METHODS            0.000000e+00\n",
       "CDL_SEPARATINGLINES            -6.524981e-02\n",
       "CDL_SHOOTINGSTAR               -8.016406e-01\n",
       "CDL_SHORTLINE                   2.665921e+00\n",
       "CDL_SPINNINGTOP                 2.004101e+00\n",
       "CDL_STALLEDPATTERN             -3.076063e-01\n",
       "CDL_STICKSANDWICH               4.660701e-02\n",
       "CDL_TAKURI                      3.616704e+00\n",
       "CDL_TASUKIGAP                  -1.864280e-02\n",
       "CDL_THRUSTING                   0.000000e+00\n",
       "CDL_TRISTAR                    -9.321402e-03\n",
       "CDL_UNIQUE3RIVER                0.000000e+00\n",
       "CDL_UPSIDEGAP2CROWS             0.000000e+00\n",
       "CDL_XSIDEGAP3METHODS           -1.118568e-01\n",
       "open_Z_30_1                     1.694781e-01\n",
       "high_Z_30_1                     1.539216e-01\n",
       "low_Z_30_1                      1.779142e-01\n",
       "close_Z_30_1                    1.691069e-01\n",
       "CFO_9                          -2.797905e-03\n",
       "CG_10                          -5.500237e+00\n",
       "CHDLREXTl_22_22_14_2.0          5.174389e+03\n",
       "CHDLREXTs_22_22_14_2.0          5.156851e+03\n",
       "CHDLREXTd_22_22_14_2.0          1.756152e-01\n",
       "CHOP_14_1_100.0                 4.631928e+01\n",
       "CKSPl_10_3_20                   5.170045e+03\n",
       "CKSPs_10_3_20                   5.161812e+03\n",
       "CMF_20                          6.553720e-02\n",
       "CMO_14                          5.437098e+00\n",
       "COPC_11_14_10                   7.693793e-02\n",
       "CRSI_3_2_100                    5.115144e+01\n",
       "CTI_12                          8.849794e-02\n",
       "CUBE_3.0_-1                     1.440565e+11\n",
       "CUBEs_3.0_-1                    1.440565e+11\n",
       "LDECAY_1                        5.195653e+03\n",
       "DEC_1                           4.643922e-01\n",
       "DEMA_10                         5.169415e+03\n",
       "DCL_20_20                       5.137075e+03\n",
       "DCM_20_20                       5.165882e+03\n",
       "DCU_20_20                       5.194690e+03\n",
       "DPO_20                         -1.909078e-01\n",
       "EBSW_40_10                      1.319327e-01\n",
       "EFI_13                          9.118868e+03\n",
       "EMA_10                          5.168773e+03\n",
       "ENTP_10                         3.322172e+00\n",
       "EOM_14_100000000                3.528097e-01\n",
       "ER_10                           3.528097e-01\n",
       "BULLP_13                        5.902369e+00\n",
       "BEARP_13                       -4.771126e+00\n",
       "EXHC_DNa                        1.696402e+00\n",
       "EXHC_UPa                        2.313572e+00\n",
       "FISHERT_9_1                     3.745276e-01\n",
       "FISHERTs_9_1                    3.747960e-01\n",
       "FWMA_10                         5.169189e+03\n",
       "HA_open                         5.168971e+03\n",
       "HA_high                         5.175375e+03\n",
       "HA_low                          5.162669e+03\n",
       "HA_close                        5.169244e+03\n",
       "HILO_13_21                      5.164358e+03\n",
       "HL2                             5.169124e+03\n",
       "HLC3                            5.169216e+03\n",
       "HMA_10                          5.169360e+03\n",
       "HT_TL                           5.167525e+03\n",
       "HWM_1                           5.169559e+03\n",
       "HWU_1                           5.184370e+03\n",
       "HWL_1                           5.154749e+03\n",
       "HWMA_0.2_0.1_0.1                5.169559e+03\n",
       "ISA_9                           5.162650e+03\n",
       "ISB_26                          5.157704e+03\n",
       "ITS_9                           5.167585e+03\n",
       "IKS_26                          5.165085e+03\n",
       "ICS_26                          5.162344e+03\n",
       "INVFISHER_1.0                   2.345318e-02\n",
       "INVFISHERs_1.0                  2.345318e-02\n",
       "INC_1                           5.122110e-01\n",
       "INERTIA_20_14                   5.274864e+01\n",
       "JMA_7_0.0                       5.169030e+03\n",
       "KAMA_10_2_30                    5.168793e+03\n",
       "KCLe_20_2                       5.146480e+03\n",
       "KCBe_20_2                       5.168050e+03\n",
       "KCUe_20_2                       5.189620e+03\n",
       "K_9_3                           5.590798e+01\n",
       "D_9_3                           5.591285e+01\n",
       "J_9_3                           5.589826e+01\n",
       "KST_10_15_20_30_10_10_10_15     6.905544e+01\n",
       "KSTs_9                          6.959066e+01\n",
       "KURT_30                        -8.732603e-02\n",
       "KVO_34_55_13                   -1.431174e+01\n",
       "KVOs_34_55_13                  -8.409071e+00\n",
       "LINREG_14                       5.169413e+03\n",
       "LOGRET_1                        2.795459e-05\n",
       "MACD_12_26_9                    1.021757e+00\n",
       "MACDh_12_26_9                  -1.025593e-02\n",
       "MACDs_12_26_9                   1.032013e+00\n",
       "MAD_30                          1.401834e+01\n",
       "MAMA_0.5_0.05                   5.168754e+03\n",
       "FAMA_0.5_0.05                   5.167582e+03\n",
       "MASSI_9_25                      2.481950e+01\n",
       "MCGD_10                         5.167802e+03\n",
       "MEDIAN_30                       5.167626e+03\n",
       "MFI_14                          5.196652e+01\n",
       "MIDPOINT_2                      5.169333e+03\n",
       "MIDPRICE_2                      5.168914e+03\n",
       "MOM_10                          1.397674e+00\n",
       "NATR_14                         2.080304e-01\n",
       "NVI_1                           1.036598e+03\n",
       "OHLC4                           5.169244e+03\n",
       "PDIST                           1.641541e+01\n",
       "PCTRET_1                        2.940163e-05\n",
       "PGO_14                          1.113090e-01\n",
       "PIVOTS_TRAD_D_P                 5.166664e+03\n",
       "PIVOTS_TRAD_D_S1                5.142434e+03\n",
       "PIVOTS_TRAD_D_S2                5.116272e+03\n",
       "PIVOTS_TRAD_D_S3                5.065879e+03\n",
       "PIVOTS_TRAD_D_S4                5.065879e+03\n",
       "PIVOTS_TRAD_D_R1                5.192826e+03\n",
       "PIVOTS_TRAD_D_R2                5.217056e+03\n",
       "PIVOTS_TRAD_D_R3                5.267448e+03\n",
       "PIVOTS_TRAD_D_R4                5.267448e+03\n",
       "PPO_12_26_9                     2.073642e-02\n",
       "PPOh_12_26_9                   -2.010184e-04\n",
       "PPOs_12_26_9                    2.093744e-02\n",
       "PSARr_0.02_0.2                  9.153617e-02\n",
       "PSL_12                          5.125373e+01\n",
       "PVI                             9.999666e+01\n",
       "PVIe_255                        9.945080e+01\n",
       "PVO_12_26_9                    -7.688669e+00\n",
       "PVOh_12_26_9                    4.958553e-03\n",
       "PVOs_12_26_9                   -7.693628e+00\n",
       "PVOL                            3.286415e+08\n",
       "PVR                             2.394855e+00\n",
       "PVT                            -3.638696e+05\n",
       "PWMA_10                         5.168782e+03\n",
       "QQE_14_5_4.236                  5.241516e+01\n",
       "QQE_14_5_4.236_RSIMA            5.272384e+01\n",
       "QS_10                           7.581096e-02\n",
       "QTL_30_0.5                      5.167626e+03\n",
       "REFLEX_20_20_0.04              -6.872649e-03\n",
       "REMAP_0.0_100.0_-1.0_1.0        1.023880e+02\n",
       "RMA_10                          5.168123e+03\n",
       "ROC_10                          3.023252e-02\n",
       "RSI_14                          5.271855e+01\n",
       "RSX_14                          5.293595e+01\n",
       "RVGI_14_4                       2.051426e-02\n",
       "RVGIs_14_4                      2.054933e-02\n",
       "RVI_14                          5.274043e+01\n",
       "RWIh_14                         3.619050e-01\n",
       "RWIl_14                         1.796480e-01\n",
       "SINWMA_14                       5.168498e+03\n",
       "SKEW_30                        -9.480727e-02\n",
       "SLOPE_1                         1.351137e-01\n",
       "SMA_10                          5.168780e+03\n",
       "SMChv_14_50_20_5                2.181208e-01\n",
       "SMCbf_14_50_20_5                1.056115e-01\n",
       "SMCbi_14_50_20_5               -1.039986e+01\n",
       "SMCbp_14_50_20_5               -2.510241e+01\n",
       "SMCtf_14_50_20_5                8.296048e-02\n",
       "SMCti_14_50_20_5               -1.094631e+01\n",
       "SMCtp_14_50_20_5               -2.689662e+01\n",
       "SMI_5_20_5_1.0                  5.509689e-02\n",
       "SMIs_5_20_5_1.0                 5.519524e-02\n",
       "SMIo_5_20_5_1.0                -9.834914e-05\n",
       "SMMA_7                          5.168558e+03\n",
       "SQZ_20_2.0_20_1.5               1.712555e+00\n",
       "SQZ_ON                          2.225951e-01\n",
       "SQZ_OFF                         7.774049e-01\n",
       "SQZ_NO                          0.000000e+00\n",
       "SQZPRO_20_2.0_20_2.0_1.5_1.0    1.712555e+00\n",
       "SQZPRO_ON_WIDE                  4.669090e-01\n",
       "SQZPRO_ON_NORMAL                2.225951e-01\n",
       "SQZPRO_ON_NARROW                3.532811e-02\n",
       "SQZPRO_OFF                      5.330910e-01\n",
       "SQZPRO_NO                       0.000000e+00\n",
       "SSF_20                          5.168642e+03\n",
       "SSF3_20                         5.168724e+03\n",
       "STC_10_12_26_0.5                2.396248e+01\n",
       "STCmacd_10_12_26_0.5            1.021757e+00\n",
       "STCstoch_10_12_26_0.5           1.997526e+01\n",
       "STDEV_30                        1.663122e+01\n",
       "STOCHk_14_3_3                   5.664142e+01\n",
       "STOCHd_14_3_3                   5.664469e+01\n",
       "STOCHh_14_3_3                  -3.267253e-03\n",
       "STOCHFk_14_3                    5.663799e+01\n",
       "STOCHFd_14_3                    5.664142e+01\n",
       "STOCHRSIk_14_14_3_3             5.237769e+01\n",
       "STOCHRSId_14_14_3_3             5.238166e+01\n",
       "SUPERT_7_3.0                    5.169372e+03\n",
       "SUPERTd_7_3.0                   4.903057e-02\n",
       "SWMA_10                         5.168781e+03\n",
       "T3_10_0.7                       5.168857e+03\n",
       "TEMA_10                         5.169405e+03\n",
       "THERMO_20_2_0.5                 6.822124e+00\n",
       "THERMOma_20_2_0.5               6.815322e+00\n",
       "THERMOl_20_2_0.5                8.945749e-01\n",
       "THERMOs_20_2_0.5                6.556674e-01\n",
       "TMO_14_5_3                      1.292264e+00\n",
       "TMOs_14_5_3                     1.292669e+00\n",
       "TMOM_14_5_3                     0.000000e+00\n",
       "TMOMs_14_5_3                    0.000000e+00\n",
       "TOS_STDEVALL_LR                 5.169425e+03\n",
       "TOS_STDEVALL_L_1                4.542070e+03\n",
       "TOS_STDEVALL_U_1                5.796780e+03\n",
       "TOS_STDEVALL_L_2                3.914715e+03\n",
       "TOS_STDEVALL_U_2                6.424135e+03\n",
       "TOS_STDEVALL_L_3                3.287360e+03\n",
       "TOS_STDEVALL_U_3                7.051490e+03\n",
       "TRENDFLEX_20_20_0.04            9.489779e-02\n",
       "TRIMA_10                        5.168781e+03\n",
       "TRIX_30_9                       3.080910e-03\n",
       "TRIXs_30_9                      3.092361e-03\n",
       "TRUERANGE_1                     1.079174e+01\n",
       "TSI_13_25_13                    5.319566e+00\n",
       "TSIs_13_25_13                   5.343082e+00\n",
       "UI_14                           3.650737e-01\n",
       "UO_7_14_28                      5.349297e+01\n",
       "VAR_30                          4.054450e+02\n",
       "VHF_28                          3.737229e-01\n",
       "VHM_610                         3.987318e-02\n",
       "VTXP_14                         1.023653e+00\n",
       "VTXM_14                         9.720616e-01\n",
       "VWAP_D                          5.168560e+03\n",
       "VWMA_10                         5.168395e+03\n",
       "TSV_18_10                       1.747212e+05\n",
       "TSVs_18_10                      1.846856e+05\n",
       "TSVr_18_10                      2.159510e+00\n",
       "WCP                             5.169263e+03\n",
       "WILLR_14                       -4.336201e+01\n",
       "WMA_10                          5.168989e+03\n",
       "ZIGZAGs_5.0%_10                 5.165448e+03\n",
       "ZIGZAGv_5.0%_10                 5.169328e+03\n",
       "ZIGZAGd_5.0%_10                 5.165458e+03\n",
       "ZL_EMA_10                       5.169337e+03\n",
       "ZS_30                           1.691069e-01\n",
       "predict                         4.516219e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2441bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict\n",
       "0.0    5883\n",
       "1.0    4845\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class frequency\n",
    "c = data['predict'].value_counts()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde82859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight function\n",
    "def cwts(dfs):\n",
    "    c0, c1 = np.bincount(dfs['predict'])\n",
    "    w0=(1/c0)*(len(df))/2 \n",
    "    w1=(1/c1)*(len(df))/2 \n",
    "    return {0: w0, 1: w1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d9ef61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9292027876933537, 1: 1.1282765737874096}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class weights\n",
    "class_weight = cwts(data)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb8655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5466.5, 5466.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the calculated weights, both classes gain equal weight\n",
    "class_weight[0] * c[0], class_weight[1] * c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d735067b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>VTXP_14</th>\n",
       "      <th>VTXM_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>VWMA_10</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>TSVr_18_10</th>\n",
       "      <th>WCP</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>ZIGZAGs_5.0%_10</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZIGZAGd_5.0%_10</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-28 17:00:00+00:00</th>\n",
       "      <td>5630.75</td>\n",
       "      <td>5633.00</td>\n",
       "      <td>5618.75</td>\n",
       "      <td>5632.00</td>\n",
       "      <td>174057.0</td>\n",
       "      <td>5661.333333</td>\n",
       "      <td>5680.177744</td>\n",
       "      <td>5642.488923</td>\n",
       "      <td>18.844410</td>\n",
       "      <td>5676.998297</td>\n",
       "      <td>5713.6375</td>\n",
       "      <td>5757.060797</td>\n",
       "      <td>3.030610e+07</td>\n",
       "      <td>-289516.717266</td>\n",
       "      <td>41.091296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553522</td>\n",
       "      <td>1.405306</td>\n",
       "      <td>5672.262205</td>\n",
       "      <td>5661.292394</td>\n",
       "      <td>-24642615.50</td>\n",
       "      <td>-1.064921e+07</td>\n",
       "      <td>2.314032</td>\n",
       "      <td>5628.3125</td>\n",
       "      <td>-90.697674</td>\n",
       "      <td>5670.350000</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>-2.633574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 18:00:00+00:00</th>\n",
       "      <td>5628.75</td>\n",
       "      <td>5636.50</td>\n",
       "      <td>5619.75</td>\n",
       "      <td>5630.75</td>\n",
       "      <td>143085.0</td>\n",
       "      <td>5643.833333</td>\n",
       "      <td>5662.538116</td>\n",
       "      <td>5625.128550</td>\n",
       "      <td>18.704783</td>\n",
       "      <td>5669.975476</td>\n",
       "      <td>5708.0875</td>\n",
       "      <td>5752.725476</td>\n",
       "      <td>3.031678e+07</td>\n",
       "      <td>-242010.490013</td>\n",
       "      <td>42.999767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578440</td>\n",
       "      <td>1.375986</td>\n",
       "      <td>5667.881518</td>\n",
       "      <td>5656.732734</td>\n",
       "      <td>-24970470.50</td>\n",
       "      <td>-1.296109e+07</td>\n",
       "      <td>1.926573</td>\n",
       "      <td>5628.4375</td>\n",
       "      <td>-92.248062</td>\n",
       "      <td>5659.177273</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>-2.345638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 19:00:00+00:00</th>\n",
       "      <td>5624.50</td>\n",
       "      <td>5634.25</td>\n",
       "      <td>5617.25</td>\n",
       "      <td>5628.75</td>\n",
       "      <td>295029.0</td>\n",
       "      <td>5634.483333</td>\n",
       "      <td>5653.074464</td>\n",
       "      <td>5615.892202</td>\n",
       "      <td>18.591131</td>\n",
       "      <td>5663.452339</td>\n",
       "      <td>5702.5125</td>\n",
       "      <td>5748.202339</td>\n",
       "      <td>3.027339e+07</td>\n",
       "      <td>-214380.003569</td>\n",
       "      <td>44.818261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>1.375211</td>\n",
       "      <td>5660.624908</td>\n",
       "      <td>5650.222595</td>\n",
       "      <td>-26203976.75</td>\n",
       "      <td>-1.488171e+07</td>\n",
       "      <td>1.760817</td>\n",
       "      <td>5625.1250</td>\n",
       "      <td>-94.444444</td>\n",
       "      <td>5648.995455</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>-2.169653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 20:00:00+00:00</th>\n",
       "      <td>5602.50</td>\n",
       "      <td>5625.25</td>\n",
       "      <td>5602.25</td>\n",
       "      <td>5624.50</td>\n",
       "      <td>85426.0</td>\n",
       "      <td>5626.100000</td>\n",
       "      <td>5644.985055</td>\n",
       "      <td>5607.214945</td>\n",
       "      <td>18.885055</td>\n",
       "      <td>5656.280342</td>\n",
       "      <td>5695.5875</td>\n",
       "      <td>5743.280342</td>\n",
       "      <td>3.018982e+07</td>\n",
       "      <td>-210177.640213</td>\n",
       "      <td>46.766461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>1.406639</td>\n",
       "      <td>5658.242543</td>\n",
       "      <td>5647.042187</td>\n",
       "      <td>-28105848.75</td>\n",
       "      <td>-1.746749e+07</td>\n",
       "      <td>1.609038</td>\n",
       "      <td>5608.1250</td>\n",
       "      <td>-99.818182</td>\n",
       "      <td>5636.631818</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>-2.342159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30 22:00:00+00:00</th>\n",
       "      <td>5594.25</td>\n",
       "      <td>5600.00</td>\n",
       "      <td>5580.25</td>\n",
       "      <td>5590.00</td>\n",
       "      <td>22300.0</td>\n",
       "      <td>5616.533333</td>\n",
       "      <td>5635.642718</td>\n",
       "      <td>5597.423948</td>\n",
       "      <td>19.109385</td>\n",
       "      <td>5647.083490</td>\n",
       "      <td>5688.4000</td>\n",
       "      <td>5737.458490</td>\n",
       "      <td>3.019914e+07</td>\n",
       "      <td>-186387.509316</td>\n",
       "      <td>48.882431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572020</td>\n",
       "      <td>1.432119</td>\n",
       "      <td>5591.500000</td>\n",
       "      <td>5645.744790</td>\n",
       "      <td>-28299001.50</td>\n",
       "      <td>-2.028136e+07</td>\n",
       "      <td>1.395321</td>\n",
       "      <td>5592.1875</td>\n",
       "      <td>-91.222571</td>\n",
       "      <td>5625.177273</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>-2.249456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Close     High      Low     Open    Volume  \\\n",
       "Datetime                                                                  \n",
       "2025-03-28 17:00:00+00:00  5630.75  5633.00  5618.75  5632.00  174057.0   \n",
       "2025-03-28 18:00:00+00:00  5628.75  5636.50  5619.75  5630.75  143085.0   \n",
       "2025-03-28 19:00:00+00:00  5624.50  5634.25  5617.25  5628.75  295029.0   \n",
       "2025-03-28 20:00:00+00:00  5602.50  5625.25  5602.25  5624.50   85426.0   \n",
       "2025-03-30 22:00:00+00:00  5594.25  5600.00  5580.25  5590.00   22300.0   \n",
       "\n",
       "                           ABER_ZG_5_15  ABER_SG_5_15  ABER_XG_5_15  \\\n",
       "Datetime                                                              \n",
       "2025-03-28 17:00:00+00:00   5661.333333   5680.177744   5642.488923   \n",
       "2025-03-28 18:00:00+00:00   5643.833333   5662.538116   5625.128550   \n",
       "2025-03-28 19:00:00+00:00   5634.483333   5653.074464   5615.892202   \n",
       "2025-03-28 20:00:00+00:00   5626.100000   5644.985055   5607.214945   \n",
       "2025-03-30 22:00:00+00:00   5616.533333   5635.642718   5597.423948   \n",
       "\n",
       "                           ABER_ATR_5_15     ACCBL_20   ACCBM_20     ACCBU_20  \\\n",
       "Datetime                                                                        \n",
       "2025-03-28 17:00:00+00:00      18.844410  5676.998297  5713.6375  5757.060797   \n",
       "2025-03-28 18:00:00+00:00      18.704783  5669.975476  5708.0875  5752.725476   \n",
       "2025-03-28 19:00:00+00:00      18.591131  5663.452339  5702.5125  5748.202339   \n",
       "2025-03-28 20:00:00+00:00      18.885055  5656.280342  5695.5875  5743.280342   \n",
       "2025-03-30 22:00:00+00:00      19.109385  5647.083490  5688.4000  5737.458490   \n",
       "\n",
       "                                     AD     ADOSC_3_10     ADX_14  ...  \\\n",
       "Datetime                                                           ...   \n",
       "2025-03-28 17:00:00+00:00  3.030610e+07 -289516.717266  41.091296  ...   \n",
       "2025-03-28 18:00:00+00:00  3.031678e+07 -242010.490013  42.999767  ...   \n",
       "2025-03-28 19:00:00+00:00  3.027339e+07 -214380.003569  44.818261  ...   \n",
       "2025-03-28 20:00:00+00:00  3.018982e+07 -210177.640213  46.766461  ...   \n",
       "2025-03-30 22:00:00+00:00  3.019914e+07 -186387.509316  48.882431  ...   \n",
       "\n",
       "                            VTXP_14   VTXM_14       VWAP_D      VWMA_10  \\\n",
       "Datetime                                                                  \n",
       "2025-03-28 17:00:00+00:00  0.553522  1.405306  5672.262205  5661.292394   \n",
       "2025-03-28 18:00:00+00:00  0.578440  1.375986  5667.881518  5656.732734   \n",
       "2025-03-28 19:00:00+00:00  0.586847  1.375211  5660.624908  5650.222595   \n",
       "2025-03-28 20:00:00+00:00  0.577593  1.406639  5658.242543  5647.042187   \n",
       "2025-03-30 22:00:00+00:00  0.572020  1.432119  5591.500000  5645.744790   \n",
       "\n",
       "                             TSV_18_10    TSVs_18_10  TSVr_18_10        WCP  \\\n",
       "Datetime                                                                      \n",
       "2025-03-28 17:00:00+00:00 -24642615.50 -1.064921e+07    2.314032  5628.3125   \n",
       "2025-03-28 18:00:00+00:00 -24970470.50 -1.296109e+07    1.926573  5628.4375   \n",
       "2025-03-28 19:00:00+00:00 -26203976.75 -1.488171e+07    1.760817  5625.1250   \n",
       "2025-03-28 20:00:00+00:00 -28105848.75 -1.746749e+07    1.609038  5608.1250   \n",
       "2025-03-30 22:00:00+00:00 -28299001.50 -2.028136e+07    1.395321  5592.1875   \n",
       "\n",
       "                            WILLR_14       WMA_10  ZIGZAGs_5.0%_10  \\\n",
       "Datetime                                                             \n",
       "2025-03-28 17:00:00+00:00 -90.697674  5670.350000      5630.046629   \n",
       "2025-03-28 18:00:00+00:00 -92.248062  5659.177273      5624.947242   \n",
       "2025-03-28 19:00:00+00:00 -94.444444  5648.995455      5620.911379   \n",
       "2025-03-28 20:00:00+00:00 -99.818182  5636.631818      5612.200220   \n",
       "2025-03-30 22:00:00+00:00 -91.222571  5625.177273      5602.300180   \n",
       "\n",
       "                           ZIGZAGv_5.0%_10  ZIGZAGd_5.0%_10    ZL_EMA_10  \\\n",
       "Datetime                                                                   \n",
       "2025-03-28 17:00:00+00:00      5630.046629      5630.046629  5630.046629   \n",
       "2025-03-28 18:00:00+00:00      5624.947242      5624.947242  5624.947242   \n",
       "2025-03-28 19:00:00+00:00      5620.911379      5620.911379  5620.911379   \n",
       "2025-03-28 20:00:00+00:00      5612.200220      5612.200220  5612.200220   \n",
       "2025-03-30 22:00:00+00:00      5602.300180      5602.300180  5602.300180   \n",
       "\n",
       "                              ZS_30  \n",
       "Datetime                             \n",
       "2025-03-28 17:00:00+00:00 -2.633574  \n",
       "2025-03-28 18:00:00+00:00 -2.345638  \n",
       "2025-03-28 19:00:00+00:00 -2.169653  \n",
       "2025-03-28 20:00:00+00:00 -2.342159  \n",
       "2025-03-30 22:00:00+00:00 -2.249456  \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['predict'], axis=1)\n",
    "feature_names = X.columns\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5b3d1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['predict'].values\n",
    "# pandas-ta converts all dtype to objects\n",
    "y = y.astype(int) \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cfd8822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Size 8582, 2146\n"
     ]
    }
   ],
   "source": [
    "# Always keep shuffle = False for financial time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# convert to array\n",
    "X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test) \n",
    "\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {len(X_train)}, {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "025bdd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define random forest classifier\n",
    "forest = RandomForestClassifier(n_jobs=-1, \n",
    "                                class_weight=cwts(data), \n",
    "                                random_state=42, \n",
    "                                max_depth=5)\n",
    "\n",
    "# train the model\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7024cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score \t\t 0.6584342963653308\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Accuracy Score \\t\\t\", accuracy_score(y_test, forest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8879d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t330\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 300\n",
      "Confirmed: \t0\n",
      "Tentative: \t100\n",
      "Rejected: \t230\n",
      "Iteration: \t9 / 300\n",
      "Confirmed: \t15\n",
      "Tentative: \t85\n",
      "Rejected: \t230\n",
      "Iteration: \t10 / 300\n",
      "Confirmed: \t15\n",
      "Tentative: \t85\n",
      "Rejected: \t230\n",
      "Iteration: \t11 / 300\n",
      "Confirmed: \t15\n",
      "Tentative: \t85\n",
      "Rejected: \t230\n",
      "Iteration: \t12 / 300\n",
      "Confirmed: \t19\n",
      "Tentative: \t81\n",
      "Rejected: \t230\n",
      "Iteration: \t13 / 300\n",
      "Confirmed: \t19\n",
      "Tentative: \t81\n",
      "Rejected: \t230\n",
      "Iteration: \t14 / 300\n",
      "Confirmed: \t19\n",
      "Tentative: \t81\n",
      "Rejected: \t230\n",
      "Iteration: \t15 / 300\n",
      "Confirmed: \t19\n",
      "Tentative: \t81\n",
      "Rejected: \t230\n",
      "Iteration: \t16 / 300\n",
      "Confirmed: \t22\n",
      "Tentative: \t78\n",
      "Rejected: \t230\n",
      "Iteration: \t17 / 300\n",
      "Confirmed: \t22\n",
      "Tentative: \t78\n",
      "Rejected: \t230\n",
      "Iteration: \t18 / 300\n",
      "Confirmed: \t22\n",
      "Tentative: \t78\n",
      "Rejected: \t230\n",
      "Iteration: \t19 / 300\n",
      "Confirmed: \t26\n",
      "Tentative: \t74\n",
      "Rejected: \t230\n",
      "Iteration: \t20 / 300\n",
      "Confirmed: \t26\n",
      "Tentative: \t74\n",
      "Rejected: \t230\n",
      "Iteration: \t21 / 300\n",
      "Confirmed: \t26\n",
      "Tentative: \t74\n",
      "Rejected: \t230\n",
      "Iteration: \t22 / 300\n",
      "Confirmed: \t29\n",
      "Tentative: \t71\n",
      "Rejected: \t230\n",
      "Iteration: \t23 / 300\n",
      "Confirmed: \t29\n",
      "Tentative: \t71\n",
      "Rejected: \t230\n",
      "Iteration: \t24 / 300\n",
      "Confirmed: \t29\n",
      "Tentative: \t71\n",
      "Rejected: \t230\n",
      "Iteration: \t25 / 300\n",
      "Confirmed: \t29\n",
      "Tentative: \t71\n",
      "Rejected: \t230\n",
      "Iteration: \t26 / 300\n",
      "Confirmed: \t31\n",
      "Tentative: \t69\n",
      "Rejected: \t230\n",
      "Iteration: \t27 / 300\n",
      "Confirmed: \t31\n",
      "Tentative: \t69\n",
      "Rejected: \t230\n",
      "Iteration: \t28 / 300\n",
      "Confirmed: \t31\n",
      "Tentative: \t69\n",
      "Rejected: \t230\n",
      "Iteration: \t29 / 300\n",
      "Confirmed: \t32\n",
      "Tentative: \t68\n",
      "Rejected: \t230\n",
      "Iteration: \t30 / 300\n",
      "Confirmed: \t32\n",
      "Tentative: \t68\n",
      "Rejected: \t230\n",
      "Iteration: \t31 / 300\n",
      "Confirmed: \t32\n",
      "Tentative: \t68\n",
      "Rejected: \t230\n",
      "Iteration: \t32 / 300\n",
      "Confirmed: \t37\n",
      "Tentative: \t63\n",
      "Rejected: \t230\n",
      "Iteration: \t33 / 300\n",
      "Confirmed: \t37\n",
      "Tentative: \t63\n",
      "Rejected: \t230\n",
      "Iteration: \t34 / 300\n",
      "Confirmed: \t41\n",
      "Tentative: \t59\n",
      "Rejected: \t230\n",
      "Iteration: \t35 / 300\n",
      "Confirmed: \t41\n",
      "Tentative: \t59\n",
      "Rejected: \t230\n",
      "Iteration: \t36 / 300\n",
      "Confirmed: \t41\n",
      "Tentative: \t59\n",
      "Rejected: \t230\n",
      "Iteration: \t37 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t38 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t39 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t40 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t41 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t42 / 300\n",
      "Confirmed: \t43\n",
      "Tentative: \t57\n",
      "Rejected: \t230\n",
      "Iteration: \t43 / 300\n",
      "Confirmed: \t44\n",
      "Tentative: \t56\n",
      "Rejected: \t230\n",
      "Iteration: \t44 / 300\n",
      "Confirmed: \t44\n",
      "Tentative: \t56\n",
      "Rejected: \t230\n",
      "Iteration: \t45 / 300\n",
      "Confirmed: \t44\n",
      "Tentative: \t55\n",
      "Rejected: \t231\n",
      "Iteration: \t46 / 300\n",
      "Confirmed: \t46\n",
      "Tentative: \t53\n",
      "Rejected: \t231\n",
      "Iteration: \t47 / 300\n",
      "Confirmed: \t46\n",
      "Tentative: \t53\n",
      "Rejected: \t231\n",
      "Iteration: \t48 / 300\n",
      "Confirmed: \t46\n",
      "Tentative: \t53\n",
      "Rejected: \t231\n",
      "Iteration: \t49 / 300\n",
      "Confirmed: \t47\n",
      "Tentative: \t52\n",
      "Rejected: \t231\n",
      "Iteration: \t50 / 300\n",
      "Confirmed: \t47\n",
      "Tentative: \t52\n",
      "Rejected: \t231\n",
      "Iteration: \t51 / 300\n",
      "Confirmed: \t48\n",
      "Tentative: \t51\n",
      "Rejected: \t231\n",
      "Iteration: \t52 / 300\n",
      "Confirmed: \t48\n",
      "Tentative: \t51\n",
      "Rejected: \t231\n",
      "Iteration: \t53 / 300\n",
      "Confirmed: \t48\n",
      "Tentative: \t51\n",
      "Rejected: \t231\n",
      "Iteration: \t54 / 300\n",
      "Confirmed: \t51\n",
      "Tentative: \t46\n",
      "Rejected: \t233\n",
      "Iteration: \t55 / 300\n",
      "Confirmed: \t51\n",
      "Tentative: \t46\n",
      "Rejected: \t233\n",
      "Iteration: \t56 / 300\n",
      "Confirmed: \t51\n",
      "Tentative: \t46\n",
      "Rejected: \t233\n",
      "Iteration: \t57 / 300\n",
      "Confirmed: \t52\n",
      "Tentative: \t45\n",
      "Rejected: \t233\n",
      "Iteration: \t58 / 300\n",
      "Confirmed: \t52\n",
      "Tentative: \t45\n",
      "Rejected: \t233\n",
      "Iteration: \t59 / 300\n",
      "Confirmed: \t52\n",
      "Tentative: \t45\n",
      "Rejected: \t233\n",
      "Iteration: \t60 / 300\n",
      "Confirmed: \t52\n",
      "Tentative: \t45\n",
      "Rejected: \t233\n",
      "Iteration: \t61 / 300\n",
      "Confirmed: \t52\n",
      "Tentative: \t45\n",
      "Rejected: \t233\n",
      "Iteration: \t62 / 300\n",
      "Confirmed: \t53\n",
      "Tentative: \t44\n",
      "Rejected: \t233\n",
      "Iteration: \t63 / 300\n",
      "Confirmed: \t53\n",
      "Tentative: \t44\n",
      "Rejected: \t233\n",
      "Iteration: \t64 / 300\n",
      "Confirmed: \t53\n",
      "Tentative: \t44\n",
      "Rejected: \t233\n",
      "Iteration: \t65 / 300\n",
      "Confirmed: \t55\n",
      "Tentative: \t42\n",
      "Rejected: \t233\n",
      "Iteration: \t66 / 300\n",
      "Confirmed: \t55\n",
      "Tentative: \t42\n",
      "Rejected: \t233\n",
      "Iteration: \t67 / 300\n",
      "Confirmed: \t55\n",
      "Tentative: \t42\n",
      "Rejected: \t233\n",
      "Iteration: \t68 / 300\n",
      "Confirmed: \t55\n",
      "Tentative: \t42\n",
      "Rejected: \t233\n",
      "Iteration: \t69 / 300\n",
      "Confirmed: \t55\n",
      "Tentative: \t42\n",
      "Rejected: \t233\n",
      "Iteration: \t70 / 300\n",
      "Confirmed: \t56\n",
      "Tentative: \t41\n",
      "Rejected: \t233\n",
      "Iteration: \t71 / 300\n",
      "Confirmed: \t56\n",
      "Tentative: \t41\n",
      "Rejected: \t233\n",
      "Iteration: \t72 / 300\n",
      "Confirmed: \t56\n",
      "Tentative: \t41\n",
      "Rejected: \t233\n",
      "Iteration: \t73 / 300\n",
      "Confirmed: \t56\n",
      "Tentative: \t41\n",
      "Rejected: \t233\n",
      "Iteration: \t74 / 300\n",
      "Confirmed: \t56\n",
      "Tentative: \t41\n",
      "Rejected: \t233\n",
      "Iteration: \t75 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t76 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t77 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t78 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t79 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t80 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t81 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t82 / 300\n",
      "Confirmed: \t57\n",
      "Tentative: \t40\n",
      "Rejected: \t233\n",
      "Iteration: \t83 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t84 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t85 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t86 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t87 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t88 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t89 / 300\n",
      "Confirmed: \t58\n",
      "Tentative: \t39\n",
      "Rejected: \t233\n",
      "Iteration: \t90 / 300\n",
      "Confirmed: \t59\n",
      "Tentative: \t38\n",
      "Rejected: \t233\n",
      "Iteration: \t91 / 300\n",
      "Confirmed: \t59\n",
      "Tentative: \t38\n",
      "Rejected: \t233\n",
      "Iteration: \t92 / 300\n",
      "Confirmed: \t59\n",
      "Tentative: \t38\n",
      "Rejected: \t233\n",
      "Iteration: \t93 / 300\n",
      "Confirmed: \t61\n",
      "Tentative: \t36\n",
      "Rejected: \t233\n",
      "Iteration: \t94 / 300\n",
      "Confirmed: \t61\n",
      "Tentative: \t36\n",
      "Rejected: \t233\n",
      "Iteration: \t95 / 300\n",
      "Confirmed: \t62\n",
      "Tentative: \t35\n",
      "Rejected: \t233\n",
      "Iteration: \t96 / 300\n",
      "Confirmed: \t62\n",
      "Tentative: \t35\n",
      "Rejected: \t233\n",
      "Iteration: \t97 / 300\n",
      "Confirmed: \t62\n",
      "Tentative: \t35\n",
      "Rejected: \t233\n",
      "Iteration: \t98 / 300\n",
      "Confirmed: \t62\n",
      "Tentative: \t35\n",
      "Rejected: \t233\n",
      "Iteration: \t99 / 300\n",
      "Confirmed: \t62\n",
      "Tentative: \t35\n",
      "Rejected: \t233\n",
      "Iteration: \t100 / 300\n",
      "Confirmed: \t63\n",
      "Tentative: \t34\n",
      "Rejected: \t233\n",
      "Iteration: \t101 / 300\n",
      "Confirmed: \t63\n",
      "Tentative: \t34\n",
      "Rejected: \t233\n",
      "Iteration: \t102 / 300\n",
      "Confirmed: \t63\n",
      "Tentative: \t34\n",
      "Rejected: \t233\n",
      "Iteration: \t103 / 300\n",
      "Confirmed: \t64\n",
      "Tentative: \t33\n",
      "Rejected: \t233\n",
      "Iteration: \t104 / 300\n",
      "Confirmed: \t64\n",
      "Tentative: \t33\n",
      "Rejected: \t233\n",
      "Iteration: \t105 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t106 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t107 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t108 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t109 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t110 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t111 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t112 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t113 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t114 / 300\n",
      "Confirmed: \t65\n",
      "Tentative: \t32\n",
      "Rejected: \t233\n",
      "Iteration: \t115 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t116 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t117 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t118 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t119 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t120 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t121 / 300\n",
      "Confirmed: \t66\n",
      "Tentative: \t31\n",
      "Rejected: \t233\n",
      "Iteration: \t122 / 300\n",
      "Confirmed: \t67\n",
      "Tentative: \t30\n",
      "Rejected: \t233\n",
      "Iteration: \t123 / 300\n",
      "Confirmed: \t67\n",
      "Tentative: \t30\n",
      "Rejected: \t233\n",
      "Iteration: \t124 / 300\n",
      "Confirmed: \t67\n",
      "Tentative: \t30\n",
      "Rejected: \t233\n",
      "Iteration: \t125 / 300\n",
      "Confirmed: \t67\n",
      "Tentative: \t30\n",
      "Rejected: \t233\n",
      "Iteration: \t126 / 300\n",
      "Confirmed: \t67\n",
      "Tentative: \t30\n",
      "Rejected: \t233\n",
      "Iteration: \t127 / 300\n",
      "Confirmed: \t69\n",
      "Tentative: \t28\n",
      "Rejected: \t233\n",
      "Iteration: \t128 / 300\n",
      "Confirmed: \t69\n",
      "Tentative: \t28\n",
      "Rejected: \t233\n",
      "Iteration: \t129 / 300\n",
      "Confirmed: \t70\n",
      "Tentative: \t27\n",
      "Rejected: \t233\n",
      "Iteration: \t130 / 300\n",
      "Confirmed: \t70\n",
      "Tentative: \t27\n",
      "Rejected: \t233\n",
      "Iteration: \t131 / 300\n",
      "Confirmed: \t70\n",
      "Tentative: \t27\n",
      "Rejected: \t233\n",
      "Iteration: \t132 / 300\n",
      "Confirmed: \t70\n",
      "Tentative: \t27\n",
      "Rejected: \t233\n",
      "Iteration: \t133 / 300\n",
      "Confirmed: \t70\n",
      "Tentative: \t27\n",
      "Rejected: \t233\n",
      "Iteration: \t134 / 300\n",
      "Confirmed: \t71\n",
      "Tentative: \t26\n",
      "Rejected: \t233\n",
      "Iteration: \t135 / 300\n",
      "Confirmed: \t71\n",
      "Tentative: \t26\n",
      "Rejected: \t233\n",
      "Iteration: \t136 / 300\n",
      "Confirmed: \t71\n",
      "Tentative: \t26\n",
      "Rejected: \t233\n",
      "Iteration: \t137 / 300\n",
      "Confirmed: \t71\n",
      "Tentative: \t26\n",
      "Rejected: \t233\n",
      "Iteration: \t138 / 300\n",
      "Confirmed: \t71\n",
      "Tentative: \t26\n",
      "Rejected: \t233\n",
      "Iteration: \t139 / 300\n",
      "Confirmed: \t72\n",
      "Tentative: \t25\n",
      "Rejected: \t233\n",
      "Iteration: \t140 / 300\n",
      "Confirmed: \t72\n",
      "Tentative: \t25\n",
      "Rejected: \t233\n",
      "Iteration: \t141 / 300\n",
      "Confirmed: \t72\n",
      "Tentative: \t25\n",
      "Rejected: \t233\n",
      "Iteration: \t142 / 300\n",
      "Confirmed: \t72\n",
      "Tentative: \t25\n",
      "Rejected: \t233\n",
      "Iteration: \t143 / 300\n",
      "Confirmed: \t72\n",
      "Tentative: \t25\n",
      "Rejected: \t233\n",
      "Iteration: \t144 / 300\n",
      "Confirmed: \t73\n",
      "Tentative: \t24\n",
      "Rejected: \t233\n",
      "Iteration: \t145 / 300\n",
      "Confirmed: \t73\n",
      "Tentative: \t24\n",
      "Rejected: \t233\n",
      "Iteration: \t146 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t147 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t148 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t149 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t150 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t151 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t152 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t153 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t154 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t155 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t156 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t157 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t158 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t159 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t160 / 300\n",
      "Confirmed: \t74\n",
      "Tentative: \t23\n",
      "Rejected: \t233\n",
      "Iteration: \t161 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t162 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t163 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t164 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t165 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t166 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t167 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t168 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t169 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t170 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t171 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t172 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t173 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t174 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t175 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t176 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t177 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t178 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t179 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t180 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t181 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t182 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t183 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t184 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t185 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t186 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t187 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t188 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t189 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t190 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t191 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t192 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t193 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t194 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t195 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t196 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t197 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t198 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t199 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t200 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t201 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t202 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t203 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t204 / 300\n",
      "Confirmed: \t75\n",
      "Tentative: \t22\n",
      "Rejected: \t233\n",
      "Iteration: \t205 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t206 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t207 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t208 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t209 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t210 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t211 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t212 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t213 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t214 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t215 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t216 / 300\n",
      "Confirmed: \t76\n",
      "Tentative: \t21\n",
      "Rejected: \t233\n",
      "Iteration: \t217 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t218 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t219 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t220 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t221 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t222 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t223 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t224 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t225 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t226 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t227 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t228 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t229 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t230 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t231 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t232 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t233 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t234 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t235 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t236 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t237 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t238 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t239 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t240 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t241 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t242 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t243 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t244 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t245 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t246 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t247 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t248 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t249 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t250 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t251 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t252 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t253 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t254 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t255 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t256 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t257 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t258 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t259 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t260 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t261 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t262 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t263 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t264 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t265 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t266 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t267 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t268 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t269 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t270 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t271 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t272 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t273 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t274 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t275 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t276 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t277 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t278 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t279 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t280 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t281 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t282 / 300\n",
      "Confirmed: \t77\n",
      "Tentative: \t20\n",
      "Rejected: \t233\n",
      "Iteration: \t283 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t284 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t285 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t286 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t287 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t288 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t289 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t290 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t291 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t292 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t293 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t294 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t295 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t296 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t297 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t298 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "Iteration: \t299 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t19\n",
      "Rejected: \t233\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t300 / 300\n",
      "Confirmed: \t78\n",
      "Tentative: \t18\n",
      "Rejected: \t234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                                        1: 1.1282765737874096},\n",
       "                                          max_depth=5, n_estimators=278,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x278A5423E40),\n",
       "         max_iter=300, n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x278A5423E40, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BorutaPy<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BorutaPy(estimator=RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                                        1: 1.1282765737874096},\n",
       "                                          max_depth=5, n_estimators=278,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x278A5423E40),\n",
       "         max_iter=300, n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x278A5423E40, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_estimators=278, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x278A5423E40)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_estimators=278, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x278A5423E40)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                                        1: 1.1282765737874096},\n",
       "                                          max_depth=5, n_estimators=278,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x278A5423E40),\n",
       "         max_iter=300, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x278A5423E40, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=0,max_iter=300)\n",
    "\n",
    "# find all relevant features\n",
    "# takes input in array format not as dataframe\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a311007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False False False False False False False  True\n",
      "  True False False False  True False False False False False False False\n",
      " False False  True  True  True  True  True  True False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False  True False  True False False False False\n",
      "  True False False False  True  True False False False False False False\n",
      "  True  True False False False False  True False False False False False\n",
      "  True False False False  True  True False False False False  True  True\n",
      "  True False False False  True  True False False  True False False False\n",
      " False False False False  True  True False False False False  True False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False  True False False  True False False\n",
      "  True False  True False False False False  True False False  True  True\n",
      "  True False False False False  True  True False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False  True False False False False False\n",
      "  True  True False False  True False False False False False  True False\n",
      " False  True False False  True  True False False  True  True  True  True\n",
      "  True  True  True  True False  True  True False  True  True  True  True\n",
      " False  True False  True False  True False  True  True False False  True\n",
      " False False  True False False  True]\n",
      "[  1  25  85 106 135  94  79  81   2 117 110   1   1   2   2  23   1  55\n",
      "  85 101  82  82 120 131 149 153   1   1   1   1   1   1 157 159  90 151\n",
      " 152 112  16 139  48   2  57  44  63   1 148  38   4  35 218 218 195 218\n",
      " 190 218 218 218 195 165 218 158 218 218 218 176 195 195 161 218 218 218\n",
      " 195 169 188 167 180 163 166 218 218 218 218 186 218 218 218 218 174 171\n",
      " 191 184 218 218 195 218 218 187 218 195 195 177 168 218 218 188 218 218\n",
      " 218 218 218 182   1   1   1   1 141  43  40  99 154  24 136  93   1  10\n",
      "  10 100  22 139 129 108 159  95  76 134 128   1   2   1 109   2 126 121\n",
      "   1  20 150 143   1   1  28 107  26  89  39 129   1   1  27 118  57  37\n",
      "   1 113   8  60 119 123   1 103 133 173   1   1  51  71  74   7   1   1\n",
      "   1  12   2  13   1   1  41 141   1  51   5  92  55  97   2  78   1   1\n",
      "  60  49  53  19   1  65 125 131   1 111 103   2   2   2   2  33  59  30\n",
      " 115  84  50 178 145 144   1  15 105   1 137 156   1  62   1   2  20  46\n",
      "   2   1  77  34   1   1   1  65  75  71  67   1   1 147 114 170 163 127\n",
      "   5 179 115  95  67   3   1  87  31 155 183 218  87 145 175 163 122 218\n",
      "   1  69   2   2  14  17   1   1  44  29   1 102 124  73 171  69   1  41\n",
      " 139   1 185 180   1   1 218 218   1   1   1   1   1   1   1   1  47   1\n",
      "   1  90   1   1   1   1   9   1   2   1  55   1  35   1   1   2  17   1\n",
      "  65  79   1  98  32   1]\n"
     ]
    }
   ],
   "source": [
    "# check selected features\n",
    "print(feat_selector.support_)\n",
    "\n",
    "# check ranking of features\n",
    "print(feat_selector.ranking_)\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a16c0fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.14400000e+03,  4.17664414e+03,  1.39104718e+05, ...,\n",
       "        -5.21276596e+01,  4.14147682e+03, -4.24333591e-01],\n",
       "       [ 4.14525000e+03,  4.17558141e+03,  1.87401607e+05, ...,\n",
       "        -4.94680851e+01,  4.14275376e+03, -3.10069899e-01],\n",
       "       [ 4.14875000e+03,  4.17485645e+03,  1.87401607e+05, ...,\n",
       "        -4.20212766e+01,  4.14629853e+03, -6.48597483e-02],\n",
       "       ...,\n",
       "       [ 6.00150000e+03,  6.01028058e+03,  2.73676365e+07, ...,\n",
       "        -2.50000000e+01,  6.00505460e+03,  1.20677558e+00],\n",
       "       [ 6.00300000e+03,  6.01165541e+03,  2.73679600e+07, ...,\n",
       "        -2.17391304e+01,  6.00390831e+03,  1.20713580e+00],\n",
       "       [ 6.00300000e+03,  6.01292982e+03,  2.73667319e+07, ...,\n",
       "        -2.38095238e+01,  6.00360680e+03,  1.13045115e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered_1 = feat_selector.transform(X_train)\n",
    "X_filtered_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72bc32cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Close                          Rank: 1     Keep: True\n",
      "Feature: High                           Rank: 25    Keep: False\n",
      "Feature: Low                            Rank: 85    Keep: False\n",
      "Feature: Open                           Rank: 106   Keep: False\n",
      "Feature: Volume                         Rank: 135   Keep: False\n",
      "Feature: ABER_ZG_5_15                   Rank: 94    Keep: False\n",
      "Feature: ABER_SG_5_15                   Rank: 79    Keep: False\n",
      "Feature: ABER_XG_5_15                   Rank: 81    Keep: False\n",
      "Feature: ABER_ATR_5_15                  Rank: 2     Keep: False\n",
      "Feature: ACCBL_20                       Rank: 117   Keep: False\n",
      "Feature: ACCBM_20                       Rank: 110   Keep: False\n",
      "Feature: ACCBU_20                       Rank: 1     Keep: True\n",
      "Feature: AD                             Rank: 1     Keep: True\n",
      "Feature: ADOSC_3_10                     Rank: 2     Keep: False\n",
      "Feature: ADX_14                         Rank: 2     Keep: False\n",
      "Feature: ADXR_14_2                      Rank: 23    Keep: False\n",
      "Feature: DMP_14                         Rank: 1     Keep: True\n",
      "Feature: DMN_14                         Rank: 55    Keep: False\n",
      "Feature: AGj_13_8_5                     Rank: 85    Keep: False\n",
      "Feature: AGt_13_8_5                     Rank: 101   Keep: False\n",
      "Feature: AGl_13_8_5                     Rank: 82    Keep: False\n",
      "Feature: ALMA_9_6.0_0.85                Rank: 82    Keep: False\n",
      "Feature: ALPHAT_14_1_50                 Rank: 120   Keep: False\n",
      "Feature: ALPHATl_14_1_50_2              Rank: 131   Keep: False\n",
      "Feature: AMATe_LR_8_21_2                Rank: 149   Keep: False\n",
      "Feature: AMATe_SR_8_21_2                Rank: 153   Keep: False\n",
      "Feature: AO_5_34                        Rank: 1     Keep: True\n",
      "Feature: OBV                            Rank: 1     Keep: True\n",
      "Feature: OBV_min_2                      Rank: 1     Keep: True\n",
      "Feature: OBV_max_2                      Rank: 1     Keep: True\n",
      "Feature: OBVe_4                         Rank: 1     Keep: True\n",
      "Feature: OBVe_12                        Rank: 1     Keep: True\n",
      "Feature: AOBV_LR_2                      Rank: 157   Keep: False\n",
      "Feature: AOBV_SR_2                      Rank: 159   Keep: False\n",
      "Feature: APO_12_26                      Rank: 90    Keep: False\n",
      "Feature: AROOND_14                      Rank: 151   Keep: False\n",
      "Feature: AROONU_14                      Rank: 152   Keep: False\n",
      "Feature: AROONOSC_14                    Rank: 112   Keep: False\n",
      "Feature: ATRr_14                        Rank: 16    Keep: False\n",
      "Feature: ATRTSe_14_20_3.0               Rank: 139   Keep: False\n",
      "Feature: BBL_5_2.0                      Rank: 48    Keep: False\n",
      "Feature: BBM_5_2.0                      Rank: 2     Keep: False\n",
      "Feature: BBU_5_2.0                      Rank: 57    Keep: False\n",
      "Feature: BBB_5_2.0                      Rank: 44    Keep: False\n",
      "Feature: BBP_5_2.0                      Rank: 63    Keep: False\n",
      "Feature: BIAS_SMA_26                    Rank: 1     Keep: True\n",
      "Feature: BOP                            Rank: 148   Keep: False\n",
      "Feature: AR_26                          Rank: 38    Keep: False\n",
      "Feature: BR_26                          Rank: 4     Keep: False\n",
      "Feature: CCI_14_0.015                   Rank: 35    Keep: False\n",
      "Feature: CDL_2CROWS                     Rank: 218   Keep: False\n",
      "Feature: CDL_3BLACKCROWS                Rank: 218   Keep: False\n",
      "Feature: CDL_3INSIDE                    Rank: 195   Keep: False\n",
      "Feature: CDL_3LINESTRIKE                Rank: 218   Keep: False\n",
      "Feature: CDL_3OUTSIDE                   Rank: 190   Keep: False\n",
      "Feature: CDL_3STARSINSOUTH              Rank: 218   Keep: False\n",
      "Feature: CDL_3WHITESOLDIERS             Rank: 218   Keep: False\n",
      "Feature: CDL_ABANDONEDBABY              Rank: 218   Keep: False\n",
      "Feature: CDL_ADVANCEBLOCK               Rank: 195   Keep: False\n",
      "Feature: CDL_BELTHOLD                   Rank: 165   Keep: False\n",
      "Feature: CDL_BREAKAWAY                  Rank: 218   Keep: False\n",
      "Feature: CDL_CLOSINGMARUBOZU            Rank: 158   Keep: False\n",
      "Feature: CDL_CONCEALBABYSWALL           Rank: 218   Keep: False\n",
      "Feature: CDL_COUNTERATTACK              Rank: 218   Keep: False\n",
      "Feature: CDL_DARKCLOUDCOVER             Rank: 218   Keep: False\n",
      "Feature: CDL_DOJI_10_0.1                Rank: 176   Keep: False\n",
      "Feature: CDL_DOJISTAR                   Rank: 195   Keep: False\n",
      "Feature: CDL_DRAGONFLYDOJI              Rank: 195   Keep: False\n",
      "Feature: CDL_ENGULFING                  Rank: 161   Keep: False\n",
      "Feature: CDL_EVENINGDOJISTAR            Rank: 218   Keep: False\n",
      "Feature: CDL_EVENINGSTAR                Rank: 218   Keep: False\n",
      "Feature: CDL_GAPSIDESIDEWHITE           Rank: 218   Keep: False\n",
      "Feature: CDL_GRAVESTONEDOJI             Rank: 195   Keep: False\n",
      "Feature: CDL_HAMMER                     Rank: 169   Keep: False\n",
      "Feature: CDL_HANGINGMAN                 Rank: 188   Keep: False\n",
      "Feature: CDL_HARAMI                     Rank: 167   Keep: False\n",
      "Feature: CDL_HARAMICROSS                Rank: 180   Keep: False\n",
      "Feature: CDL_HIGHWAVE                   Rank: 163   Keep: False\n",
      "Feature: CDL_HIKKAKE                    Rank: 166   Keep: False\n",
      "Feature: CDL_HIKKAKEMOD                 Rank: 218   Keep: False\n",
      "Feature: CDL_HOMINGPIGEON               Rank: 218   Keep: False\n",
      "Feature: CDL_IDENTICAL3CROWS            Rank: 218   Keep: False\n",
      "Feature: CDL_INNECK                     Rank: 218   Keep: False\n",
      "Feature: CDL_INSIDE                     Rank: 186   Keep: False\n",
      "Feature: CDL_INVERTEDHAMMER             Rank: 218   Keep: False\n",
      "Feature: CDL_KICKING                    Rank: 218   Keep: False\n",
      "Feature: CDL_KICKINGBYLENGTH            Rank: 218   Keep: False\n",
      "Feature: CDL_LADDERBOTTOM               Rank: 218   Keep: False\n",
      "Feature: CDL_LONGLEGGEDDOJI             Rank: 174   Keep: False\n",
      "Feature: CDL_LONGLINE                   Rank: 171   Keep: False\n",
      "Feature: CDL_MARUBOZU                   Rank: 191   Keep: False\n",
      "Feature: CDL_MATCHINGLOW                Rank: 184   Keep: False\n",
      "Feature: CDL_MATHOLD                    Rank: 218   Keep: False\n",
      "Feature: CDL_MORNINGDOJISTAR            Rank: 218   Keep: False\n",
      "Feature: CDL_MORNINGSTAR                Rank: 195   Keep: False\n",
      "Feature: CDL_ONNECK                     Rank: 218   Keep: False\n",
      "Feature: CDL_PIERCING                   Rank: 218   Keep: False\n",
      "Feature: CDL_RICKSHAWMAN                Rank: 187   Keep: False\n",
      "Feature: CDL_RISEFALL3METHODS           Rank: 218   Keep: False\n",
      "Feature: CDL_SEPARATINGLINES            Rank: 195   Keep: False\n",
      "Feature: CDL_SHOOTINGSTAR               Rank: 195   Keep: False\n",
      "Feature: CDL_SHORTLINE                  Rank: 177   Keep: False\n",
      "Feature: CDL_SPINNINGTOP                Rank: 168   Keep: False\n",
      "Feature: CDL_STALLEDPATTERN             Rank: 218   Keep: False\n",
      "Feature: CDL_STICKSANDWICH              Rank: 218   Keep: False\n",
      "Feature: CDL_TAKURI                     Rank: 188   Keep: False\n",
      "Feature: CDL_TASUKIGAP                  Rank: 218   Keep: False\n",
      "Feature: CDL_THRUSTING                  Rank: 218   Keep: False\n",
      "Feature: CDL_TRISTAR                    Rank: 218   Keep: False\n",
      "Feature: CDL_UNIQUE3RIVER               Rank: 218   Keep: False\n",
      "Feature: CDL_UPSIDEGAP2CROWS            Rank: 218   Keep: False\n",
      "Feature: CDL_XSIDEGAP3METHODS           Rank: 182   Keep: False\n",
      "Feature: open_Z_30_1                    Rank: 1     Keep: True\n",
      "Feature: high_Z_30_1                    Rank: 1     Keep: True\n",
      "Feature: low_Z_30_1                     Rank: 1     Keep: True\n",
      "Feature: close_Z_30_1                   Rank: 1     Keep: True\n",
      "Feature: CFO_9                          Rank: 141   Keep: False\n",
      "Feature: CG_10                          Rank: 43    Keep: False\n",
      "Feature: CHDLREXTl_22_22_14_2.0         Rank: 40    Keep: False\n",
      "Feature: CHDLREXTs_22_22_14_2.0         Rank: 99    Keep: False\n",
      "Feature: CHDLREXTd_22_22_14_2.0         Rank: 154   Keep: False\n",
      "Feature: CHOP_14_1_100.0                Rank: 24    Keep: False\n",
      "Feature: CKSPl_10_3_20                  Rank: 136   Keep: False\n",
      "Feature: CKSPs_10_3_20                  Rank: 93    Keep: False\n",
      "Feature: CMF_20                         Rank: 1     Keep: True\n",
      "Feature: CMO_14                         Rank: 10    Keep: False\n",
      "Feature: COPC_11_14_10                  Rank: 10    Keep: False\n",
      "Feature: CRSI_3_2_100                   Rank: 100   Keep: False\n",
      "Feature: CTI_12                         Rank: 22    Keep: False\n",
      "Feature: CUBE_3.0_-1                    Rank: 139   Keep: False\n",
      "Feature: CUBEs_3.0_-1                   Rank: 129   Keep: False\n",
      "Feature: LDECAY_1                       Rank: 108   Keep: False\n",
      "Feature: DEC_1                          Rank: 159   Keep: False\n",
      "Feature: DEMA_10                        Rank: 95    Keep: False\n",
      "Feature: DCL_20_20                      Rank: 76    Keep: False\n",
      "Feature: DCM_20_20                      Rank: 134   Keep: False\n",
      "Feature: DCU_20_20                      Rank: 128   Keep: False\n",
      "Feature: DPO_20                         Rank: 1     Keep: True\n",
      "Feature: EBSW_40_10                     Rank: 2     Keep: False\n",
      "Feature: EFI_13                         Rank: 1     Keep: True\n",
      "Feature: EMA_10                         Rank: 109   Keep: False\n",
      "Feature: ENTP_10                        Rank: 2     Keep: False\n",
      "Feature: EOM_14_100000000               Rank: 126   Keep: False\n",
      "Feature: ER_10                          Rank: 121   Keep: False\n",
      "Feature: BULLP_13                       Rank: 1     Keep: True\n",
      "Feature: BEARP_13                       Rank: 20    Keep: False\n",
      "Feature: EXHC_DNa                       Rank: 150   Keep: False\n",
      "Feature: EXHC_UPa                       Rank: 143   Keep: False\n",
      "Feature: FISHERT_9_1                    Rank: 1     Keep: True\n",
      "Feature: FISHERTs_9_1                   Rank: 1     Keep: True\n",
      "Feature: FWMA_10                        Rank: 28    Keep: False\n",
      "Feature: HA_open                        Rank: 107   Keep: False\n",
      "Feature: HA_high                        Rank: 26    Keep: False\n",
      "Feature: HA_low                         Rank: 89    Keep: False\n",
      "Feature: HA_close                       Rank: 39    Keep: False\n",
      "Feature: HILO_13_21                     Rank: 129   Keep: False\n",
      "Feature: HL2                            Rank: 1     Keep: True\n",
      "Feature: HLC3                           Rank: 1     Keep: True\n",
      "Feature: HMA_10                         Rank: 27    Keep: False\n",
      "Feature: HT_TL                          Rank: 118   Keep: False\n",
      "Feature: HWM_1                          Rank: 57    Keep: False\n",
      "Feature: HWU_1                          Rank: 37    Keep: False\n",
      "Feature: HWL_1                          Rank: 1     Keep: True\n",
      "Feature: HWMA_0.2_0.1_0.1               Rank: 113   Keep: False\n",
      "Feature: ISA_9                          Rank: 8     Keep: False\n",
      "Feature: ISB_26                         Rank: 60    Keep: False\n",
      "Feature: ITS_9                          Rank: 119   Keep: False\n",
      "Feature: IKS_26                         Rank: 123   Keep: False\n",
      "Feature: ICS_26                         Rank: 1     Keep: True\n",
      "Feature: INVFISHER_1.0                  Rank: 103   Keep: False\n",
      "Feature: INVFISHERs_1.0                 Rank: 133   Keep: False\n",
      "Feature: INC_1                          Rank: 173   Keep: False\n",
      "Feature: INERTIA_20_14                  Rank: 1     Keep: True\n",
      "Feature: JMA_7_0.0                      Rank: 1     Keep: True\n",
      "Feature: KAMA_10_2_30                   Rank: 51    Keep: False\n",
      "Feature: KCLe_20_2                      Rank: 71    Keep: False\n",
      "Feature: KCBe_20_2                      Rank: 74    Keep: False\n",
      "Feature: KCUe_20_2                      Rank: 7     Keep: False\n",
      "Feature: K_9_3                          Rank: 1     Keep: True\n",
      "Feature: D_9_3                          Rank: 1     Keep: True\n",
      "Feature: J_9_3                          Rank: 1     Keep: True\n",
      "Feature: KST_10_15_20_30_10_10_10_15    Rank: 12    Keep: False\n",
      "Feature: KSTs_9                         Rank: 2     Keep: False\n",
      "Feature: KURT_30                        Rank: 13    Keep: False\n",
      "Feature: KVO_34_55_13                   Rank: 1     Keep: True\n",
      "Feature: KVOs_34_55_13                  Rank: 1     Keep: True\n",
      "Feature: LINREG_14                      Rank: 41    Keep: False\n",
      "Feature: LOGRET_1                       Rank: 141   Keep: False\n",
      "Feature: MACD_12_26_9                   Rank: 1     Keep: True\n",
      "Feature: MACDh_12_26_9                  Rank: 51    Keep: False\n",
      "Feature: MACDs_12_26_9                  Rank: 5     Keep: False\n",
      "Feature: MAD_30                         Rank: 92    Keep: False\n",
      "Feature: MAMA_0.5_0.05                  Rank: 55    Keep: False\n",
      "Feature: FAMA_0.5_0.05                  Rank: 97    Keep: False\n",
      "Feature: MASSI_9_25                     Rank: 2     Keep: False\n",
      "Feature: MCGD_10                        Rank: 78    Keep: False\n",
      "Feature: MEDIAN_30                      Rank: 1     Keep: True\n",
      "Feature: MFI_14                         Rank: 1     Keep: True\n",
      "Feature: MIDPOINT_2                     Rank: 60    Keep: False\n",
      "Feature: MIDPRICE_2                     Rank: 49    Keep: False\n",
      "Feature: MOM_10                         Rank: 53    Keep: False\n",
      "Feature: NATR_14                        Rank: 19    Keep: False\n",
      "Feature: NVI_1                          Rank: 1     Keep: True\n",
      "Feature: OHLC4                          Rank: 65    Keep: False\n",
      "Feature: PDIST                          Rank: 125   Keep: False\n",
      "Feature: PCTRET_1                       Rank: 131   Keep: False\n",
      "Feature: PGO_14                         Rank: 1     Keep: True\n",
      "Feature: PIVOTS_TRAD_D_P                Rank: 111   Keep: False\n",
      "Feature: PIVOTS_TRAD_D_S1               Rank: 103   Keep: False\n",
      "Feature: PIVOTS_TRAD_D_S2               Rank: 2     Keep: False\n",
      "Feature: PIVOTS_TRAD_D_S3               Rank: 2     Keep: False\n",
      "Feature: PIVOTS_TRAD_D_S4               Rank: 2     Keep: False\n",
      "Feature: PIVOTS_TRAD_D_R1               Rank: 2     Keep: False\n",
      "Feature: PIVOTS_TRAD_D_R2               Rank: 33    Keep: False\n",
      "Feature: PIVOTS_TRAD_D_R3               Rank: 59    Keep: False\n",
      "Feature: PIVOTS_TRAD_D_R4               Rank: 30    Keep: False\n",
      "Feature: PPO_12_26_9                    Rank: 115   Keep: False\n",
      "Feature: PPOh_12_26_9                   Rank: 84    Keep: False\n",
      "Feature: PPOs_12_26_9                   Rank: 50    Keep: False\n",
      "Feature: PSARr_0.02_0.2                 Rank: 178   Keep: False\n",
      "Feature: PSL_12                         Rank: 145   Keep: False\n",
      "Feature: PVI                            Rank: 144   Keep: False\n",
      "Feature: PVIe_255                       Rank: 1     Keep: True\n",
      "Feature: PVO_12_26_9                    Rank: 15    Keep: False\n",
      "Feature: PVOh_12_26_9                   Rank: 105   Keep: False\n",
      "Feature: PVOs_12_26_9                   Rank: 1     Keep: True\n",
      "Feature: PVOL                           Rank: 137   Keep: False\n",
      "Feature: PVR                            Rank: 156   Keep: False\n",
      "Feature: PVT                            Rank: 1     Keep: True\n",
      "Feature: PWMA_10                        Rank: 62    Keep: False\n",
      "Feature: QQE_14_5_4.236                 Rank: 1     Keep: True\n",
      "Feature: QQE_14_5_4.236_RSIMA           Rank: 2     Keep: False\n",
      "Feature: QS_10                          Rank: 20    Keep: False\n",
      "Feature: QTL_30_0.5                     Rank: 46    Keep: False\n",
      "Feature: REFLEX_20_20_0.04              Rank: 2     Keep: False\n",
      "Feature: REMAP_0.0_100.0_-1.0_1.0       Rank: 1     Keep: True\n",
      "Feature: RMA_10                         Rank: 77    Keep: False\n",
      "Feature: ROC_10                         Rank: 34    Keep: False\n",
      "Feature: RSI_14                         Rank: 1     Keep: True\n",
      "Feature: RSX_14                         Rank: 1     Keep: True\n",
      "Feature: RVGI_14_4                      Rank: 1     Keep: True\n",
      "Feature: RVGIs_14_4                     Rank: 65    Keep: False\n",
      "Feature: RVI_14                         Rank: 75    Keep: False\n",
      "Feature: RWIh_14                        Rank: 71    Keep: False\n",
      "Feature: RWIl_14                        Rank: 67    Keep: False\n",
      "Feature: SINWMA_14                      Rank: 1     Keep: True\n",
      "Feature: SKEW_30                        Rank: 1     Keep: True\n",
      "Feature: SLOPE_1                        Rank: 147   Keep: False\n",
      "Feature: SMA_10                         Rank: 114   Keep: False\n",
      "Feature: SMChv_14_50_20_5               Rank: 170   Keep: False\n",
      "Feature: SMCbf_14_50_20_5               Rank: 163   Keep: False\n",
      "Feature: SMCbi_14_50_20_5               Rank: 127   Keep: False\n",
      "Feature: SMCbp_14_50_20_5               Rank: 5     Keep: False\n",
      "Feature: SMCtf_14_50_20_5               Rank: 179   Keep: False\n",
      "Feature: SMCti_14_50_20_5               Rank: 115   Keep: False\n",
      "Feature: SMCtp_14_50_20_5               Rank: 95    Keep: False\n",
      "Feature: SMI_5_20_5_1.0                 Rank: 67    Keep: False\n",
      "Feature: SMIs_5_20_5_1.0                Rank: 3     Keep: False\n",
      "Feature: SMIo_5_20_5_1.0                Rank: 1     Keep: True\n",
      "Feature: SMMA_7                         Rank: 87    Keep: False\n",
      "Feature: SQZ_20_2.0_20_1.5              Rank: 31    Keep: False\n",
      "Feature: SQZ_ON                         Rank: 155   Keep: False\n",
      "Feature: SQZ_OFF                        Rank: 183   Keep: False\n",
      "Feature: SQZ_NO                         Rank: 218   Keep: False\n",
      "Feature: SQZPRO_20_2.0_20_2.0_1.5_1.0   Rank: 87    Keep: False\n",
      "Feature: SQZPRO_ON_WIDE                 Rank: 145   Keep: False\n",
      "Feature: SQZPRO_ON_NORMAL               Rank: 175   Keep: False\n",
      "Feature: SQZPRO_ON_NARROW               Rank: 163   Keep: False\n",
      "Feature: SQZPRO_OFF                     Rank: 122   Keep: False\n",
      "Feature: SQZPRO_NO                      Rank: 218   Keep: False\n",
      "Feature: SSF_20                         Rank: 1     Keep: True\n",
      "Feature: SSF3_20                        Rank: 69    Keep: False\n",
      "Feature: STC_10_12_26_0.5               Rank: 2     Keep: False\n",
      "Feature: STCmacd_10_12_26_0.5           Rank: 2     Keep: False\n",
      "Feature: STCstoch_10_12_26_0.5          Rank: 14    Keep: False\n",
      "Feature: STDEV_30                       Rank: 17    Keep: False\n",
      "Feature: STOCHk_14_3_3                  Rank: 1     Keep: True\n",
      "Feature: STOCHd_14_3_3                  Rank: 1     Keep: True\n",
      "Feature: STOCHh_14_3_3                  Rank: 44    Keep: False\n",
      "Feature: STOCHFk_14_3                   Rank: 29    Keep: False\n",
      "Feature: STOCHFd_14_3                   Rank: 1     Keep: True\n",
      "Feature: STOCHRSIk_14_14_3_3            Rank: 102   Keep: False\n",
      "Feature: STOCHRSId_14_14_3_3            Rank: 124   Keep: False\n",
      "Feature: SUPERT_7_3.0                   Rank: 73    Keep: False\n",
      "Feature: SUPERTd_7_3.0                  Rank: 171   Keep: False\n",
      "Feature: SWMA_10                        Rank: 69    Keep: False\n",
      "Feature: T3_10_0.7                      Rank: 1     Keep: True\n",
      "Feature: TEMA_10                        Rank: 41    Keep: False\n",
      "Feature: THERMO_20_2_0.5                Rank: 139   Keep: False\n",
      "Feature: THERMOma_20_2_0.5              Rank: 1     Keep: True\n",
      "Feature: THERMOl_20_2_0.5               Rank: 185   Keep: False\n",
      "Feature: THERMOs_20_2_0.5               Rank: 180   Keep: False\n",
      "Feature: TMO_14_5_3                     Rank: 1     Keep: True\n",
      "Feature: TMOs_14_5_3                    Rank: 1     Keep: True\n",
      "Feature: TMOM_14_5_3                    Rank: 218   Keep: False\n",
      "Feature: TMOMs_14_5_3                   Rank: 218   Keep: False\n",
      "Feature: TOS_STDEVALL_LR                Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_L_1               Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_U_1               Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_L_2               Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_U_2               Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_L_3               Rank: 1     Keep: True\n",
      "Feature: TOS_STDEVALL_U_3               Rank: 1     Keep: True\n",
      "Feature: TRENDFLEX_20_20_0.04           Rank: 1     Keep: True\n",
      "Feature: TRIMA_10                       Rank: 47    Keep: False\n",
      "Feature: TRIX_30_9                      Rank: 1     Keep: True\n",
      "Feature: TRIXs_30_9                     Rank: 1     Keep: True\n",
      "Feature: TRUERANGE_1                    Rank: 90    Keep: False\n",
      "Feature: TSI_13_25_13                   Rank: 1     Keep: True\n",
      "Feature: TSIs_13_25_13                  Rank: 1     Keep: True\n",
      "Feature: UI_14                          Rank: 1     Keep: True\n",
      "Feature: UO_7_14_28                     Rank: 1     Keep: True\n",
      "Feature: VAR_30                         Rank: 9     Keep: False\n",
      "Feature: VHF_28                         Rank: 1     Keep: True\n",
      "Feature: VHM_610                        Rank: 2     Keep: False\n",
      "Feature: VTXP_14                        Rank: 1     Keep: True\n",
      "Feature: VTXM_14                        Rank: 55    Keep: False\n",
      "Feature: VWAP_D                         Rank: 1     Keep: True\n",
      "Feature: VWMA_10                        Rank: 35    Keep: False\n",
      "Feature: TSV_18_10                      Rank: 1     Keep: True\n",
      "Feature: TSVs_18_10                     Rank: 1     Keep: True\n",
      "Feature: TSVr_18_10                     Rank: 2     Keep: False\n",
      "Feature: WCP                            Rank: 17    Keep: False\n",
      "Feature: WILLR_14                       Rank: 1     Keep: True\n",
      "Feature: WMA_10                         Rank: 65    Keep: False\n",
      "Feature: ZIGZAGs_5.0%_10                Rank: 79    Keep: False\n",
      "Feature: ZIGZAGv_5.0%_10                Rank: 1     Keep: True\n",
      "Feature: ZIGZAGd_5.0%_10                Rank: 98    Keep: False\n",
      "Feature: ZL_EMA_10                      Rank: 32    Keep: False\n",
      "Feature: ZS_30                          Rank: 1     Keep: True\n"
     ]
    }
   ],
   "source": [
    "# zip my names, ranks, and decisions in a single iterable\n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# iterate through and print out the results\n",
    "for feat in feature_ranks:\n",
    "    print(f'Feature: {feat[0]:<30} Rank: {feat[1]:<5} Keep: {feat[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b67945cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Close</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ACCBU_20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DMP_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AO_5_34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OBV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OBV_min_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OBV_max_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OBVe_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>OBVe_12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BIAS_SMA_26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>open_Z_30_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>high_Z_30_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>low_Z_30_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>close_Z_30_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>CMF_20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>DPO_20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>EFI_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>BULLP_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>FISHERT_9_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>FISHERTs_9_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>HL2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>HLC3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>HWL_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ICS_26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>INERTIA_20_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>JMA_7_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>K_9_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>D_9_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>J_9_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>KVO_34_55_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>KVOs_34_55_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>MACD_12_26_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>MEDIAN_30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>MFI_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>NVI_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>PGO_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>PVIe_255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>PVOs_12_26_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>PVT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>QQE_14_5_4.236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>REMAP_0.0_100.0_-1.0_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>RSI_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>RSX_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>RVGI_14_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>SINWMA_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>SKEW_30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>SMIo_5_20_5_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>SSF_20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>STOCHk_14_3_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>STOCHd_14_3_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>STOCHFd_14_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>T3_10_0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>THERMOma_20_2_0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>TMO_14_5_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>TMOs_14_5_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>TOS_STDEVALL_LR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>TOS_STDEVALL_L_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>TOS_STDEVALL_U_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>TOS_STDEVALL_L_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>TOS_STDEVALL_U_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>TOS_STDEVALL_L_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>TOS_STDEVALL_U_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>TRENDFLEX_20_20_0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>TRIX_30_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>TRIXs_30_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>TSI_13_25_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TSIs_13_25_13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>UI_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>UO_7_14_28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>VHF_28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>VTXP_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>VWAP_D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>TSV_18_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>TSVs_18_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>WILLR_14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>ZIGZAGv_5.0%_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>ZS_30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Ranking\n",
       "0                       Close        1\n",
       "11                   ACCBU_20        1\n",
       "12                         AD        1\n",
       "16                     DMP_14        1\n",
       "26                    AO_5_34        1\n",
       "27                        OBV        1\n",
       "28                  OBV_min_2        1\n",
       "29                  OBV_max_2        1\n",
       "30                     OBVe_4        1\n",
       "31                    OBVe_12        1\n",
       "45                BIAS_SMA_26        1\n",
       "112               open_Z_30_1        1\n",
       "113               high_Z_30_1        1\n",
       "114                low_Z_30_1        1\n",
       "115              close_Z_30_1        1\n",
       "124                    CMF_20        1\n",
       "137                    DPO_20        1\n",
       "139                    EFI_13        1\n",
       "144                  BULLP_13        1\n",
       "148               FISHERT_9_1        1\n",
       "149              FISHERTs_9_1        1\n",
       "156                       HL2        1\n",
       "157                      HLC3        1\n",
       "162                     HWL_1        1\n",
       "168                    ICS_26        1\n",
       "172             INERTIA_20_14        1\n",
       "173                 JMA_7_0.0        1\n",
       "178                     K_9_3        1\n",
       "179                     D_9_3        1\n",
       "180                     J_9_3        1\n",
       "184              KVO_34_55_13        1\n",
       "185             KVOs_34_55_13        1\n",
       "188              MACD_12_26_9        1\n",
       "196                 MEDIAN_30        1\n",
       "197                    MFI_14        1\n",
       "202                     NVI_1        1\n",
       "206                    PGO_14        1\n",
       "222                  PVIe_255        1\n",
       "225              PVOs_12_26_9        1\n",
       "228                       PVT        1\n",
       "230            QQE_14_5_4.236        1\n",
       "235  REMAP_0.0_100.0_-1.0_1.0        1\n",
       "238                    RSI_14        1\n",
       "239                    RSX_14        1\n",
       "240                 RVGI_14_4        1\n",
       "245                 SINWMA_14        1\n",
       "246                   SKEW_30        1\n",
       "258           SMIo_5_20_5_1.0        1\n",
       "270                    SSF_20        1\n",
       "276             STOCHk_14_3_3        1\n",
       "277             STOCHd_14_3_3        1\n",
       "280              STOCHFd_14_3        1\n",
       "286                 T3_10_0.7        1\n",
       "289         THERMOma_20_2_0.5        1\n",
       "292                TMO_14_5_3        1\n",
       "293               TMOs_14_5_3        1\n",
       "296           TOS_STDEVALL_LR        1\n",
       "297          TOS_STDEVALL_L_1        1\n",
       "298          TOS_STDEVALL_U_1        1\n",
       "299          TOS_STDEVALL_L_2        1\n",
       "300          TOS_STDEVALL_U_2        1\n",
       "301          TOS_STDEVALL_L_3        1\n",
       "302          TOS_STDEVALL_U_3        1\n",
       "303      TRENDFLEX_20_20_0.04        1\n",
       "305                 TRIX_30_9        1\n",
       "306                TRIXs_30_9        1\n",
       "308              TSI_13_25_13        1\n",
       "309             TSIs_13_25_13        1\n",
       "310                     UI_14        1\n",
       "311                UO_7_14_28        1\n",
       "313                    VHF_28        1\n",
       "315                   VTXP_14        1\n",
       "317                    VWAP_D        1\n",
       "319                 TSV_18_10        1\n",
       "320                TSVs_18_10        1\n",
       "323                  WILLR_14        1\n",
       "326           ZIGZAGv_5.0%_10        1\n",
       "329                     ZS_30        1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_rf_features = pd.DataFrame({'Feature':feature_names,\n",
    "                                     'Ranking':feat_selector.ranking_})\n",
    "\n",
    "# selected_rf_features#.sort_values(by='Ranking') \n",
    "\n",
    "selected_rf_features[selected_rf_features['Ranking']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0547f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=selected_rf_features[selected_rf_features['Ranking']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91b8c9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8582, 78)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape \n",
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538f1c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_estimators=278, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x278A5423E40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_estimators=278, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x278A5423E40)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9292027876933537,\n",
       "                                     1: 1.1282765737874096},\n",
       "                       max_depth=5, n_estimators=278, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x278A5423E40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit with selected features\n",
    "forest.fit(X_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "941bcc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.00750000e+03,  6.01424149e+03,  2.73681949e+07, ...,\n",
       "        -1.89655172e+01,  6.00472374e+03,  1.27708205e+00],\n",
       "       [ 6.00500000e+03,  6.01574116e+03,  2.73672797e+07, ...,\n",
       "        -2.90909091e+01,  6.00541034e+03,  1.07586006e+00],\n",
       "       [ 6.00850000e+03,  6.01786633e+03,  2.73701054e+07, ...,\n",
       "        -1.63636364e+01,  6.00697209e+03,  1.19799641e+00],\n",
       "       ...,\n",
       "       [ 5.62450000e+03,  5.74820234e+03,  3.02733928e+07, ...,\n",
       "        -9.44444444e+01,  5.62091138e+03, -2.16965323e+00],\n",
       "       [ 5.60250000e+03,  5.74328034e+03,  3.01898239e+07, ...,\n",
       "        -9.98181818e+01,  5.61220022e+03, -2.34215925e+00],\n",
       "       [ 5.59425000e+03,  5.73745849e+03,  3.01991391e+07, ...,\n",
       "        -9.12225705e+01,  5.60230018e+03, -2.24945644e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first apply feature selector transform to make sure same features are selected\n",
    "X_test_filtered = feat_selector.transform(X_test)\n",
    "X_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06522bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 78)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape\n",
    "X_test_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e62c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels with unseen dataset\n",
    "prediction = forest.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34fa49c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score \t\t 0.7050326188257223\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Accuracy Score \\t\\t\", accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a9fb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1138\n",
      "           1       0.77      0.53      0.63      1008\n",
      "\n",
      "    accuracy                           0.71      2146\n",
      "   macro avg       0.72      0.70      0.69      2146\n",
      "weighted avg       0.72      0.71      0.70      2146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6d2f650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc\n",
    "RocCurveDisplay.from_estimator(forest, X_test_filtered, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ecd79b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(forest, X_test_filtered, y_test, cmap='Blues', values_format='.4g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d418839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>VTXP_14</th>\n",
       "      <th>VTXM_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>VWMA_10</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>TSVr_18_10</th>\n",
       "      <th>WCP</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>ZIGZAGs_5.0%_10</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZIGZAGd_5.0%_10</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-11 19:00:00+00:00</th>\n",
       "      <td>4144.00</td>\n",
       "      <td>4145.50</td>\n",
       "      <td>4136.50</td>\n",
       "      <td>4144.50</td>\n",
       "      <td>177477.0</td>\n",
       "      <td>4139.066667</td>\n",
       "      <td>4150.536503</td>\n",
       "      <td>4127.596830</td>\n",
       "      <td>11.469837</td>\n",
       "      <td>4127.519138</td>\n",
       "      <td>4151.7375</td>\n",
       "      <td>4176.644138</td>\n",
       "      <td>1.391047e+05</td>\n",
       "      <td>133049.775078</td>\n",
       "      <td>23.121759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>1.105339</td>\n",
       "      <td>4139.411662</td>\n",
       "      <td>4137.969551</td>\n",
       "      <td>-2076637.00</td>\n",
       "      <td>-5.570004e+05</td>\n",
       "      <td>3.728251</td>\n",
       "      <td>4142.5000</td>\n",
       "      <td>-52.127660</td>\n",
       "      <td>4140.572727</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>-0.424334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 20:00:00+00:00</th>\n",
       "      <td>4145.25</td>\n",
       "      <td>4145.75</td>\n",
       "      <td>4141.25</td>\n",
       "      <td>4144.00</td>\n",
       "      <td>62096.0</td>\n",
       "      <td>4140.300000</td>\n",
       "      <td>4151.305181</td>\n",
       "      <td>4129.294819</td>\n",
       "      <td>11.005181</td>\n",
       "      <td>4126.893913</td>\n",
       "      <td>4150.9125</td>\n",
       "      <td>4175.581413</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>153792.518856</td>\n",
       "      <td>22.782025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909884</td>\n",
       "      <td>1.097384</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>4138.089410</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1.086842e+06</td>\n",
       "      <td>1.842487</td>\n",
       "      <td>4144.3750</td>\n",
       "      <td>-49.468085</td>\n",
       "      <td>4141.177273</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>-0.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 22:00:00+00:00</th>\n",
       "      <td>4148.75</td>\n",
       "      <td>4149.50</td>\n",
       "      <td>4143.75</td>\n",
       "      <td>4144.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4141.716667</td>\n",
       "      <td>4152.371502</td>\n",
       "      <td>4131.061831</td>\n",
       "      <td>10.654835</td>\n",
       "      <td>4126.106448</td>\n",
       "      <td>4150.3750</td>\n",
       "      <td>4174.856448</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>148297.048687</td>\n",
       "      <td>21.977115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920420</td>\n",
       "      <td>1.112613</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>4137.872708</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1.690910e+06</td>\n",
       "      <td>1.184269</td>\n",
       "      <td>4147.6875</td>\n",
       "      <td>-42.021277</td>\n",
       "      <td>4142.659091</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>-0.064860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 23:00:00+00:00</th>\n",
       "      <td>4146.00</td>\n",
       "      <td>4148.75</td>\n",
       "      <td>4146.00</td>\n",
       "      <td>4148.50</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>4144.250000</td>\n",
       "      <td>4154.377846</td>\n",
       "      <td>4134.122154</td>\n",
       "      <td>10.127846</td>\n",
       "      <td>4125.481448</td>\n",
       "      <td>4149.6625</td>\n",
       "      <td>4174.231448</td>\n",
       "      <td>1.844896e+05</td>\n",
       "      <td>131640.806465</td>\n",
       "      <td>21.229698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901840</td>\n",
       "      <td>1.119632</td>\n",
       "      <td>4139.630997</td>\n",
       "      <td>4137.302401</td>\n",
       "      <td>-2015179.75</td>\n",
       "      <td>-2.404742e+06</td>\n",
       "      <td>0.838002</td>\n",
       "      <td>4146.6875</td>\n",
       "      <td>-47.872340</td>\n",
       "      <td>4143.604545</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>-0.321340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12 00:00:00+00:00</th>\n",
       "      <td>4151.50</td>\n",
       "      <td>4152.00</td>\n",
       "      <td>4145.25</td>\n",
       "      <td>4145.75</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>4145.983333</td>\n",
       "      <td>4155.885990</td>\n",
       "      <td>4136.080677</td>\n",
       "      <td>9.902657</td>\n",
       "      <td>4124.269449</td>\n",
       "      <td>4149.2250</td>\n",
       "      <td>4174.206949</td>\n",
       "      <td>1.915830e+05</td>\n",
       "      <td>115116.524631</td>\n",
       "      <td>20.097679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901538</td>\n",
       "      <td>1.101538</td>\n",
       "      <td>4149.583333</td>\n",
       "      <td>4140.376301</td>\n",
       "      <td>-1973241.50</td>\n",
       "      <td>-2.286844e+06</td>\n",
       "      <td>0.862867</td>\n",
       "      <td>4150.0625</td>\n",
       "      <td>-32.960894</td>\n",
       "      <td>4145.577273</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>0.101855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 17:00:00+00:00</th>\n",
       "      <td>5630.75</td>\n",
       "      <td>5633.00</td>\n",
       "      <td>5618.75</td>\n",
       "      <td>5632.00</td>\n",
       "      <td>174057.0</td>\n",
       "      <td>5661.333333</td>\n",
       "      <td>5680.177744</td>\n",
       "      <td>5642.488923</td>\n",
       "      <td>18.844410</td>\n",
       "      <td>5676.998297</td>\n",
       "      <td>5713.6375</td>\n",
       "      <td>5757.060797</td>\n",
       "      <td>3.030610e+07</td>\n",
       "      <td>-289516.717266</td>\n",
       "      <td>41.091296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553522</td>\n",
       "      <td>1.405306</td>\n",
       "      <td>5672.262205</td>\n",
       "      <td>5661.292394</td>\n",
       "      <td>-24642615.50</td>\n",
       "      <td>-1.064921e+07</td>\n",
       "      <td>2.314032</td>\n",
       "      <td>5628.3125</td>\n",
       "      <td>-90.697674</td>\n",
       "      <td>5670.350000</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>-2.633574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 18:00:00+00:00</th>\n",
       "      <td>5628.75</td>\n",
       "      <td>5636.50</td>\n",
       "      <td>5619.75</td>\n",
       "      <td>5630.75</td>\n",
       "      <td>143085.0</td>\n",
       "      <td>5643.833333</td>\n",
       "      <td>5662.538116</td>\n",
       "      <td>5625.128550</td>\n",
       "      <td>18.704783</td>\n",
       "      <td>5669.975476</td>\n",
       "      <td>5708.0875</td>\n",
       "      <td>5752.725476</td>\n",
       "      <td>3.031678e+07</td>\n",
       "      <td>-242010.490013</td>\n",
       "      <td>42.999767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578440</td>\n",
       "      <td>1.375986</td>\n",
       "      <td>5667.881518</td>\n",
       "      <td>5656.732734</td>\n",
       "      <td>-24970470.50</td>\n",
       "      <td>-1.296109e+07</td>\n",
       "      <td>1.926573</td>\n",
       "      <td>5628.4375</td>\n",
       "      <td>-92.248062</td>\n",
       "      <td>5659.177273</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>-2.345638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 19:00:00+00:00</th>\n",
       "      <td>5624.50</td>\n",
       "      <td>5634.25</td>\n",
       "      <td>5617.25</td>\n",
       "      <td>5628.75</td>\n",
       "      <td>295029.0</td>\n",
       "      <td>5634.483333</td>\n",
       "      <td>5653.074464</td>\n",
       "      <td>5615.892202</td>\n",
       "      <td>18.591131</td>\n",
       "      <td>5663.452339</td>\n",
       "      <td>5702.5125</td>\n",
       "      <td>5748.202339</td>\n",
       "      <td>3.027339e+07</td>\n",
       "      <td>-214380.003569</td>\n",
       "      <td>44.818261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>1.375211</td>\n",
       "      <td>5660.624908</td>\n",
       "      <td>5650.222595</td>\n",
       "      <td>-26203976.75</td>\n",
       "      <td>-1.488171e+07</td>\n",
       "      <td>1.760817</td>\n",
       "      <td>5625.1250</td>\n",
       "      <td>-94.444444</td>\n",
       "      <td>5648.995455</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>-2.169653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 20:00:00+00:00</th>\n",
       "      <td>5602.50</td>\n",
       "      <td>5625.25</td>\n",
       "      <td>5602.25</td>\n",
       "      <td>5624.50</td>\n",
       "      <td>85426.0</td>\n",
       "      <td>5626.100000</td>\n",
       "      <td>5644.985055</td>\n",
       "      <td>5607.214945</td>\n",
       "      <td>18.885055</td>\n",
       "      <td>5656.280342</td>\n",
       "      <td>5695.5875</td>\n",
       "      <td>5743.280342</td>\n",
       "      <td>3.018982e+07</td>\n",
       "      <td>-210177.640213</td>\n",
       "      <td>46.766461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>1.406639</td>\n",
       "      <td>5658.242543</td>\n",
       "      <td>5647.042187</td>\n",
       "      <td>-28105848.75</td>\n",
       "      <td>-1.746749e+07</td>\n",
       "      <td>1.609038</td>\n",
       "      <td>5608.1250</td>\n",
       "      <td>-99.818182</td>\n",
       "      <td>5636.631818</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>-2.342159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30 22:00:00+00:00</th>\n",
       "      <td>5594.25</td>\n",
       "      <td>5600.00</td>\n",
       "      <td>5580.25</td>\n",
       "      <td>5590.00</td>\n",
       "      <td>22300.0</td>\n",
       "      <td>5616.533333</td>\n",
       "      <td>5635.642718</td>\n",
       "      <td>5597.423948</td>\n",
       "      <td>19.109385</td>\n",
       "      <td>5647.083490</td>\n",
       "      <td>5688.4000</td>\n",
       "      <td>5737.458490</td>\n",
       "      <td>3.019914e+07</td>\n",
       "      <td>-186387.509316</td>\n",
       "      <td>48.882431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572020</td>\n",
       "      <td>1.432119</td>\n",
       "      <td>5591.500000</td>\n",
       "      <td>5645.744790</td>\n",
       "      <td>-28299001.50</td>\n",
       "      <td>-2.028136e+07</td>\n",
       "      <td>1.395321</td>\n",
       "      <td>5592.1875</td>\n",
       "      <td>-91.222571</td>\n",
       "      <td>5625.177273</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>-2.249456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10728 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Close     High      Low     Open    Volume  \\\n",
       "Datetime                                                                  \n",
       "2023-05-11 19:00:00+00:00  4144.00  4145.50  4136.50  4144.50  177477.0   \n",
       "2023-05-11 20:00:00+00:00  4145.25  4145.75  4141.25  4144.00   62096.0   \n",
       "2023-05-11 22:00:00+00:00  4148.75  4149.50  4143.75  4144.50       0.0   \n",
       "2023-05-11 23:00:00+00:00  4146.00  4148.75  4146.00  4148.50    2912.0   \n",
       "2023-05-12 00:00:00+00:00  4151.50  4152.00  4145.25  4145.75    8327.0   \n",
       "...                            ...      ...      ...      ...       ...   \n",
       "2025-03-28 17:00:00+00:00  5630.75  5633.00  5618.75  5632.00  174057.0   \n",
       "2025-03-28 18:00:00+00:00  5628.75  5636.50  5619.75  5630.75  143085.0   \n",
       "2025-03-28 19:00:00+00:00  5624.50  5634.25  5617.25  5628.75  295029.0   \n",
       "2025-03-28 20:00:00+00:00  5602.50  5625.25  5602.25  5624.50   85426.0   \n",
       "2025-03-30 22:00:00+00:00  5594.25  5600.00  5580.25  5590.00   22300.0   \n",
       "\n",
       "                           ABER_ZG_5_15  ABER_SG_5_15  ABER_XG_5_15  \\\n",
       "Datetime                                                              \n",
       "2023-05-11 19:00:00+00:00   4139.066667   4150.536503   4127.596830   \n",
       "2023-05-11 20:00:00+00:00   4140.300000   4151.305181   4129.294819   \n",
       "2023-05-11 22:00:00+00:00   4141.716667   4152.371502   4131.061831   \n",
       "2023-05-11 23:00:00+00:00   4144.250000   4154.377846   4134.122154   \n",
       "2023-05-12 00:00:00+00:00   4145.983333   4155.885990   4136.080677   \n",
       "...                                 ...           ...           ...   \n",
       "2025-03-28 17:00:00+00:00   5661.333333   5680.177744   5642.488923   \n",
       "2025-03-28 18:00:00+00:00   5643.833333   5662.538116   5625.128550   \n",
       "2025-03-28 19:00:00+00:00   5634.483333   5653.074464   5615.892202   \n",
       "2025-03-28 20:00:00+00:00   5626.100000   5644.985055   5607.214945   \n",
       "2025-03-30 22:00:00+00:00   5616.533333   5635.642718   5597.423948   \n",
       "\n",
       "                           ABER_ATR_5_15     ACCBL_20   ACCBM_20     ACCBU_20  \\\n",
       "Datetime                                                                        \n",
       "2023-05-11 19:00:00+00:00      11.469837  4127.519138  4151.7375  4176.644138   \n",
       "2023-05-11 20:00:00+00:00      11.005181  4126.893913  4150.9125  4175.581413   \n",
       "2023-05-11 22:00:00+00:00      10.654835  4126.106448  4150.3750  4174.856448   \n",
       "2023-05-11 23:00:00+00:00      10.127846  4125.481448  4149.6625  4174.231448   \n",
       "2023-05-12 00:00:00+00:00       9.902657  4124.269449  4149.2250  4174.206949   \n",
       "...                                  ...          ...        ...          ...   \n",
       "2025-03-28 17:00:00+00:00      18.844410  5676.998297  5713.6375  5757.060797   \n",
       "2025-03-28 18:00:00+00:00      18.704783  5669.975476  5708.0875  5752.725476   \n",
       "2025-03-28 19:00:00+00:00      18.591131  5663.452339  5702.5125  5748.202339   \n",
       "2025-03-28 20:00:00+00:00      18.885055  5656.280342  5695.5875  5743.280342   \n",
       "2025-03-30 22:00:00+00:00      19.109385  5647.083490  5688.4000  5737.458490   \n",
       "\n",
       "                                     AD     ADOSC_3_10     ADX_14  ...  \\\n",
       "Datetime                                                           ...   \n",
       "2023-05-11 19:00:00+00:00  1.391047e+05  133049.775078  23.121759  ...   \n",
       "2023-05-11 20:00:00+00:00  1.874016e+05  153792.518856  22.782025  ...   \n",
       "2023-05-11 22:00:00+00:00  1.874016e+05  148297.048687  21.977115  ...   \n",
       "2023-05-11 23:00:00+00:00  1.844896e+05  131640.806465  21.229698  ...   \n",
       "2023-05-12 00:00:00+00:00  1.915830e+05  115116.524631  20.097679  ...   \n",
       "...                                 ...            ...        ...  ...   \n",
       "2025-03-28 17:00:00+00:00  3.030610e+07 -289516.717266  41.091296  ...   \n",
       "2025-03-28 18:00:00+00:00  3.031678e+07 -242010.490013  42.999767  ...   \n",
       "2025-03-28 19:00:00+00:00  3.027339e+07 -214380.003569  44.818261  ...   \n",
       "2025-03-28 20:00:00+00:00  3.018982e+07 -210177.640213  46.766461  ...   \n",
       "2025-03-30 22:00:00+00:00  3.019914e+07 -186387.509316  48.882431  ...   \n",
       "\n",
       "                            VTXP_14   VTXM_14       VWAP_D      VWMA_10  \\\n",
       "Datetime                                                                  \n",
       "2023-05-11 19:00:00+00:00  0.867244  1.105339  4139.411662  4137.969551   \n",
       "2023-05-11 20:00:00+00:00  0.909884  1.097384  4139.616049  4138.089410   \n",
       "2023-05-11 22:00:00+00:00  0.920420  1.112613  4139.616049  4137.872708   \n",
       "2023-05-11 23:00:00+00:00  0.901840  1.119632  4139.630997  4137.302401   \n",
       "2023-05-12 00:00:00+00:00  0.901538  1.101538  4149.583333  4140.376301   \n",
       "...                             ...       ...          ...          ...   \n",
       "2025-03-28 17:00:00+00:00  0.553522  1.405306  5672.262205  5661.292394   \n",
       "2025-03-28 18:00:00+00:00  0.578440  1.375986  5667.881518  5656.732734   \n",
       "2025-03-28 19:00:00+00:00  0.586847  1.375211  5660.624908  5650.222595   \n",
       "2025-03-28 20:00:00+00:00  0.577593  1.406639  5658.242543  5647.042187   \n",
       "2025-03-30 22:00:00+00:00  0.572020  1.432119  5591.500000  5645.744790   \n",
       "\n",
       "                             TSV_18_10    TSVs_18_10  TSVr_18_10        WCP  \\\n",
       "Datetime                                                                      \n",
       "2023-05-11 19:00:00+00:00  -2076637.00 -5.570004e+05    3.728251  4142.5000   \n",
       "2023-05-11 20:00:00+00:00  -2002493.25 -1.086842e+06    1.842487  4144.3750   \n",
       "2023-05-11 22:00:00+00:00  -2002493.25 -1.690910e+06    1.184269  4147.6875   \n",
       "2023-05-11 23:00:00+00:00  -2015179.75 -2.404742e+06    0.838002  4146.6875   \n",
       "2023-05-12 00:00:00+00:00  -1973241.50 -2.286844e+06    0.862867  4150.0625   \n",
       "...                                ...           ...         ...        ...   \n",
       "2025-03-28 17:00:00+00:00 -24642615.50 -1.064921e+07    2.314032  5628.3125   \n",
       "2025-03-28 18:00:00+00:00 -24970470.50 -1.296109e+07    1.926573  5628.4375   \n",
       "2025-03-28 19:00:00+00:00 -26203976.75 -1.488171e+07    1.760817  5625.1250   \n",
       "2025-03-28 20:00:00+00:00 -28105848.75 -1.746749e+07    1.609038  5608.1250   \n",
       "2025-03-30 22:00:00+00:00 -28299001.50 -2.028136e+07    1.395321  5592.1875   \n",
       "\n",
       "                            WILLR_14       WMA_10  ZIGZAGs_5.0%_10  \\\n",
       "Datetime                                                             \n",
       "2023-05-11 19:00:00+00:00 -52.127660  4140.572727      4141.476818   \n",
       "2023-05-11 20:00:00+00:00 -49.468085  4141.177273      4142.753760   \n",
       "2023-05-11 22:00:00+00:00 -42.021277  4142.659091      4146.298531   \n",
       "2023-05-11 23:00:00+00:00 -47.872340  4143.604545      4146.471526   \n",
       "2023-05-12 00:00:00+00:00 -32.960894  4145.577273      4148.749430   \n",
       "...                              ...          ...              ...   \n",
       "2025-03-28 17:00:00+00:00 -90.697674  5670.350000      5630.046629   \n",
       "2025-03-28 18:00:00+00:00 -92.248062  5659.177273      5624.947242   \n",
       "2025-03-28 19:00:00+00:00 -94.444444  5648.995455      5620.911379   \n",
       "2025-03-28 20:00:00+00:00 -99.818182  5636.631818      5612.200220   \n",
       "2025-03-30 22:00:00+00:00 -91.222571  5625.177273      5602.300180   \n",
       "\n",
       "                           ZIGZAGv_5.0%_10  ZIGZAGd_5.0%_10    ZL_EMA_10  \\\n",
       "Datetime                                                                   \n",
       "2023-05-11 19:00:00+00:00      4141.476818      4141.476818  4141.476818   \n",
       "2023-05-11 20:00:00+00:00      4142.753760      4142.753760  4142.753760   \n",
       "2023-05-11 22:00:00+00:00      4146.298531      4146.298531  4146.298531   \n",
       "2023-05-11 23:00:00+00:00      4146.471526      4146.471526  4146.471526   \n",
       "2023-05-12 00:00:00+00:00      4148.749430      4148.749430  4148.749430   \n",
       "...                                    ...              ...          ...   \n",
       "2025-03-28 17:00:00+00:00      5630.046629      5630.046629  5630.046629   \n",
       "2025-03-28 18:00:00+00:00      5624.947242      5624.947242  5624.947242   \n",
       "2025-03-28 19:00:00+00:00      5620.911379      5620.911379  5620.911379   \n",
       "2025-03-28 20:00:00+00:00      5612.200220      5612.200220  5612.200220   \n",
       "2025-03-30 22:00:00+00:00      5602.300180      5602.300180  5602.300180   \n",
       "\n",
       "                              ZS_30  \n",
       "Datetime                             \n",
       "2023-05-11 19:00:00+00:00 -0.424334  \n",
       "2023-05-11 20:00:00+00:00 -0.310070  \n",
       "2023-05-11 22:00:00+00:00 -0.064860  \n",
       "2023-05-11 23:00:00+00:00 -0.321340  \n",
       "2023-05-12 00:00:00+00:00  0.101855  \n",
       "...                             ...  \n",
       "2025-03-28 17:00:00+00:00 -2.633574  \n",
       "2025-03-28 18:00:00+00:00 -2.345638  \n",
       "2025-03-28 19:00:00+00:00 -2.169653  \n",
       "2025-03-28 20:00:00+00:00 -2.342159  \n",
       "2025-03-30 22:00:00+00:00 -2.249456  \n",
       "\n",
       "[10728 rows x 330 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ce61c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(X_filtered, columns =sel['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "793c0916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Close</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>AO_5_34</th>\n",
       "      <th>OBV</th>\n",
       "      <th>OBV_min_2</th>\n",
       "      <th>OBV_max_2</th>\n",
       "      <th>OBVe_4</th>\n",
       "      <th>OBVe_12</th>\n",
       "      <th>BIAS_SMA_26</th>\n",
       "      <th>open_Z_30_1</th>\n",
       "      <th>high_Z_30_1</th>\n",
       "      <th>low_Z_30_1</th>\n",
       "      <th>close_Z_30_1</th>\n",
       "      <th>...</th>\n",
       "      <th>TRENDFLEX_20_20_0.04</th>\n",
       "      <th>TRIX_30_9</th>\n",
       "      <th>TRIXs_30_9</th>\n",
       "      <th>TSI_13_25_13</th>\n",
       "      <th>TSIs_13_25_13</th>\n",
       "      <th>UI_14</th>\n",
       "      <th>UO_7_14_28</th>\n",
       "      <th>VHF_28</th>\n",
       "      <th>VTXP_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4144.00</td>\n",
       "      <td>4176.644138</td>\n",
       "      <td>1.391047e+05</td>\n",
       "      <td>28.620295</td>\n",
       "      <td>-9.730147</td>\n",
       "      <td>-1577626.0</td>\n",
       "      <td>-1577626.0</td>\n",
       "      <td>-1400149.0</td>\n",
       "      <td>-1.519474e+06</td>\n",
       "      <td>-1.587197e+06</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>-0.444303</td>\n",
       "      <td>-0.950039</td>\n",
       "      <td>-0.464179</td>\n",
       "      <td>-0.424334</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.122983</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>-4.939295</td>\n",
       "      <td>1.740578</td>\n",
       "      <td>0.486103</td>\n",
       "      <td>56.043561</td>\n",
       "      <td>0.257329</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>4139.411662</td>\n",
       "      <td>-2076637.00</td>\n",
       "      <td>-557000.375</td>\n",
       "      <td>-52.127660</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>-0.424334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4145.25</td>\n",
       "      <td>4175.581413</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>26.825988</td>\n",
       "      <td>-8.792647</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1577626.0</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1.517897e+06</td>\n",
       "      <td>-1.576171e+06</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.436843</td>\n",
       "      <td>-0.871194</td>\n",
       "      <td>-0.152159</td>\n",
       "      <td>-0.310070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.962115</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>-4.525594</td>\n",
       "      <td>0.845411</td>\n",
       "      <td>0.500135</td>\n",
       "      <td>67.035334</td>\n",
       "      <td>0.269165</td>\n",
       "      <td>0.909884</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1086842.350</td>\n",
       "      <td>-49.468085</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>-0.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4148.75</td>\n",
       "      <td>4174.856448</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>28.659846</td>\n",
       "      <td>-7.901471</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1.516950e+06</td>\n",
       "      <td>-1.566842e+06</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>-0.382348</td>\n",
       "      <td>-0.476069</td>\n",
       "      <td>-0.025833</td>\n",
       "      <td>-0.064860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.773736</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>-3.474663</td>\n",
       "      <td>0.228257</td>\n",
       "      <td>0.509933</td>\n",
       "      <td>66.134866</td>\n",
       "      <td>0.282143</td>\n",
       "      <td>0.920420</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1690910.125</td>\n",
       "      <td>-42.021277</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>-0.064860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4146.00</td>\n",
       "      <td>4174.231448</td>\n",
       "      <td>1.844896e+05</td>\n",
       "      <td>26.612714</td>\n",
       "      <td>-5.724265</td>\n",
       "      <td>-1518442.0</td>\n",
       "      <td>-1518442.0</td>\n",
       "      <td>-1515530.0</td>\n",
       "      <td>-1.517547e+06</td>\n",
       "      <td>-1.559396e+06</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-0.085802</td>\n",
       "      <td>-0.551128</td>\n",
       "      <td>0.099784</td>\n",
       "      <td>-0.321340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593734</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>-3.153352</td>\n",
       "      <td>-0.254830</td>\n",
       "      <td>0.523209</td>\n",
       "      <td>63.307336</td>\n",
       "      <td>0.287796</td>\n",
       "      <td>0.901840</td>\n",
       "      <td>4139.630997</td>\n",
       "      <td>-2015179.75</td>\n",
       "      <td>-2404742.275</td>\n",
       "      <td>-47.872340</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>-0.321340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4151.50</td>\n",
       "      <td>4174.206949</td>\n",
       "      <td>1.915830e+05</td>\n",
       "      <td>27.961806</td>\n",
       "      <td>-3.817647</td>\n",
       "      <td>-1510115.0</td>\n",
       "      <td>-1518442.0</td>\n",
       "      <td>-1510115.0</td>\n",
       "      <td>-1.514574e+06</td>\n",
       "      <td>-1.551814e+06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.341786</td>\n",
       "      <td>-0.282270</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.101855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418917</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>-1.752822</td>\n",
       "      <td>-0.468829</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>64.573340</td>\n",
       "      <td>0.319838</td>\n",
       "      <td>0.901538</td>\n",
       "      <td>4149.583333</td>\n",
       "      <td>-1973241.50</td>\n",
       "      <td>-2286844.450</td>\n",
       "      <td>-32.960894</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>0.101855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>6003.75</td>\n",
       "      <td>6006.743207</td>\n",
       "      <td>2.736824e+07</td>\n",
       "      <td>42.433747</td>\n",
       "      <td>35.587500</td>\n",
       "      <td>12749668.0</td>\n",
       "      <td>12749668.0</td>\n",
       "      <td>12754440.0</td>\n",
       "      <td>1.275382e+07</td>\n",
       "      <td>1.267293e+07</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>1.737972</td>\n",
       "      <td>1.596713</td>\n",
       "      <td>1.839060</td>\n",
       "      <td>1.490349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703834</td>\n",
       "      <td>0.056421</td>\n",
       "      <td>0.057037</td>\n",
       "      <td>45.638926</td>\n",
       "      <td>43.960244</td>\n",
       "      <td>0.037940</td>\n",
       "      <td>65.357969</td>\n",
       "      <td>0.424951</td>\n",
       "      <td>1.266781</td>\n",
       "      <td>6005.333333</td>\n",
       "      <td>4590987.75</td>\n",
       "      <td>4281338.475</td>\n",
       "      <td>-19.170984</td>\n",
       "      <td>6006.723537</td>\n",
       "      <td>1.490349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8578</th>\n",
       "      <td>6005.25</td>\n",
       "      <td>6008.317970</td>\n",
       "      <td>2.737248e+07</td>\n",
       "      <td>39.402765</td>\n",
       "      <td>35.277206</td>\n",
       "      <td>12755446.0</td>\n",
       "      <td>12749668.0</td>\n",
       "      <td>12755446.0</td>\n",
       "      <td>1.275447e+07</td>\n",
       "      <td>1.268562e+07</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>1.492893</td>\n",
       "      <td>1.358206</td>\n",
       "      <td>1.683604</td>\n",
       "      <td>1.482607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666273</td>\n",
       "      <td>0.056143</td>\n",
       "      <td>0.056894</td>\n",
       "      <td>45.209096</td>\n",
       "      <td>44.138651</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>64.893878</td>\n",
       "      <td>0.428291</td>\n",
       "      <td>1.240069</td>\n",
       "      <td>6004.785656</td>\n",
       "      <td>4610026.75</td>\n",
       "      <td>4356700.100</td>\n",
       "      <td>-16.062176</td>\n",
       "      <td>6006.955621</td>\n",
       "      <td>1.482607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>6001.50</td>\n",
       "      <td>6010.280576</td>\n",
       "      <td>2.736764e+07</td>\n",
       "      <td>37.838282</td>\n",
       "      <td>32.507353</td>\n",
       "      <td>12750143.0</td>\n",
       "      <td>12750143.0</td>\n",
       "      <td>12755446.0</td>\n",
       "      <td>1.275274e+07</td>\n",
       "      <td>1.269555e+07</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>1.473237</td>\n",
       "      <td>1.336169</td>\n",
       "      <td>1.546743</td>\n",
       "      <td>1.206776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613257</td>\n",
       "      <td>0.055797</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>43.819062</td>\n",
       "      <td>44.092996</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>62.732151</td>\n",
       "      <td>0.431683</td>\n",
       "      <td>1.253472</td>\n",
       "      <td>6004.271962</td>\n",
       "      <td>4642172.25</td>\n",
       "      <td>4419980.625</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>6005.054599</td>\n",
       "      <td>1.206776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>6003.00</td>\n",
       "      <td>6011.655408</td>\n",
       "      <td>2.736796e+07</td>\n",
       "      <td>35.135547</td>\n",
       "      <td>29.672794</td>\n",
       "      <td>12753701.0</td>\n",
       "      <td>12750143.0</td>\n",
       "      <td>12753701.0</td>\n",
       "      <td>1.275312e+07</td>\n",
       "      <td>1.270450e+07</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>1.198790</td>\n",
       "      <td>1.114644</td>\n",
       "      <td>1.462134</td>\n",
       "      <td>1.207136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549761</td>\n",
       "      <td>0.055392</td>\n",
       "      <td>0.056504</td>\n",
       "      <td>42.825676</td>\n",
       "      <td>43.911950</td>\n",
       "      <td>0.050305</td>\n",
       "      <td>52.046069</td>\n",
       "      <td>0.457023</td>\n",
       "      <td>1.235714</td>\n",
       "      <td>6004.023539</td>\n",
       "      <td>4517215.50</td>\n",
       "      <td>4491805.300</td>\n",
       "      <td>-21.739130</td>\n",
       "      <td>6003.908308</td>\n",
       "      <td>1.207136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>6003.00</td>\n",
       "      <td>6012.929817</td>\n",
       "      <td>2.736673e+07</td>\n",
       "      <td>33.625865</td>\n",
       "      <td>26.944853</td>\n",
       "      <td>12753701.0</td>\n",
       "      <td>12753701.0</td>\n",
       "      <td>12753701.0</td>\n",
       "      <td>1.275336e+07</td>\n",
       "      <td>1.271207e+07</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>1.187124</td>\n",
       "      <td>1.093432</td>\n",
       "      <td>1.389301</td>\n",
       "      <td>1.130451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488444</td>\n",
       "      <td>0.054927</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>41.990078</td>\n",
       "      <td>43.637397</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>54.847322</td>\n",
       "      <td>0.496583</td>\n",
       "      <td>1.262664</td>\n",
       "      <td>6003.937813</td>\n",
       "      <td>4520970.75</td>\n",
       "      <td>4543437.700</td>\n",
       "      <td>-23.809524</td>\n",
       "      <td>6003.606798</td>\n",
       "      <td>1.130451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8582 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature    Close     ACCBU_20            AD     DMP_14    AO_5_34         OBV  \\\n",
       "0        4144.00  4176.644138  1.391047e+05  28.620295  -9.730147  -1577626.0   \n",
       "1        4145.25  4175.581413  1.874016e+05  26.825988  -8.792647  -1515530.0   \n",
       "2        4148.75  4174.856448  1.874016e+05  28.659846  -7.901471  -1515530.0   \n",
       "3        4146.00  4174.231448  1.844896e+05  26.612714  -5.724265  -1518442.0   \n",
       "4        4151.50  4174.206949  1.915830e+05  27.961806  -3.817647  -1510115.0   \n",
       "...          ...          ...           ...        ...        ...         ...   \n",
       "8577     6003.75  6006.743207  2.736824e+07  42.433747  35.587500  12749668.0   \n",
       "8578     6005.25  6008.317970  2.737248e+07  39.402765  35.277206  12755446.0   \n",
       "8579     6001.50  6010.280576  2.736764e+07  37.838282  32.507353  12750143.0   \n",
       "8580     6003.00  6011.655408  2.736796e+07  35.135547  29.672794  12753701.0   \n",
       "8581     6003.00  6012.929817  2.736673e+07  33.625865  26.944853  12753701.0   \n",
       "\n",
       "Feature   OBV_min_2   OBV_max_2        OBVe_4       OBVe_12  BIAS_SMA_26  \\\n",
       "0        -1577626.0  -1400149.0 -1.519474e+06 -1.587197e+06    -0.001633   \n",
       "1        -1577626.0  -1515530.0 -1.517897e+06 -1.576171e+06    -0.001522   \n",
       "2        -1515530.0  -1515530.0 -1.516950e+06 -1.566842e+06    -0.000723   \n",
       "3        -1518442.0  -1515530.0 -1.517547e+06 -1.559396e+06    -0.001327   \n",
       "4        -1518442.0  -1510115.0 -1.514574e+06 -1.551814e+06     0.000009   \n",
       "...             ...         ...           ...           ...          ...   \n",
       "8577     12749668.0  12754440.0  1.275382e+07  1.267293e+07     0.004191   \n",
       "8578     12749668.0  12755446.0  1.275447e+07  1.268562e+07     0.004190   \n",
       "8579     12750143.0  12755446.0  1.275274e+07  1.269555e+07     0.003274   \n",
       "8580     12750143.0  12753701.0  1.275312e+07  1.270450e+07     0.003201   \n",
       "8581     12753701.0  12753701.0  1.275336e+07  1.271207e+07     0.002927   \n",
       "\n",
       "Feature  open_Z_30_1  high_Z_30_1  low_Z_30_1  close_Z_30_1  ...  \\\n",
       "0          -0.444303    -0.950039   -0.464179     -0.424334  ...   \n",
       "1          -0.436843    -0.871194   -0.152159     -0.310070  ...   \n",
       "2          -0.382348    -0.476069   -0.025833     -0.064860  ...   \n",
       "3          -0.085802    -0.551128    0.099784     -0.321340  ...   \n",
       "4          -0.341786    -0.282270    0.007132      0.101855  ...   \n",
       "...              ...          ...         ...           ...  ...   \n",
       "8577        1.737972     1.596713    1.839060      1.490349  ...   \n",
       "8578        1.492893     1.358206    1.683604      1.482607  ...   \n",
       "8579        1.473237     1.336169    1.546743      1.206776  ...   \n",
       "8580        1.198790     1.114644    1.462134      1.207136  ...   \n",
       "8581        1.187124     1.093432    1.389301      1.130451  ...   \n",
       "\n",
       "Feature  TRENDFLEX_20_20_0.04  TRIX_30_9  TRIXs_30_9  TSI_13_25_13  \\\n",
       "0                   -1.122983   0.005306    0.006146     -4.939295   \n",
       "1                   -0.962115   0.005019    0.006005     -4.525594   \n",
       "2                   -0.773736   0.004762    0.005804     -3.474663   \n",
       "3                   -0.593734   0.004513    0.005571     -3.153352   \n",
       "4                   -0.418917   0.004308    0.005325     -1.752822   \n",
       "...                       ...        ...         ...           ...   \n",
       "8577                 0.703834   0.056421    0.057037     45.638926   \n",
       "8578                 0.666273   0.056143    0.056894     45.209096   \n",
       "8579                 0.613257   0.055797    0.056718     43.819062   \n",
       "8580                 0.549761   0.055392    0.056504     42.825676   \n",
       "8581                 0.488444   0.054927    0.056250     41.990078   \n",
       "\n",
       "Feature  TSIs_13_25_13     UI_14  UO_7_14_28    VHF_28   VTXP_14       VWAP_D  \\\n",
       "0             1.740578  0.486103   56.043561  0.257329  0.867244  4139.411662   \n",
       "1             0.845411  0.500135   67.035334  0.269165  0.909884  4139.616049   \n",
       "2             0.228257  0.509933   66.134866  0.282143  0.920420  4139.616049   \n",
       "3            -0.254830  0.523209   63.307336  0.287796  0.901840  4139.630997   \n",
       "4            -0.468829  0.525140   64.573340  0.319838  0.901538  4149.583333   \n",
       "...                ...       ...         ...       ...       ...          ...   \n",
       "8577         43.960244  0.037940   65.357969  0.424951  1.266781  6005.333333   \n",
       "8578         44.138651  0.038969   64.893878  0.428291  1.240069  6004.785656   \n",
       "8579         44.092996  0.046616   62.732151  0.431683  1.253472  6004.271962   \n",
       "8580         43.911950  0.050305   52.046069  0.457023  1.235714  6004.023539   \n",
       "8581         43.637397  0.053741   54.847322  0.496583  1.262664  6003.937813   \n",
       "\n",
       "Feature   TSV_18_10   TSVs_18_10   WILLR_14  ZIGZAGv_5.0%_10     ZS_30  \n",
       "0       -2076637.00  -557000.375 -52.127660      4141.476818 -0.424334  \n",
       "1       -2002493.25 -1086842.350 -49.468085      4142.753760 -0.310070  \n",
       "2       -2002493.25 -1690910.125 -42.021277      4146.298531 -0.064860  \n",
       "3       -2015179.75 -2404742.275 -47.872340      4146.471526 -0.321340  \n",
       "4       -1973241.50 -2286844.450 -32.960894      4148.749430  0.101855  \n",
       "...             ...          ...        ...              ...       ...  \n",
       "8577     4590987.75  4281338.475 -19.170984      6006.723537  1.490349  \n",
       "8578     4610026.75  4356700.100 -16.062176      6006.955621  1.482607  \n",
       "8579     4642172.25  4419980.625 -25.000000      6005.054599  1.206776  \n",
       "8580     4517215.50  4491805.300 -21.739130      6003.908308  1.207136  \n",
       "8581     4520970.75  4543437.700 -23.809524      6003.606798  1.130451  \n",
       "\n",
       "[8582 rows x 78 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23cb3d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Close', 'ACCBU_20', 'AD', 'DMP_14', 'AO_5_34', 'OBV', 'OBV_min_2',\n",
       "       'OBV_max_2', 'OBVe_4', 'OBVe_12', 'BIAS_SMA_26', 'open_Z_30_1',\n",
       "       'high_Z_30_1', 'low_Z_30_1', 'close_Z_30_1', 'CMF_20', 'DPO_20',\n",
       "       'EFI_13', 'BULLP_13', 'FISHERT_9_1', 'FISHERTs_9_1', 'HL2', 'HLC3',\n",
       "       'HWL_1', 'ICS_26', 'INERTIA_20_14', 'JMA_7_0.0', 'K_9_3', 'D_9_3',\n",
       "       'J_9_3', 'KVO_34_55_13', 'KVOs_34_55_13', 'MACD_12_26_9', 'MEDIAN_30',\n",
       "       'MFI_14', 'NVI_1', 'PGO_14', 'PVIe_255', 'PVOs_12_26_9', 'PVT',\n",
       "       'QQE_14_5_4.236', 'REMAP_0.0_100.0_-1.0_1.0', 'RSI_14', 'RSX_14',\n",
       "       'RVGI_14_4', 'SINWMA_14', 'SKEW_30', 'SMIo_5_20_5_1.0', 'SSF_20',\n",
       "       'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHFd_14_3', 'T3_10_0.7',\n",
       "       'THERMOma_20_2_0.5', 'TMO_14_5_3', 'TMOs_14_5_3', 'TOS_STDEVALL_LR',\n",
       "       'TOS_STDEVALL_L_1', 'TOS_STDEVALL_U_1', 'TOS_STDEVALL_L_2',\n",
       "       'TOS_STDEVALL_U_2', 'TOS_STDEVALL_L_3', 'TOS_STDEVALL_U_3',\n",
       "       'TRENDFLEX_20_20_0.04', 'TRIX_30_9', 'TRIXs_30_9', 'TSI_13_25_13',\n",
       "       'TSIs_13_25_13', 'UI_14', 'UO_7_14_28', 'VHF_28', 'VTXP_14', 'VWAP_D',\n",
       "       'TSV_18_10', 'TSVs_18_10', 'WILLR_14', 'ZIGZAGv_5.0%_10', 'ZS_30'],\n",
       "      dtype='object', name='Feature')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39c8b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "783a490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>8567</th>\n",
       "      <th>8568</th>\n",
       "      <th>8569</th>\n",
       "      <th>8570</th>\n",
       "      <th>8571</th>\n",
       "      <th>8572</th>\n",
       "      <th>8573</th>\n",
       "      <th>8574</th>\n",
       "      <th>8575</th>\n",
       "      <th>8576</th>\n",
       "      <th>8577</th>\n",
       "      <th>8578</th>\n",
       "      <th>8579</th>\n",
       "      <th>8580</th>\n",
       "      <th>8581</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>4.144000e+03</td>\n",
       "      <td>4.145250e+03</td>\n",
       "      <td>4.148750e+03</td>\n",
       "      <td>4.146000e+03</td>\n",
       "      <td>4.151500e+03</td>\n",
       "      <td>4.153000e+03</td>\n",
       "      <td>4.150000e+03</td>\n",
       "      <td>4.149000e+03</td>\n",
       "      <td>4.153250e+03</td>\n",
       "      <td>4.151750e+03</td>\n",
       "      <td>4.151250e+03</td>\n",
       "      <td>4.154500e+03</td>\n",
       "      <td>4.161500e+03</td>\n",
       "      <td>4.159500e+03</td>\n",
       "      <td>4.160000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.973250e+03</td>\n",
       "      <td>5.986000e+03</td>\n",
       "      <td>5.994500e+03</td>\n",
       "      <td>5.997750e+03</td>\n",
       "      <td>6.000500e+03</td>\n",
       "      <td>5.994000e+03</td>\n",
       "      <td>6.006750e+03</td>\n",
       "      <td>6.002500e+03</td>\n",
       "      <td>6.006500e+03</td>\n",
       "      <td>6.007250e+03</td>\n",
       "      <td>6.003750e+03</td>\n",
       "      <td>6.005250e+03</td>\n",
       "      <td>6.001500e+03</td>\n",
       "      <td>6.003000e+03</td>\n",
       "      <td>6.003000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCBU_20</th>\n",
       "      <td>4.176644e+03</td>\n",
       "      <td>4.175581e+03</td>\n",
       "      <td>4.174856e+03</td>\n",
       "      <td>4.174231e+03</td>\n",
       "      <td>4.174207e+03</td>\n",
       "      <td>4.173995e+03</td>\n",
       "      <td>4.173507e+03</td>\n",
       "      <td>4.172544e+03</td>\n",
       "      <td>4.171068e+03</td>\n",
       "      <td>4.169993e+03</td>\n",
       "      <td>4.168880e+03</td>\n",
       "      <td>4.168693e+03</td>\n",
       "      <td>4.168304e+03</td>\n",
       "      <td>4.167301e+03</td>\n",
       "      <td>4.166131e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.984628e+03</td>\n",
       "      <td>5.987217e+03</td>\n",
       "      <td>5.988953e+03</td>\n",
       "      <td>5.991153e+03</td>\n",
       "      <td>5.992202e+03</td>\n",
       "      <td>5.994153e+03</td>\n",
       "      <td>5.997556e+03</td>\n",
       "      <td>6.000494e+03</td>\n",
       "      <td>6.002481e+03</td>\n",
       "      <td>6.005019e+03</td>\n",
       "      <td>6.006743e+03</td>\n",
       "      <td>6.008318e+03</td>\n",
       "      <td>6.010281e+03</td>\n",
       "      <td>6.011655e+03</td>\n",
       "      <td>6.012930e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>1.391047e+05</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>1.844896e+05</td>\n",
       "      <td>1.915830e+05</td>\n",
       "      <td>1.921213e+05</td>\n",
       "      <td>1.906416e+05</td>\n",
       "      <td>1.902364e+05</td>\n",
       "      <td>1.943464e+05</td>\n",
       "      <td>1.921596e+05</td>\n",
       "      <td>1.917519e+05</td>\n",
       "      <td>1.960261e+05</td>\n",
       "      <td>2.082303e+05</td>\n",
       "      <td>2.005389e+05</td>\n",
       "      <td>2.013147e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.693935e+07</td>\n",
       "      <td>2.707224e+07</td>\n",
       "      <td>2.718468e+07</td>\n",
       "      <td>2.726441e+07</td>\n",
       "      <td>2.731116e+07</td>\n",
       "      <td>2.730461e+07</td>\n",
       "      <td>2.746039e+07</td>\n",
       "      <td>2.735296e+07</td>\n",
       "      <td>2.737218e+07</td>\n",
       "      <td>2.737218e+07</td>\n",
       "      <td>2.736824e+07</td>\n",
       "      <td>2.737248e+07</td>\n",
       "      <td>2.736764e+07</td>\n",
       "      <td>2.736796e+07</td>\n",
       "      <td>2.736673e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMP_14</th>\n",
       "      <td>2.862029e+01</td>\n",
       "      <td>2.682599e+01</td>\n",
       "      <td>2.865985e+01</td>\n",
       "      <td>2.661271e+01</td>\n",
       "      <td>2.796181e+01</td>\n",
       "      <td>2.896453e+01</td>\n",
       "      <td>2.689564e+01</td>\n",
       "      <td>2.497452e+01</td>\n",
       "      <td>2.619063e+01</td>\n",
       "      <td>2.481987e+01</td>\n",
       "      <td>2.304702e+01</td>\n",
       "      <td>2.665080e+01</td>\n",
       "      <td>2.824718e+01</td>\n",
       "      <td>2.872952e+01</td>\n",
       "      <td>2.667741e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.060165e+01</td>\n",
       "      <td>4.745153e+01</td>\n",
       "      <td>5.356214e+01</td>\n",
       "      <td>5.273627e+01</td>\n",
       "      <td>5.171939e+01</td>\n",
       "      <td>4.802515e+01</td>\n",
       "      <td>5.034478e+01</td>\n",
       "      <td>5.299873e+01</td>\n",
       "      <td>4.921310e+01</td>\n",
       "      <td>4.569788e+01</td>\n",
       "      <td>4.243375e+01</td>\n",
       "      <td>3.940276e+01</td>\n",
       "      <td>3.783828e+01</td>\n",
       "      <td>3.513555e+01</td>\n",
       "      <td>3.362587e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO_5_34</th>\n",
       "      <td>-9.730147e+00</td>\n",
       "      <td>-8.792647e+00</td>\n",
       "      <td>-7.901471e+00</td>\n",
       "      <td>-5.724265e+00</td>\n",
       "      <td>-3.817647e+00</td>\n",
       "      <td>-1.354412e+00</td>\n",
       "      <td>-1.389706e-01</td>\n",
       "      <td>1.036765e-01</td>\n",
       "      <td>3.823529e-01</td>\n",
       "      <td>2.279412e-01</td>\n",
       "      <td>-5.463235e-01</td>\n",
       "      <td>-8.088235e-03</td>\n",
       "      <td>1.528676e+00</td>\n",
       "      <td>3.318382e+00</td>\n",
       "      <td>4.690441e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.624265e+01</td>\n",
       "      <td>2.546985e+01</td>\n",
       "      <td>2.647279e+01</td>\n",
       "      <td>2.810368e+01</td>\n",
       "      <td>3.026250e+01</td>\n",
       "      <td>3.244265e+01</td>\n",
       "      <td>3.408015e+01</td>\n",
       "      <td>3.528603e+01</td>\n",
       "      <td>3.592426e+01</td>\n",
       "      <td>3.530294e+01</td>\n",
       "      <td>3.558750e+01</td>\n",
       "      <td>3.527721e+01</td>\n",
       "      <td>3.250735e+01</td>\n",
       "      <td>2.967279e+01</td>\n",
       "      <td>2.694485e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBV</th>\n",
       "      <td>-1.577626e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.518442e+06</td>\n",
       "      <td>-1.510115e+06</td>\n",
       "      <td>-1.500963e+06</td>\n",
       "      <td>-1.506586e+06</td>\n",
       "      <td>-1.510233e+06</td>\n",
       "      <td>-1.506123e+06</td>\n",
       "      <td>-1.510934e+06</td>\n",
       "      <td>-1.517049e+06</td>\n",
       "      <td>-1.495678e+06</td>\n",
       "      <td>-1.482038e+06</td>\n",
       "      <td>-1.494857e+06</td>\n",
       "      <td>-1.486323e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236755e+07</td>\n",
       "      <td>1.251443e+07</td>\n",
       "      <td>1.267185e+07</td>\n",
       "      <td>1.277815e+07</td>\n",
       "      <td>1.285295e+07</td>\n",
       "      <td>1.276783e+07</td>\n",
       "      <td>1.292362e+07</td>\n",
       "      <td>1.268396e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.274967e+07</td>\n",
       "      <td>1.275545e+07</td>\n",
       "      <td>1.275014e+07</td>\n",
       "      <td>1.275370e+07</td>\n",
       "      <td>1.275370e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBV_min_2</th>\n",
       "      <td>-1.577626e+06</td>\n",
       "      <td>-1.577626e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.518442e+06</td>\n",
       "      <td>-1.518442e+06</td>\n",
       "      <td>-1.510115e+06</td>\n",
       "      <td>-1.506586e+06</td>\n",
       "      <td>-1.510233e+06</td>\n",
       "      <td>-1.510233e+06</td>\n",
       "      <td>-1.510934e+06</td>\n",
       "      <td>-1.517049e+06</td>\n",
       "      <td>-1.517049e+06</td>\n",
       "      <td>-1.495678e+06</td>\n",
       "      <td>-1.494857e+06</td>\n",
       "      <td>-1.494857e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236755e+07</td>\n",
       "      <td>1.236755e+07</td>\n",
       "      <td>1.251443e+07</td>\n",
       "      <td>1.267185e+07</td>\n",
       "      <td>1.277815e+07</td>\n",
       "      <td>1.276783e+07</td>\n",
       "      <td>1.276783e+07</td>\n",
       "      <td>1.268396e+07</td>\n",
       "      <td>1.268396e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.274967e+07</td>\n",
       "      <td>1.274967e+07</td>\n",
       "      <td>1.275014e+07</td>\n",
       "      <td>1.275014e+07</td>\n",
       "      <td>1.275370e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBV_max_2</th>\n",
       "      <td>-1.400149e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.515530e+06</td>\n",
       "      <td>-1.510115e+06</td>\n",
       "      <td>-1.500963e+06</td>\n",
       "      <td>-1.500963e+06</td>\n",
       "      <td>-1.506586e+06</td>\n",
       "      <td>-1.506123e+06</td>\n",
       "      <td>-1.506123e+06</td>\n",
       "      <td>-1.510934e+06</td>\n",
       "      <td>-1.495678e+06</td>\n",
       "      <td>-1.482038e+06</td>\n",
       "      <td>-1.482038e+06</td>\n",
       "      <td>-1.486323e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236755e+07</td>\n",
       "      <td>1.251443e+07</td>\n",
       "      <td>1.267185e+07</td>\n",
       "      <td>1.277815e+07</td>\n",
       "      <td>1.285295e+07</td>\n",
       "      <td>1.285295e+07</td>\n",
       "      <td>1.292362e+07</td>\n",
       "      <td>1.292362e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.275444e+07</td>\n",
       "      <td>1.275545e+07</td>\n",
       "      <td>1.275545e+07</td>\n",
       "      <td>1.275370e+07</td>\n",
       "      <td>1.275370e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBVe_4</th>\n",
       "      <td>-1.519474e+06</td>\n",
       "      <td>-1.517897e+06</td>\n",
       "      <td>-1.516950e+06</td>\n",
       "      <td>-1.517547e+06</td>\n",
       "      <td>-1.514574e+06</td>\n",
       "      <td>-1.509130e+06</td>\n",
       "      <td>-1.508112e+06</td>\n",
       "      <td>-1.508961e+06</td>\n",
       "      <td>-1.507826e+06</td>\n",
       "      <td>-1.509069e+06</td>\n",
       "      <td>-1.512261e+06</td>\n",
       "      <td>-1.505628e+06</td>\n",
       "      <td>-1.496192e+06</td>\n",
       "      <td>-1.495658e+06</td>\n",
       "      <td>-1.491924e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235951e+07</td>\n",
       "      <td>1.242148e+07</td>\n",
       "      <td>1.252163e+07</td>\n",
       "      <td>1.262424e+07</td>\n",
       "      <td>1.271572e+07</td>\n",
       "      <td>1.273657e+07</td>\n",
       "      <td>1.281139e+07</td>\n",
       "      <td>1.276042e+07</td>\n",
       "      <td>1.275803e+07</td>\n",
       "      <td>1.275659e+07</td>\n",
       "      <td>1.275382e+07</td>\n",
       "      <td>1.275447e+07</td>\n",
       "      <td>1.275274e+07</td>\n",
       "      <td>1.275312e+07</td>\n",
       "      <td>1.275336e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBVe_12</th>\n",
       "      <td>-1.587197e+06</td>\n",
       "      <td>-1.576171e+06</td>\n",
       "      <td>-1.566842e+06</td>\n",
       "      <td>-1.559396e+06</td>\n",
       "      <td>-1.551814e+06</td>\n",
       "      <td>-1.543991e+06</td>\n",
       "      <td>-1.538236e+06</td>\n",
       "      <td>-1.533928e+06</td>\n",
       "      <td>-1.529650e+06</td>\n",
       "      <td>-1.526771e+06</td>\n",
       "      <td>-1.525275e+06</td>\n",
       "      <td>-1.520722e+06</td>\n",
       "      <td>-1.514770e+06</td>\n",
       "      <td>-1.511707e+06</td>\n",
       "      <td>-1.507802e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231016e+07</td>\n",
       "      <td>1.234159e+07</td>\n",
       "      <td>1.239240e+07</td>\n",
       "      <td>1.245175e+07</td>\n",
       "      <td>1.251347e+07</td>\n",
       "      <td>1.255260e+07</td>\n",
       "      <td>1.260968e+07</td>\n",
       "      <td>1.262111e+07</td>\n",
       "      <td>1.264162e+07</td>\n",
       "      <td>1.265898e+07</td>\n",
       "      <td>1.267293e+07</td>\n",
       "      <td>1.268562e+07</td>\n",
       "      <td>1.269555e+07</td>\n",
       "      <td>1.270450e+07</td>\n",
       "      <td>1.271207e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIAS_SMA_26</th>\n",
       "      <td>-1.633150e-03</td>\n",
       "      <td>-1.521668e-03</td>\n",
       "      <td>-7.225869e-04</td>\n",
       "      <td>-1.327135e-03</td>\n",
       "      <td>9.264578e-06</td>\n",
       "      <td>3.868024e-04</td>\n",
       "      <td>-2.710109e-04</td>\n",
       "      <td>-3.938230e-04</td>\n",
       "      <td>6.880718e-04</td>\n",
       "      <td>4.054614e-04</td>\n",
       "      <td>3.684214e-04</td>\n",
       "      <td>1.218885e-03</td>\n",
       "      <td>2.915155e-03</td>\n",
       "      <td>2.414575e-03</td>\n",
       "      <td>2.572243e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.176418e-03</td>\n",
       "      <td>4.921751e-03</td>\n",
       "      <td>6.020684e-03</td>\n",
       "      <td>6.148843e-03</td>\n",
       "      <td>6.013006e-03</td>\n",
       "      <td>4.426155e-03</td>\n",
       "      <td>6.103925e-03</td>\n",
       "      <td>4.992281e-03</td>\n",
       "      <td>5.299469e-03</td>\n",
       "      <td>5.074003e-03</td>\n",
       "      <td>4.191166e-03</td>\n",
       "      <td>4.190115e-03</td>\n",
       "      <td>3.274293e-03</td>\n",
       "      <td>3.200926e-03</td>\n",
       "      <td>2.926955e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_Z_30_1</th>\n",
       "      <td>-4.443029e-01</td>\n",
       "      <td>-4.368429e-01</td>\n",
       "      <td>-3.823481e-01</td>\n",
       "      <td>-8.580248e-02</td>\n",
       "      <td>-3.417861e-01</td>\n",
       "      <td>8.119890e-02</td>\n",
       "      <td>1.476444e-01</td>\n",
       "      <td>-1.559204e-01</td>\n",
       "      <td>-2.221024e-01</td>\n",
       "      <td>1.893360e-01</td>\n",
       "      <td>1.896667e-02</td>\n",
       "      <td>3.904895e-02</td>\n",
       "      <td>4.093402e-01</td>\n",
       "      <td>1.106992e+00</td>\n",
       "      <td>9.031592e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205616e+00</td>\n",
       "      <td>1.190329e+00</td>\n",
       "      <td>1.787147e+00</td>\n",
       "      <td>2.040170e+00</td>\n",
       "      <td>1.992514e+00</td>\n",
       "      <td>1.908267e+00</td>\n",
       "      <td>1.506266e+00</td>\n",
       "      <td>1.902491e+00</td>\n",
       "      <td>1.590901e+00</td>\n",
       "      <td>1.796922e+00</td>\n",
       "      <td>1.737972e+00</td>\n",
       "      <td>1.492893e+00</td>\n",
       "      <td>1.473237e+00</td>\n",
       "      <td>1.198790e+00</td>\n",
       "      <td>1.187124e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_Z_30_1</th>\n",
       "      <td>-9.500395e-01</td>\n",
       "      <td>-8.711936e-01</td>\n",
       "      <td>-4.760687e-01</td>\n",
       "      <td>-5.511279e-01</td>\n",
       "      <td>-2.822705e-01</td>\n",
       "      <td>-7.229326e-02</td>\n",
       "      <td>-3.233008e-01</td>\n",
       "      <td>-5.871734e-01</td>\n",
       "      <td>-2.373392e-01</td>\n",
       "      <td>-1.755755e-01</td>\n",
       "      <td>-2.105892e-01</td>\n",
       "      <td>4.028581e-01</td>\n",
       "      <td>8.178374e-01</td>\n",
       "      <td>1.080181e+00</td>\n",
       "      <td>8.499573e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401504e+00</td>\n",
       "      <td>2.062503e+00</td>\n",
       "      <td>2.432652e+00</td>\n",
       "      <td>2.320812e+00</td>\n",
       "      <td>2.212235e+00</td>\n",
       "      <td>1.947365e+00</td>\n",
       "      <td>2.044202e+00</td>\n",
       "      <td>2.130648e+00</td>\n",
       "      <td>1.805048e+00</td>\n",
       "      <td>1.673110e+00</td>\n",
       "      <td>1.596713e+00</td>\n",
       "      <td>1.358206e+00</td>\n",
       "      <td>1.336169e+00</td>\n",
       "      <td>1.114644e+00</td>\n",
       "      <td>1.093432e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_Z_30_1</th>\n",
       "      <td>-4.641785e-01</td>\n",
       "      <td>-1.521588e-01</td>\n",
       "      <td>-2.583297e-02</td>\n",
       "      <td>9.978443e-02</td>\n",
       "      <td>7.132282e-03</td>\n",
       "      <td>3.413695e-01</td>\n",
       "      <td>8.561091e-02</td>\n",
       "      <td>4.818218e-02</td>\n",
       "      <td>1.602014e-01</td>\n",
       "      <td>3.086522e-01</td>\n",
       "      <td>1.946480e-01</td>\n",
       "      <td>1.365797e-01</td>\n",
       "      <td>5.036993e-01</td>\n",
       "      <td>1.003081e+00</td>\n",
       "      <td>9.115885e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067706e+00</td>\n",
       "      <td>1.203581e+00</td>\n",
       "      <td>1.712225e+00</td>\n",
       "      <td>1.708237e+00</td>\n",
       "      <td>1.831435e+00</td>\n",
       "      <td>1.465294e+00</td>\n",
       "      <td>1.273022e+00</td>\n",
       "      <td>1.699312e+00</td>\n",
       "      <td>1.785438e+00</td>\n",
       "      <td>1.784095e+00</td>\n",
       "      <td>1.839060e+00</td>\n",
       "      <td>1.683604e+00</td>\n",
       "      <td>1.546743e+00</td>\n",
       "      <td>1.462134e+00</td>\n",
       "      <td>1.389301e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close_Z_30_1</th>\n",
       "      <td>-4.243336e-01</td>\n",
       "      <td>-3.100699e-01</td>\n",
       "      <td>-6.485975e-02</td>\n",
       "      <td>-3.213398e-01</td>\n",
       "      <td>1.018548e-01</td>\n",
       "      <td>1.702538e-01</td>\n",
       "      <td>-1.581031e-01</td>\n",
       "      <td>-2.497979e-01</td>\n",
       "      <td>1.862238e-01</td>\n",
       "      <td>4.213366e-02</td>\n",
       "      <td>1.037961e-02</td>\n",
       "      <td>3.798855e-01</td>\n",
       "      <td>1.105363e+00</td>\n",
       "      <td>9.001579e-01</td>\n",
       "      <td>9.544857e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192044e+00</td>\n",
       "      <td>1.800801e+00</td>\n",
       "      <td>2.039608e+00</td>\n",
       "      <td>1.981715e+00</td>\n",
       "      <td>1.909438e+00</td>\n",
       "      <td>1.507856e+00</td>\n",
       "      <td>1.904292e+00</td>\n",
       "      <td>1.591887e+00</td>\n",
       "      <td>1.745361e+00</td>\n",
       "      <td>1.747173e+00</td>\n",
       "      <td>1.490349e+00</td>\n",
       "      <td>1.482607e+00</td>\n",
       "      <td>1.206776e+00</td>\n",
       "      <td>1.207136e+00</td>\n",
       "      <td>1.130451e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMF_20</th>\n",
       "      <td>2.092556e-01</td>\n",
       "      <td>2.325357e-01</td>\n",
       "      <td>2.387055e-01</td>\n",
       "      <td>2.360134e-01</td>\n",
       "      <td>2.428811e-01</td>\n",
       "      <td>2.417800e-01</td>\n",
       "      <td>2.391435e-01</td>\n",
       "      <td>2.441664e-01</td>\n",
       "      <td>2.464029e-01</td>\n",
       "      <td>2.504205e-01</td>\n",
       "      <td>2.536061e-01</td>\n",
       "      <td>2.652109e-01</td>\n",
       "      <td>2.941479e-01</td>\n",
       "      <td>3.490623e-01</td>\n",
       "      <td>6.115053e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.108053e-01</td>\n",
       "      <td>2.892367e-01</td>\n",
       "      <td>3.496854e-01</td>\n",
       "      <td>3.989106e-01</td>\n",
       "      <td>6.411883e-01</td>\n",
       "      <td>5.310785e-01</td>\n",
       "      <td>6.125747e-01</td>\n",
       "      <td>3.970077e-01</td>\n",
       "      <td>3.887067e-01</td>\n",
       "      <td>3.930151e-01</td>\n",
       "      <td>3.890651e-01</td>\n",
       "      <td>3.920534e-01</td>\n",
       "      <td>3.853398e-01</td>\n",
       "      <td>3.892919e-01</td>\n",
       "      <td>3.940495e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPO_20</th>\n",
       "      <td>-1.750000e+00</td>\n",
       "      <td>-1.237500e+00</td>\n",
       "      <td>1.662500e+00</td>\n",
       "      <td>-2.850000e+00</td>\n",
       "      <td>1.575000e+00</td>\n",
       "      <td>2.312500e+00</td>\n",
       "      <td>-1.025000e+00</td>\n",
       "      <td>-2.087500e+00</td>\n",
       "      <td>2.587500e+00</td>\n",
       "      <td>2.450000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>8.175000e+00</td>\n",
       "      <td>1.558750e+01</td>\n",
       "      <td>1.456250e+01</td>\n",
       "      <td>1.626250e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.307500e+01</td>\n",
       "      <td>-1.937500e+00</td>\n",
       "      <td>4.775000e+00</td>\n",
       "      <td>5.950000e+00</td>\n",
       "      <td>6.712500e+00</td>\n",
       "      <td>-1.662500e+00</td>\n",
       "      <td>9.212500e+00</td>\n",
       "      <td>3.212500e+00</td>\n",
       "      <td>5.562500e+00</td>\n",
       "      <td>5.275000e+00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "      <td>2.362500e+00</td>\n",
       "      <td>-1.412500e+00</td>\n",
       "      <td>-6.375000e-01</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EFI_13</th>\n",
       "      <td>-3.867705e+04</td>\n",
       "      <td>-2.206319e+04</td>\n",
       "      <td>-1.891130e+04</td>\n",
       "      <td>-1.735369e+04</td>\n",
       "      <td>-8.331948e+03</td>\n",
       "      <td>-5.180527e+03</td>\n",
       "      <td>-6.850309e+03</td>\n",
       "      <td>-6.392693e+03</td>\n",
       "      <td>-2.984094e+03</td>\n",
       "      <td>-3.588724e+03</td>\n",
       "      <td>-3.512835e+03</td>\n",
       "      <td>6.911249e+03</td>\n",
       "      <td>1.956393e+04</td>\n",
       "      <td>1.310651e+04</td>\n",
       "      <td>1.184372e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.140097e+04</td>\n",
       "      <td>3.201645e+05</td>\n",
       "      <td>4.655771e+05</td>\n",
       "      <td>4.484211e+05</td>\n",
       "      <td>4.137435e+05</td>\n",
       "      <td>2.756019e+05</td>\n",
       "      <td>5.199815e+05</td>\n",
       "      <td>3.001936e+05</td>\n",
       "      <td>2.975825e+05</td>\n",
       "      <td>2.550707e+05</td>\n",
       "      <td>2.162460e+05</td>\n",
       "      <td>1.865919e+05</td>\n",
       "      <td>1.570950e+05</td>\n",
       "      <td>1.354153e+05</td>\n",
       "      <td>1.160703e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BULLP_13</th>\n",
       "      <td>5.583246e-01</td>\n",
       "      <td>7.642782e-01</td>\n",
       "      <td>3.976524e+00</td>\n",
       "      <td>3.158449e+00</td>\n",
       "      <td>5.564385e+00</td>\n",
       "      <td>7.626616e+00</td>\n",
       "      <td>5.251385e+00</td>\n",
       "      <td>2.322616e+00</td>\n",
       "      <td>4.562242e+00</td>\n",
       "      <td>4.624779e+00</td>\n",
       "      <td>3.821239e+00</td>\n",
       "      <td>8.346776e+00</td>\n",
       "      <td>1.022581e+01</td>\n",
       "      <td>1.162212e+01</td>\n",
       "      <td>8.604675e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171310e+01</td>\n",
       "      <td>1.850408e+01</td>\n",
       "      <td>2.425350e+01</td>\n",
       "      <td>2.357443e+01</td>\n",
       "      <td>2.277808e+01</td>\n",
       "      <td>1.966693e+01</td>\n",
       "      <td>2.178594e+01</td>\n",
       "      <td>2.553080e+01</td>\n",
       "      <td>1.931212e+01</td>\n",
       "      <td>1.637467e+01</td>\n",
       "      <td>1.478543e+01</td>\n",
       "      <td>9.958943e+00</td>\n",
       "      <td>1.039338e+01</td>\n",
       "      <td>6.730040e+00</td>\n",
       "      <td>6.947177e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FISHERT_9_1</th>\n",
       "      <td>-1.005900e+00</td>\n",
       "      <td>-7.067068e-01</td>\n",
       "      <td>-1.554691e-01</td>\n",
       "      <td>4.206918e-01</td>\n",
       "      <td>9.664706e-01</td>\n",
       "      <td>1.474705e+00</td>\n",
       "      <td>1.734054e+00</td>\n",
       "      <td>1.661542e+00</td>\n",
       "      <td>1.664600e+00</td>\n",
       "      <td>1.810056e+00</td>\n",
       "      <td>1.725823e+00</td>\n",
       "      <td>1.914921e+00</td>\n",
       "      <td>2.229439e+00</td>\n",
       "      <td>2.599733e+00</td>\n",
       "      <td>2.545516e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.568644e+00</td>\n",
       "      <td>2.920939e+00</td>\n",
       "      <td>3.303538e+00</td>\n",
       "      <td>3.699195e+00</td>\n",
       "      <td>4.100004e+00</td>\n",
       "      <td>3.567664e+00</td>\n",
       "      <td>3.242039e+00</td>\n",
       "      <td>3.288318e+00</td>\n",
       "      <td>3.441850e+00</td>\n",
       "      <td>3.642659e+00</td>\n",
       "      <td>3.946824e+00</td>\n",
       "      <td>3.289602e+00</td>\n",
       "      <td>2.733930e+00</td>\n",
       "      <td>2.194553e+00</td>\n",
       "      <td>1.822363e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FISHERTs_9_1</th>\n",
       "      <td>-1.231003e+00</td>\n",
       "      <td>-1.005900e+00</td>\n",
       "      <td>-7.067068e-01</td>\n",
       "      <td>-1.554691e-01</td>\n",
       "      <td>4.206918e-01</td>\n",
       "      <td>9.664706e-01</td>\n",
       "      <td>1.474705e+00</td>\n",
       "      <td>1.734054e+00</td>\n",
       "      <td>1.661542e+00</td>\n",
       "      <td>1.664600e+00</td>\n",
       "      <td>1.810056e+00</td>\n",
       "      <td>1.725823e+00</td>\n",
       "      <td>1.914921e+00</td>\n",
       "      <td>2.229439e+00</td>\n",
       "      <td>2.599733e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.283366e+00</td>\n",
       "      <td>2.568644e+00</td>\n",
       "      <td>2.920939e+00</td>\n",
       "      <td>3.303538e+00</td>\n",
       "      <td>3.699195e+00</td>\n",
       "      <td>4.100004e+00</td>\n",
       "      <td>3.567664e+00</td>\n",
       "      <td>3.242039e+00</td>\n",
       "      <td>3.288318e+00</td>\n",
       "      <td>3.441850e+00</td>\n",
       "      <td>3.642659e+00</td>\n",
       "      <td>3.946824e+00</td>\n",
       "      <td>3.289602e+00</td>\n",
       "      <td>2.733930e+00</td>\n",
       "      <td>2.194553e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL2</th>\n",
       "      <td>4.141000e+03</td>\n",
       "      <td>4.143500e+03</td>\n",
       "      <td>4.146625e+03</td>\n",
       "      <td>4.147375e+03</td>\n",
       "      <td>4.148625e+03</td>\n",
       "      <td>4.152875e+03</td>\n",
       "      <td>4.150625e+03</td>\n",
       "      <td>4.149125e+03</td>\n",
       "      <td>4.151250e+03</td>\n",
       "      <td>4.152375e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>4.153500e+03</td>\n",
       "      <td>4.157250e+03</td>\n",
       "      <td>4.161375e+03</td>\n",
       "      <td>4.159750e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.972000e+03</td>\n",
       "      <td>5.978875e+03</td>\n",
       "      <td>5.990125e+03</td>\n",
       "      <td>5.993250e+03</td>\n",
       "      <td>5.998000e+03</td>\n",
       "      <td>5.994500e+03</td>\n",
       "      <td>5.996125e+03</td>\n",
       "      <td>6.005750e+03</td>\n",
       "      <td>6.005375e+03</td>\n",
       "      <td>6.005500e+03</td>\n",
       "      <td>6.006125e+03</td>\n",
       "      <td>6.003875e+03</td>\n",
       "      <td>6.004125e+03</td>\n",
       "      <td>6.002875e+03</td>\n",
       "      <td>6.003625e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLC3</th>\n",
       "      <td>4.142000e+03</td>\n",
       "      <td>4.144083e+03</td>\n",
       "      <td>4.147333e+03</td>\n",
       "      <td>4.146917e+03</td>\n",
       "      <td>4.149583e+03</td>\n",
       "      <td>4.152917e+03</td>\n",
       "      <td>4.150417e+03</td>\n",
       "      <td>4.149083e+03</td>\n",
       "      <td>4.151917e+03</td>\n",
       "      <td>4.152167e+03</td>\n",
       "      <td>4.151333e+03</td>\n",
       "      <td>4.153833e+03</td>\n",
       "      <td>4.158667e+03</td>\n",
       "      <td>4.160750e+03</td>\n",
       "      <td>4.159833e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.972417e+03</td>\n",
       "      <td>5.981250e+03</td>\n",
       "      <td>5.991583e+03</td>\n",
       "      <td>5.994750e+03</td>\n",
       "      <td>5.998833e+03</td>\n",
       "      <td>5.994333e+03</td>\n",
       "      <td>5.999667e+03</td>\n",
       "      <td>6.004667e+03</td>\n",
       "      <td>6.005750e+03</td>\n",
       "      <td>6.006083e+03</td>\n",
       "      <td>6.005333e+03</td>\n",
       "      <td>6.004333e+03</td>\n",
       "      <td>6.003250e+03</td>\n",
       "      <td>6.002917e+03</td>\n",
       "      <td>6.003417e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HWL_1</th>\n",
       "      <td>4.125659e+03</td>\n",
       "      <td>4.125213e+03</td>\n",
       "      <td>4.125620e+03</td>\n",
       "      <td>4.125313e+03</td>\n",
       "      <td>4.126031e+03</td>\n",
       "      <td>4.127276e+03</td>\n",
       "      <td>4.127319e+03</td>\n",
       "      <td>4.127189e+03</td>\n",
       "      <td>4.128491e+03</td>\n",
       "      <td>4.129539e+03</td>\n",
       "      <td>4.130181e+03</td>\n",
       "      <td>4.131824e+03</td>\n",
       "      <td>4.135055e+03</td>\n",
       "      <td>4.137430e+03</td>\n",
       "      <td>4.139294e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.928553e+03</td>\n",
       "      <td>5.930691e+03</td>\n",
       "      <td>5.934403e+03</td>\n",
       "      <td>5.937319e+03</td>\n",
       "      <td>5.939943e+03</td>\n",
       "      <td>5.941053e+03</td>\n",
       "      <td>5.945177e+03</td>\n",
       "      <td>5.948981e+03</td>\n",
       "      <td>5.952572e+03</td>\n",
       "      <td>5.956892e+03</td>\n",
       "      <td>5.960123e+03</td>\n",
       "      <td>5.963754e+03</td>\n",
       "      <td>5.966748e+03</td>\n",
       "      <td>5.969986e+03</td>\n",
       "      <td>5.973269e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICS_26</th>\n",
       "      <td>4.129000e+03</td>\n",
       "      <td>4.132250e+03</td>\n",
       "      <td>4.128750e+03</td>\n",
       "      <td>4.135750e+03</td>\n",
       "      <td>4.136250e+03</td>\n",
       "      <td>4.137250e+03</td>\n",
       "      <td>4.139750e+03</td>\n",
       "      <td>4.146000e+03</td>\n",
       "      <td>4.151000e+03</td>\n",
       "      <td>4.153500e+03</td>\n",
       "      <td>4.150750e+03</td>\n",
       "      <td>4.151750e+03</td>\n",
       "      <td>4.154250e+03</td>\n",
       "      <td>4.152500e+03</td>\n",
       "      <td>4.145000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.021250e+03</td>\n",
       "      <td>6.022750e+03</td>\n",
       "      <td>6.024750e+03</td>\n",
       "      <td>6.034000e+03</td>\n",
       "      <td>6.033000e+03</td>\n",
       "      <td>6.027250e+03</td>\n",
       "      <td>6.023500e+03</td>\n",
       "      <td>6.037500e+03</td>\n",
       "      <td>6.033000e+03</td>\n",
       "      <td>6.035250e+03</td>\n",
       "      <td>6.033250e+03</td>\n",
       "      <td>6.034250e+03</td>\n",
       "      <td>6.036500e+03</td>\n",
       "      <td>6.036250e+03</td>\n",
       "      <td>6.037500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INERTIA_20_14</th>\n",
       "      <td>6.067977e+01</td>\n",
       "      <td>6.107875e+01</td>\n",
       "      <td>6.133456e+01</td>\n",
       "      <td>6.054171e+01</td>\n",
       "      <td>6.069370e+01</td>\n",
       "      <td>6.208501e+01</td>\n",
       "      <td>6.263909e+01</td>\n",
       "      <td>6.104715e+01</td>\n",
       "      <td>6.081584e+01</td>\n",
       "      <td>5.935274e+01</td>\n",
       "      <td>5.744669e+01</td>\n",
       "      <td>5.629583e+01</td>\n",
       "      <td>5.555212e+01</td>\n",
       "      <td>5.421098e+01</td>\n",
       "      <td>5.279196e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.206446e+01</td>\n",
       "      <td>6.258902e+01</td>\n",
       "      <td>6.417971e+01</td>\n",
       "      <td>6.674493e+01</td>\n",
       "      <td>7.016600e+01</td>\n",
       "      <td>7.105264e+01</td>\n",
       "      <td>7.250672e+01</td>\n",
       "      <td>7.078785e+01</td>\n",
       "      <td>7.074790e+01</td>\n",
       "      <td>7.101718e+01</td>\n",
       "      <td>6.953468e+01</td>\n",
       "      <td>6.949494e+01</td>\n",
       "      <td>6.825568e+01</td>\n",
       "      <td>6.747416e+01</td>\n",
       "      <td>6.632187e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JMA_7_0.0</th>\n",
       "      <td>4.140373e+03</td>\n",
       "      <td>4.141970e+03</td>\n",
       "      <td>4.143967e+03</td>\n",
       "      <td>4.145308e+03</td>\n",
       "      <td>4.146967e+03</td>\n",
       "      <td>4.148811e+03</td>\n",
       "      <td>4.149992e+03</td>\n",
       "      <td>4.150427e+03</td>\n",
       "      <td>4.151001e+03</td>\n",
       "      <td>4.151470e+03</td>\n",
       "      <td>4.151707e+03</td>\n",
       "      <td>4.152230e+03</td>\n",
       "      <td>4.154276e+03</td>\n",
       "      <td>4.156193e+03</td>\n",
       "      <td>4.157766e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.971116e+03</td>\n",
       "      <td>5.973944e+03</td>\n",
       "      <td>5.979500e+03</td>\n",
       "      <td>5.985653e+03</td>\n",
       "      <td>5.991209e+03</td>\n",
       "      <td>5.994500e+03</td>\n",
       "      <td>5.998036e+03</td>\n",
       "      <td>6.000624e+03</td>\n",
       "      <td>6.002831e+03</td>\n",
       "      <td>6.004699e+03</td>\n",
       "      <td>6.005616e+03</td>\n",
       "      <td>6.006017e+03</td>\n",
       "      <td>6.005595e+03</td>\n",
       "      <td>6.004954e+03</td>\n",
       "      <td>6.004355e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K_9_3</th>\n",
       "      <td>4.395875e+01</td>\n",
       "      <td>4.838214e+01</td>\n",
       "      <td>6.469523e+01</td>\n",
       "      <td>7.229682e+01</td>\n",
       "      <td>8.092515e+01</td>\n",
       "      <td>8.509764e+01</td>\n",
       "      <td>8.460061e+01</td>\n",
       "      <td>8.131269e+01</td>\n",
       "      <td>8.438864e+01</td>\n",
       "      <td>8.171364e+01</td>\n",
       "      <td>7.669798e+01</td>\n",
       "      <td>7.440243e+01</td>\n",
       "      <td>8.193993e+01</td>\n",
       "      <td>7.785894e+01</td>\n",
       "      <td>7.614839e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.183969e+01</td>\n",
       "      <td>8.698404e+01</td>\n",
       "      <td>8.974612e+01</td>\n",
       "      <td>9.185689e+01</td>\n",
       "      <td>9.323792e+01</td>\n",
       "      <td>8.833311e+01</td>\n",
       "      <td>9.222208e+01</td>\n",
       "      <td>8.720602e+01</td>\n",
       "      <td>8.676054e+01</td>\n",
       "      <td>8.661020e+01</td>\n",
       "      <td>8.044128e+01</td>\n",
       "      <td>7.756692e+01</td>\n",
       "      <td>7.110522e+01</td>\n",
       "      <td>6.861560e+01</td>\n",
       "      <td>6.695585e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_9_3</th>\n",
       "      <td>3.759301e+01</td>\n",
       "      <td>4.118938e+01</td>\n",
       "      <td>4.902467e+01</td>\n",
       "      <td>5.678205e+01</td>\n",
       "      <td>6.482975e+01</td>\n",
       "      <td>7.158572e+01</td>\n",
       "      <td>7.592402e+01</td>\n",
       "      <td>7.772024e+01</td>\n",
       "      <td>7.994304e+01</td>\n",
       "      <td>8.053324e+01</td>\n",
       "      <td>7.925482e+01</td>\n",
       "      <td>7.763736e+01</td>\n",
       "      <td>7.907155e+01</td>\n",
       "      <td>7.866734e+01</td>\n",
       "      <td>7.782769e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.089347e+01</td>\n",
       "      <td>8.292366e+01</td>\n",
       "      <td>8.519781e+01</td>\n",
       "      <td>8.741750e+01</td>\n",
       "      <td>8.935764e+01</td>\n",
       "      <td>8.901613e+01</td>\n",
       "      <td>9.008478e+01</td>\n",
       "      <td>8.912519e+01</td>\n",
       "      <td>8.833697e+01</td>\n",
       "      <td>8.776138e+01</td>\n",
       "      <td>8.532135e+01</td>\n",
       "      <td>8.273654e+01</td>\n",
       "      <td>7.885943e+01</td>\n",
       "      <td>7.544482e+01</td>\n",
       "      <td>7.261516e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J_9_3</th>\n",
       "      <td>5.669022e+01</td>\n",
       "      <td>6.276764e+01</td>\n",
       "      <td>9.603636e+01</td>\n",
       "      <td>1.033264e+02</td>\n",
       "      <td>1.131160e+02</td>\n",
       "      <td>1.121215e+02</td>\n",
       "      <td>1.019538e+02</td>\n",
       "      <td>8.849759e+01</td>\n",
       "      <td>9.327984e+01</td>\n",
       "      <td>8.407444e+01</td>\n",
       "      <td>7.158430e+01</td>\n",
       "      <td>6.793257e+01</td>\n",
       "      <td>8.767669e+01</td>\n",
       "      <td>7.624213e+01</td>\n",
       "      <td>7.278977e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.373214e+01</td>\n",
       "      <td>9.510479e+01</td>\n",
       "      <td>9.884272e+01</td>\n",
       "      <td>1.007357e+02</td>\n",
       "      <td>1.009985e+02</td>\n",
       "      <td>8.696707e+01</td>\n",
       "      <td>9.649666e+01</td>\n",
       "      <td>8.336768e+01</td>\n",
       "      <td>8.360766e+01</td>\n",
       "      <td>8.430783e+01</td>\n",
       "      <td>7.068115e+01</td>\n",
       "      <td>6.722767e+01</td>\n",
       "      <td>5.559679e+01</td>\n",
       "      <td>5.495716e+01</td>\n",
       "      <td>5.563723e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVO_34_55_13</th>\n",
       "      <td>4.560542e+03</td>\n",
       "      <td>5.615083e+03</td>\n",
       "      <td>5.231766e+03</td>\n",
       "      <td>4.810184e+03</td>\n",
       "      <td>4.657907e+03</td>\n",
       "      <td>4.527633e+03</td>\n",
       "      <td>4.083342e+03</td>\n",
       "      <td>3.713409e+03</td>\n",
       "      <td>3.535716e+03</td>\n",
       "      <td>3.381965e+03</td>\n",
       "      <td>3.001147e+03</td>\n",
       "      <td>3.237775e+03</td>\n",
       "      <td>3.280641e+03</td>\n",
       "      <td>3.295326e+03</td>\n",
       "      <td>2.844387e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.474286e+03</td>\n",
       "      <td>4.971685e+03</td>\n",
       "      <td>7.457904e+03</td>\n",
       "      <td>8.607793e+03</td>\n",
       "      <td>8.960450e+03</td>\n",
       "      <td>5.836215e+03</td>\n",
       "      <td>8.145944e+03</td>\n",
       "      <td>1.202650e+04</td>\n",
       "      <td>1.190490e+04</td>\n",
       "      <td>1.025978e+04</td>\n",
       "      <td>8.640865e+03</td>\n",
       "      <td>7.129785e+03</td>\n",
       "      <td>5.751563e+03</td>\n",
       "      <td>4.524162e+03</td>\n",
       "      <td>3.543660e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVOs_34_55_13</th>\n",
       "      <td>5.413537e+02</td>\n",
       "      <td>1.266172e+03</td>\n",
       "      <td>1.832686e+03</td>\n",
       "      <td>2.258042e+03</td>\n",
       "      <td>2.600880e+03</td>\n",
       "      <td>2.876131e+03</td>\n",
       "      <td>3.048589e+03</td>\n",
       "      <td>3.143564e+03</td>\n",
       "      <td>3.199585e+03</td>\n",
       "      <td>3.225640e+03</td>\n",
       "      <td>3.193569e+03</td>\n",
       "      <td>3.199884e+03</td>\n",
       "      <td>3.211421e+03</td>\n",
       "      <td>3.223407e+03</td>\n",
       "      <td>3.169262e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.363817e+03</td>\n",
       "      <td>5.307798e+03</td>\n",
       "      <td>5.614956e+03</td>\n",
       "      <td>6.042504e+03</td>\n",
       "      <td>6.459354e+03</td>\n",
       "      <td>6.370334e+03</td>\n",
       "      <td>6.623992e+03</td>\n",
       "      <td>7.395779e+03</td>\n",
       "      <td>8.039939e+03</td>\n",
       "      <td>8.357059e+03</td>\n",
       "      <td>8.397603e+03</td>\n",
       "      <td>8.216486e+03</td>\n",
       "      <td>7.864354e+03</td>\n",
       "      <td>7.387184e+03</td>\n",
       "      <td>6.838109e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <td>-2.042903e+00</td>\n",
       "      <td>-1.839279e+00</td>\n",
       "      <td>-1.379582e+00</td>\n",
       "      <td>-1.223072e+00</td>\n",
       "      <td>-6.477656e-01</td>\n",
       "      <td>-6.998686e-02</td>\n",
       "      <td>1.441701e-01</td>\n",
       "      <td>2.305419e-01</td>\n",
       "      <td>6.346162e-01</td>\n",
       "      <td>8.243084e-01</td>\n",
       "      <td>9.236477e-01</td>\n",
       "      <td>1.250211e+00</td>\n",
       "      <td>2.050223e+00</td>\n",
       "      <td>2.494104e+00</td>\n",
       "      <td>2.853337e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.922638e+01</td>\n",
       "      <td>1.937748e+01</td>\n",
       "      <td>1.995310e+01</td>\n",
       "      <td>2.043596e+01</td>\n",
       "      <td>2.080075e+01</td>\n",
       "      <td>2.033100e+01</td>\n",
       "      <td>2.074835e+01</td>\n",
       "      <td>2.049986e+01</td>\n",
       "      <td>2.039065e+01</td>\n",
       "      <td>2.013254e+01</td>\n",
       "      <td>1.942168e+01</td>\n",
       "      <td>1.876307e+01</td>\n",
       "      <td>1.773410e+01</td>\n",
       "      <td>1.684548e+01</td>\n",
       "      <td>1.595730e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIAN_30</th>\n",
       "      <td>4.150375e+03</td>\n",
       "      <td>4.149875e+03</td>\n",
       "      <td>4.150500e+03</td>\n",
       "      <td>4.150500e+03</td>\n",
       "      <td>4.151875e+03</td>\n",
       "      <td>4.152500e+03</td>\n",
       "      <td>4.152500e+03</td>\n",
       "      <td>4.152125e+03</td>\n",
       "      <td>4.152250e+03</td>\n",
       "      <td>4.151625e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>4.151375e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.957250e+03</td>\n",
       "      <td>5.958250e+03</td>\n",
       "      <td>5.959625e+03</td>\n",
       "      <td>5.961000e+03</td>\n",
       "      <td>5.962750e+03</td>\n",
       "      <td>5.964875e+03</td>\n",
       "      <td>5.966000e+03</td>\n",
       "      <td>5.966750e+03</td>\n",
       "      <td>5.967375e+03</td>\n",
       "      <td>5.967625e+03</td>\n",
       "      <td>5.968500e+03</td>\n",
       "      <td>5.970125e+03</td>\n",
       "      <td>5.971000e+03</td>\n",
       "      <td>5.972125e+03</td>\n",
       "      <td>5.973250e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFI_14</th>\n",
       "      <td>5.118593e+01</td>\n",
       "      <td>5.374093e+01</td>\n",
       "      <td>5.298481e+01</td>\n",
       "      <td>5.240571e+01</td>\n",
       "      <td>5.270321e+01</td>\n",
       "      <td>5.360207e+01</td>\n",
       "      <td>5.468869e+01</td>\n",
       "      <td>5.180026e+01</td>\n",
       "      <td>6.389651e+01</td>\n",
       "      <td>8.239771e+01</td>\n",
       "      <td>7.777802e+01</td>\n",
       "      <td>7.403082e+01</td>\n",
       "      <td>9.586857e+01</td>\n",
       "      <td>9.448501e+01</td>\n",
       "      <td>8.354527e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.281076e+01</td>\n",
       "      <td>9.334781e+01</td>\n",
       "      <td>9.551555e+01</td>\n",
       "      <td>9.632179e+01</td>\n",
       "      <td>9.671841e+01</td>\n",
       "      <td>8.498483e+01</td>\n",
       "      <td>8.762314e+01</td>\n",
       "      <td>9.029606e+01</td>\n",
       "      <td>9.159947e+01</td>\n",
       "      <td>9.144500e+01</td>\n",
       "      <td>9.093970e+01</td>\n",
       "      <td>9.036733e+01</td>\n",
       "      <td>9.086771e+01</td>\n",
       "      <td>9.041339e+01</td>\n",
       "      <td>9.013075e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVI_1</th>\n",
       "      <td>1.002188e+03</td>\n",
       "      <td>1.002218e+03</td>\n",
       "      <td>1.002302e+03</td>\n",
       "      <td>1.002302e+03</td>\n",
       "      <td>1.002302e+03</td>\n",
       "      <td>1.002302e+03</td>\n",
       "      <td>1.002230e+03</td>\n",
       "      <td>1.002206e+03</td>\n",
       "      <td>1.002206e+03</td>\n",
       "      <td>1.002206e+03</td>\n",
       "      <td>1.002206e+03</td>\n",
       "      <td>1.002206e+03</td>\n",
       "      <td>1.002375e+03</td>\n",
       "      <td>1.002327e+03</td>\n",
       "      <td>1.002339e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055676e+03</td>\n",
       "      <td>1.055676e+03</td>\n",
       "      <td>1.055676e+03</td>\n",
       "      <td>1.055730e+03</td>\n",
       "      <td>1.055776e+03</td>\n",
       "      <td>1.055776e+03</td>\n",
       "      <td>1.055776e+03</td>\n",
       "      <td>1.055776e+03</td>\n",
       "      <td>1.055843e+03</td>\n",
       "      <td>1.055855e+03</td>\n",
       "      <td>1.055855e+03</td>\n",
       "      <td>1.055855e+03</td>\n",
       "      <td>1.055793e+03</td>\n",
       "      <td>1.055818e+03</td>\n",
       "      <td>1.055818e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGO_14</th>\n",
       "      <td>-3.525100e-01</td>\n",
       "      <td>-1.529799e-01</td>\n",
       "      <td>2.745441e-01</td>\n",
       "      <td>1.374858e-01</td>\n",
       "      <td>7.466142e-01</td>\n",
       "      <td>9.387765e-01</td>\n",
       "      <td>6.384930e-01</td>\n",
       "      <td>5.415404e-01</td>\n",
       "      <td>7.799757e-01</td>\n",
       "      <td>5.198066e-01</td>\n",
       "      <td>3.976809e-01</td>\n",
       "      <td>6.655036e-01</td>\n",
       "      <td>1.250380e+00</td>\n",
       "      <td>9.244613e-01</td>\n",
       "      <td>8.664028e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.040623e-01</td>\n",
       "      <td>1.249365e+00</td>\n",
       "      <td>1.712068e+00</td>\n",
       "      <td>1.776094e+00</td>\n",
       "      <td>1.819342e+00</td>\n",
       "      <td>1.200681e+00</td>\n",
       "      <td>1.977739e+00</td>\n",
       "      <td>1.466952e+00</td>\n",
       "      <td>1.537809e+00</td>\n",
       "      <td>1.391676e+00</td>\n",
       "      <td>9.290368e-01</td>\n",
       "      <td>8.694947e-01</td>\n",
       "      <td>4.001619e-01</td>\n",
       "      <td>3.572166e-01</td>\n",
       "      <td>1.834141e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVIe_255</th>\n",
       "      <td>2.667326e+01</td>\n",
       "      <td>2.041344e+01</td>\n",
       "      <td>1.003936e+01</td>\n",
       "      <td>8.548557e-01</td>\n",
       "      <td>-6.857376e+00</td>\n",
       "      <td>-1.366399e+01</td>\n",
       "      <td>-2.025853e+01</td>\n",
       "      <td>-2.651279e+01</td>\n",
       "      <td>-3.206708e+01</td>\n",
       "      <td>-3.690917e+01</td>\n",
       "      <td>-4.092875e+01</td>\n",
       "      <td>-4.073107e+01</td>\n",
       "      <td>-4.228160e+01</td>\n",
       "      <td>-4.369558e+01</td>\n",
       "      <td>-4.600834e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000087e+02</td>\n",
       "      <td>1.000103e+02</td>\n",
       "      <td>1.000113e+02</td>\n",
       "      <td>1.000112e+02</td>\n",
       "      <td>1.000112e+02</td>\n",
       "      <td>1.000102e+02</td>\n",
       "      <td>1.000118e+02</td>\n",
       "      <td>1.000112e+02</td>\n",
       "      <td>1.000111e+02</td>\n",
       "      <td>1.000110e+02</td>\n",
       "      <td>1.000104e+02</td>\n",
       "      <td>1.000106e+02</td>\n",
       "      <td>1.000105e+02</td>\n",
       "      <td>1.000104e+02</td>\n",
       "      <td>1.000103e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVOs_12_26_9</th>\n",
       "      <td>1.280821e+01</td>\n",
       "      <td>1.432925e+01</td>\n",
       "      <td>1.347127e+01</td>\n",
       "      <td>1.094799e+01</td>\n",
       "      <td>7.386917e+00</td>\n",
       "      <td>3.176735e+00</td>\n",
       "      <td>-1.510318e+00</td>\n",
       "      <td>-6.510813e+00</td>\n",
       "      <td>-1.162207e+01</td>\n",
       "      <td>-1.667949e+01</td>\n",
       "      <td>-2.152934e+01</td>\n",
       "      <td>-2.536968e+01</td>\n",
       "      <td>-2.875207e+01</td>\n",
       "      <td>-3.174077e+01</td>\n",
       "      <td>-3.459429e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.644379e+01</td>\n",
       "      <td>-3.125328e+01</td>\n",
       "      <td>-2.344944e+01</td>\n",
       "      <td>-1.620705e+01</td>\n",
       "      <td>-1.046451e+01</td>\n",
       "      <td>-5.711872e+00</td>\n",
       "      <td>-4.244935e-01</td>\n",
       "      <td>5.915452e+00</td>\n",
       "      <td>9.847815e+00</td>\n",
       "      <td>1.082991e+01</td>\n",
       "      <td>9.741585e+00</td>\n",
       "      <td>7.200476e+00</td>\n",
       "      <td>3.648669e+00</td>\n",
       "      <td>-6.170698e-01</td>\n",
       "      <td>-5.329524e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVT</th>\n",
       "      <td>-9.885405e+05</td>\n",
       "      <td>-9.866675e+05</td>\n",
       "      <td>-9.866675e+05</td>\n",
       "      <td>-9.868605e+05</td>\n",
       "      <td>-9.857558e+05</td>\n",
       "      <td>-9.854252e+05</td>\n",
       "      <td>-9.858313e+05</td>\n",
       "      <td>-9.859192e+05</td>\n",
       "      <td>-9.854982e+05</td>\n",
       "      <td>-9.856720e+05</td>\n",
       "      <td>-9.857456e+05</td>\n",
       "      <td>-9.840725e+05</td>\n",
       "      <td>-9.817743e+05</td>\n",
       "      <td>-9.823903e+05</td>\n",
       "      <td>-9.822878e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.634002e+05</td>\n",
       "      <td>-3.320480e+05</td>\n",
       "      <td>-3.096950e+05</td>\n",
       "      <td>-3.039316e+05</td>\n",
       "      <td>-3.005023e+05</td>\n",
       "      <td>-3.097224e+05</td>\n",
       "      <td>-2.765849e+05</td>\n",
       "      <td>-2.935414e+05</td>\n",
       "      <td>-2.888448e+05</td>\n",
       "      <td>-2.888448e+05</td>\n",
       "      <td>-2.891228e+05</td>\n",
       "      <td>-2.889784e+05</td>\n",
       "      <td>-2.893096e+05</td>\n",
       "      <td>-2.892207e+05</td>\n",
       "      <td>-2.892207e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQE_14_5_4.236</th>\n",
       "      <td>5.063408e+01</td>\n",
       "      <td>5.063408e+01</td>\n",
       "      <td>5.063408e+01</td>\n",
       "      <td>5.063408e+01</td>\n",
       "      <td>5.063408e+01</td>\n",
       "      <td>4.543667e+01</td>\n",
       "      <td>4.555952e+01</td>\n",
       "      <td>4.555952e+01</td>\n",
       "      <td>4.643741e+01</td>\n",
       "      <td>4.671230e+01</td>\n",
       "      <td>4.678628e+01</td>\n",
       "      <td>4.780087e+01</td>\n",
       "      <td>5.026645e+01</td>\n",
       "      <td>5.121144e+01</td>\n",
       "      <td>5.200040e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.355084e+01</td>\n",
       "      <td>7.355084e+01</td>\n",
       "      <td>7.355084e+01</td>\n",
       "      <td>6.942779e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.081797e+01</td>\n",
       "      <td>7.502906e+01</td>\n",
       "      <td>7.414827e+01</td>\n",
       "      <td>7.354265e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMAP_0.0_100.0_-1.0_1.0</th>\n",
       "      <td>8.188000e+01</td>\n",
       "      <td>8.190500e+01</td>\n",
       "      <td>8.197500e+01</td>\n",
       "      <td>8.192000e+01</td>\n",
       "      <td>8.203000e+01</td>\n",
       "      <td>8.206000e+01</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>8.198000e+01</td>\n",
       "      <td>8.206500e+01</td>\n",
       "      <td>8.203500e+01</td>\n",
       "      <td>8.202500e+01</td>\n",
       "      <td>8.209000e+01</td>\n",
       "      <td>8.223000e+01</td>\n",
       "      <td>8.219000e+01</td>\n",
       "      <td>8.220000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.184650e+02</td>\n",
       "      <td>1.187200e+02</td>\n",
       "      <td>1.188900e+02</td>\n",
       "      <td>1.189550e+02</td>\n",
       "      <td>1.190100e+02</td>\n",
       "      <td>1.188800e+02</td>\n",
       "      <td>1.191350e+02</td>\n",
       "      <td>1.190500e+02</td>\n",
       "      <td>1.191300e+02</td>\n",
       "      <td>1.191450e+02</td>\n",
       "      <td>1.190750e+02</td>\n",
       "      <td>1.191050e+02</td>\n",
       "      <td>1.190300e+02</td>\n",
       "      <td>1.190600e+02</td>\n",
       "      <td>1.190600e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI_14</th>\n",
       "      <td>4.823821e+01</td>\n",
       "      <td>4.908719e+01</td>\n",
       "      <td>5.148655e+01</td>\n",
       "      <td>4.951218e+01</td>\n",
       "      <td>5.336404e+01</td>\n",
       "      <td>5.438614e+01</td>\n",
       "      <td>5.193457e+01</td>\n",
       "      <td>5.110757e+01</td>\n",
       "      <td>5.442890e+01</td>\n",
       "      <td>5.305892e+01</td>\n",
       "      <td>5.258380e+01</td>\n",
       "      <td>5.538062e+01</td>\n",
       "      <td>6.075057e+01</td>\n",
       "      <td>5.858126e+01</td>\n",
       "      <td>5.897566e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.950855e+01</td>\n",
       "      <td>7.412439e+01</td>\n",
       "      <td>7.666097e+01</td>\n",
       "      <td>7.756651e+01</td>\n",
       "      <td>7.833257e+01</td>\n",
       "      <td>7.206823e+01</td>\n",
       "      <td>7.610490e+01</td>\n",
       "      <td>7.235141e+01</td>\n",
       "      <td>7.366774e+01</td>\n",
       "      <td>7.391848e+01</td>\n",
       "      <td>7.054274e+01</td>\n",
       "      <td>7.115082e+01</td>\n",
       "      <td>6.740472e+01</td>\n",
       "      <td>6.812759e+01</td>\n",
       "      <td>6.812759e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSX_14</th>\n",
       "      <td>3.636083e+01</td>\n",
       "      <td>3.879892e+01</td>\n",
       "      <td>4.162162e+01</td>\n",
       "      <td>4.399646e+01</td>\n",
       "      <td>4.691764e+01</td>\n",
       "      <td>5.009676e+01</td>\n",
       "      <td>5.258423e+01</td>\n",
       "      <td>5.429891e+01</td>\n",
       "      <td>5.628518e+01</td>\n",
       "      <td>5.787393e+01</td>\n",
       "      <td>5.899489e+01</td>\n",
       "      <td>6.050834e+01</td>\n",
       "      <td>6.365827e+01</td>\n",
       "      <td>6.646606e+01</td>\n",
       "      <td>6.886907e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.507449e+01</td>\n",
       "      <td>6.881229e+01</td>\n",
       "      <td>7.458174e+01</td>\n",
       "      <td>8.036372e+01</td>\n",
       "      <td>8.530430e+01</td>\n",
       "      <td>8.623272e+01</td>\n",
       "      <td>8.629864e+01</td>\n",
       "      <td>8.450356e+01</td>\n",
       "      <td>8.269691e+01</td>\n",
       "      <td>8.125428e+01</td>\n",
       "      <td>7.907256e+01</td>\n",
       "      <td>7.696025e+01</td>\n",
       "      <td>7.395762e+01</td>\n",
       "      <td>7.099563e+01</td>\n",
       "      <td>6.829002e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RVGI_14_4</th>\n",
       "      <td>-1.319969e-01</td>\n",
       "      <td>-1.120178e-01</td>\n",
       "      <td>-9.531936e-02</td>\n",
       "      <td>-9.277079e-02</td>\n",
       "      <td>-9.235028e-02</td>\n",
       "      <td>-8.220230e-02</td>\n",
       "      <td>-5.003930e-02</td>\n",
       "      <td>-1.261657e-02</td>\n",
       "      <td>4.416592e-02</td>\n",
       "      <td>1.133467e-01</td>\n",
       "      <td>1.638225e-01</td>\n",
       "      <td>1.709651e-01</td>\n",
       "      <td>1.727795e-01</td>\n",
       "      <td>2.109228e-01</td>\n",
       "      <td>2.429954e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023827e-01</td>\n",
       "      <td>1.240573e-01</td>\n",
       "      <td>1.854329e-01</td>\n",
       "      <td>2.490076e-01</td>\n",
       "      <td>2.794944e-01</td>\n",
       "      <td>2.699282e-01</td>\n",
       "      <td>2.526144e-01</td>\n",
       "      <td>2.394753e-01</td>\n",
       "      <td>2.476489e-01</td>\n",
       "      <td>2.621413e-01</td>\n",
       "      <td>2.644284e-01</td>\n",
       "      <td>2.553011e-01</td>\n",
       "      <td>2.345183e-01</td>\n",
       "      <td>2.184874e-01</td>\n",
       "      <td>2.092199e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SINWMA_14</th>\n",
       "      <td>4.146042e+03</td>\n",
       "      <td>4.144197e+03</td>\n",
       "      <td>4.142741e+03</td>\n",
       "      <td>4.141822e+03</td>\n",
       "      <td>4.141593e+03</td>\n",
       "      <td>4.142108e+03</td>\n",
       "      <td>4.143154e+03</td>\n",
       "      <td>4.144406e+03</td>\n",
       "      <td>4.145920e+03</td>\n",
       "      <td>4.147098e+03</td>\n",
       "      <td>4.148108e+03</td>\n",
       "      <td>4.149091e+03</td>\n",
       "      <td>4.150191e+03</td>\n",
       "      <td>4.151167e+03</td>\n",
       "      <td>4.152196e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.966313e+03</td>\n",
       "      <td>5.967751e+03</td>\n",
       "      <td>5.969445e+03</td>\n",
       "      <td>5.971563e+03</td>\n",
       "      <td>5.974032e+03</td>\n",
       "      <td>5.976719e+03</td>\n",
       "      <td>5.979823e+03</td>\n",
       "      <td>5.983191e+03</td>\n",
       "      <td>5.986720e+03</td>\n",
       "      <td>5.990147e+03</td>\n",
       "      <td>5.993381e+03</td>\n",
       "      <td>5.996309e+03</td>\n",
       "      <td>5.998798e+03</td>\n",
       "      <td>6.000771e+03</td>\n",
       "      <td>6.002191e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKEW_30</th>\n",
       "      <td>-5.068092e-01</td>\n",
       "      <td>-4.768601e-01</td>\n",
       "      <td>-5.744812e-01</td>\n",
       "      <td>-6.243520e-01</td>\n",
       "      <td>-7.356147e-01</td>\n",
       "      <td>-6.835443e-01</td>\n",
       "      <td>-7.530572e-01</td>\n",
       "      <td>-7.162102e-01</td>\n",
       "      <td>-7.208955e-01</td>\n",
       "      <td>-6.939644e-01</td>\n",
       "      <td>-6.506129e-01</td>\n",
       "      <td>-6.555396e-01</td>\n",
       "      <td>-6.413590e-01</td>\n",
       "      <td>-6.451062e-01</td>\n",
       "      <td>-6.465694e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.182607e-01</td>\n",
       "      <td>-8.495784e-01</td>\n",
       "      <td>-6.180142e-01</td>\n",
       "      <td>-4.487516e-01</td>\n",
       "      <td>-3.694177e-01</td>\n",
       "      <td>-4.189862e-01</td>\n",
       "      <td>-3.539377e-01</td>\n",
       "      <td>-4.057929e-01</td>\n",
       "      <td>-2.981428e-02</td>\n",
       "      <td>3.743399e-01</td>\n",
       "      <td>4.159029e-01</td>\n",
       "      <td>4.265290e-01</td>\n",
       "      <td>3.277945e-01</td>\n",
       "      <td>2.215375e-01</td>\n",
       "      <td>9.341712e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMIo_5_20_5_1.0</th>\n",
       "      <td>2.336892e-02</td>\n",
       "      <td>3.125081e-02</td>\n",
       "      <td>4.505079e-02</td>\n",
       "      <td>3.537681e-02</td>\n",
       "      <td>4.958129e-02</td>\n",
       "      <td>5.586475e-02</td>\n",
       "      <td>3.856037e-02</td>\n",
       "      <td>2.183574e-02</td>\n",
       "      <td>3.105540e-02</td>\n",
       "      <td>2.363784e-02</td>\n",
       "      <td>1.494733e-02</td>\n",
       "      <td>2.570045e-02</td>\n",
       "      <td>6.125374e-02</td>\n",
       "      <td>5.520772e-02</td>\n",
       "      <td>4.829349e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.108658e-02</td>\n",
       "      <td>4.280662e-02</td>\n",
       "      <td>6.874518e-02</td>\n",
       "      <td>7.633023e-02</td>\n",
       "      <td>7.483614e-02</td>\n",
       "      <td>2.445328e-02</td>\n",
       "      <td>2.472880e-02</td>\n",
       "      <td>-3.127772e-03</td>\n",
       "      <td>-6.304254e-03</td>\n",
       "      <td>-5.370630e-03</td>\n",
       "      <td>-2.506413e-02</td>\n",
       "      <td>-2.729563e-02</td>\n",
       "      <td>-4.828700e-02</td>\n",
       "      <td>-4.783649e-02</td>\n",
       "      <td>-4.237481e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSF_20</th>\n",
       "      <td>4.144125e+03</td>\n",
       "      <td>4.143338e+03</td>\n",
       "      <td>4.143053e+03</td>\n",
       "      <td>4.143130e+03</td>\n",
       "      <td>4.143516e+03</td>\n",
       "      <td>4.144288e+03</td>\n",
       "      <td>4.145217e+03</td>\n",
       "      <td>4.146069e+03</td>\n",
       "      <td>4.146919e+03</td>\n",
       "      <td>4.147800e+03</td>\n",
       "      <td>4.148586e+03</td>\n",
       "      <td>4.149348e+03</td>\n",
       "      <td>4.150356e+03</td>\n",
       "      <td>4.151612e+03</td>\n",
       "      <td>4.152905e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.967594e+03</td>\n",
       "      <td>5.969037e+03</td>\n",
       "      <td>5.971235e+03</td>\n",
       "      <td>5.974140e+03</td>\n",
       "      <td>5.977502e+03</td>\n",
       "      <td>5.980844e+03</td>\n",
       "      <td>5.984160e+03</td>\n",
       "      <td>5.987515e+03</td>\n",
       "      <td>5.990686e+03</td>\n",
       "      <td>5.993692e+03</td>\n",
       "      <td>5.996329e+03</td>\n",
       "      <td>5.998510e+03</td>\n",
       "      <td>6.000201e+03</td>\n",
       "      <td>6.001409e+03</td>\n",
       "      <td>6.002278e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <td>4.219858e+01</td>\n",
       "      <td>4.929078e+01</td>\n",
       "      <td>5.212766e+01</td>\n",
       "      <td>5.354610e+01</td>\n",
       "      <td>5.904850e+01</td>\n",
       "      <td>6.502346e+01</td>\n",
       "      <td>7.053914e+01</td>\n",
       "      <td>7.555596e+01</td>\n",
       "      <td>8.184679e+01</td>\n",
       "      <td>8.873664e+01</td>\n",
       "      <td>9.060843e+01</td>\n",
       "      <td>8.842816e+01</td>\n",
       "      <td>9.143807e+01</td>\n",
       "      <td>8.958405e+01</td>\n",
       "      <td>8.705400e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.941286e+01</td>\n",
       "      <td>9.172888e+01</td>\n",
       "      <td>9.298230e+01</td>\n",
       "      <td>9.657048e+01</td>\n",
       "      <td>9.611517e+01</td>\n",
       "      <td>9.137308e+01</td>\n",
       "      <td>9.259259e+01</td>\n",
       "      <td>8.725056e+01</td>\n",
       "      <td>8.932171e+01</td>\n",
       "      <td>8.536982e+01</td>\n",
       "      <td>8.549112e+01</td>\n",
       "      <td>8.430372e+01</td>\n",
       "      <td>7.992228e+01</td>\n",
       "      <td>7.906623e+01</td>\n",
       "      <td>7.648378e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <td>4.024823e+01</td>\n",
       "      <td>4.408983e+01</td>\n",
       "      <td>4.787234e+01</td>\n",
       "      <td>5.165485e+01</td>\n",
       "      <td>5.490742e+01</td>\n",
       "      <td>5.920602e+01</td>\n",
       "      <td>6.487037e+01</td>\n",
       "      <td>7.037285e+01</td>\n",
       "      <td>7.598063e+01</td>\n",
       "      <td>8.204646e+01</td>\n",
       "      <td>8.706396e+01</td>\n",
       "      <td>8.925775e+01</td>\n",
       "      <td>9.015822e+01</td>\n",
       "      <td>8.981676e+01</td>\n",
       "      <td>8.935870e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.929195e+01</td>\n",
       "      <td>9.077733e+01</td>\n",
       "      <td>9.137468e+01</td>\n",
       "      <td>9.376055e+01</td>\n",
       "      <td>9.522265e+01</td>\n",
       "      <td>9.468624e+01</td>\n",
       "      <td>9.336028e+01</td>\n",
       "      <td>9.040541e+01</td>\n",
       "      <td>8.972162e+01</td>\n",
       "      <td>8.731403e+01</td>\n",
       "      <td>8.672755e+01</td>\n",
       "      <td>8.505488e+01</td>\n",
       "      <td>8.323904e+01</td>\n",
       "      <td>8.109741e+01</td>\n",
       "      <td>7.849076e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHFd_14_3</th>\n",
       "      <td>4.219858e+01</td>\n",
       "      <td>4.929078e+01</td>\n",
       "      <td>5.212766e+01</td>\n",
       "      <td>5.354610e+01</td>\n",
       "      <td>5.904850e+01</td>\n",
       "      <td>6.502346e+01</td>\n",
       "      <td>7.053914e+01</td>\n",
       "      <td>7.555596e+01</td>\n",
       "      <td>8.184679e+01</td>\n",
       "      <td>8.873664e+01</td>\n",
       "      <td>9.060843e+01</td>\n",
       "      <td>8.842816e+01</td>\n",
       "      <td>9.143807e+01</td>\n",
       "      <td>8.958405e+01</td>\n",
       "      <td>8.705400e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.941286e+01</td>\n",
       "      <td>9.172888e+01</td>\n",
       "      <td>9.298230e+01</td>\n",
       "      <td>9.657048e+01</td>\n",
       "      <td>9.611517e+01</td>\n",
       "      <td>9.137308e+01</td>\n",
       "      <td>9.259259e+01</td>\n",
       "      <td>8.725056e+01</td>\n",
       "      <td>8.932171e+01</td>\n",
       "      <td>8.536982e+01</td>\n",
       "      <td>8.549112e+01</td>\n",
       "      <td>8.430372e+01</td>\n",
       "      <td>7.992228e+01</td>\n",
       "      <td>7.906623e+01</td>\n",
       "      <td>7.648378e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3_10_0.7</th>\n",
       "      <td>4.146612e+03</td>\n",
       "      <td>4.144919e+03</td>\n",
       "      <td>4.143747e+03</td>\n",
       "      <td>4.143008e+03</td>\n",
       "      <td>4.142742e+03</td>\n",
       "      <td>4.142933e+03</td>\n",
       "      <td>4.143432e+03</td>\n",
       "      <td>4.144095e+03</td>\n",
       "      <td>4.144920e+03</td>\n",
       "      <td>4.145834e+03</td>\n",
       "      <td>4.146760e+03</td>\n",
       "      <td>4.147722e+03</td>\n",
       "      <td>4.148871e+03</td>\n",
       "      <td>4.150172e+03</td>\n",
       "      <td>4.151573e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.973364e+03</td>\n",
       "      <td>5.974276e+03</td>\n",
       "      <td>5.975717e+03</td>\n",
       "      <td>5.977751e+03</td>\n",
       "      <td>5.980328e+03</td>\n",
       "      <td>5.983132e+03</td>\n",
       "      <td>5.986226e+03</td>\n",
       "      <td>5.989422e+03</td>\n",
       "      <td>5.992646e+03</td>\n",
       "      <td>5.995808e+03</td>\n",
       "      <td>5.998724e+03</td>\n",
       "      <td>6.001325e+03</td>\n",
       "      <td>6.003480e+03</td>\n",
       "      <td>6.005187e+03</td>\n",
       "      <td>6.006475e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THERMOma_20_2_0.5</th>\n",
       "      <td>7.262301e+00</td>\n",
       "      <td>7.023034e+00</td>\n",
       "      <td>6.711317e+00</td>\n",
       "      <td>6.286429e+00</td>\n",
       "      <td>5.997245e+00</td>\n",
       "      <td>5.949889e+00</td>\n",
       "      <td>5.621328e+00</td>\n",
       "      <td>5.347868e+00</td>\n",
       "      <td>5.124262e+00</td>\n",
       "      <td>4.802903e+00</td>\n",
       "      <td>4.488341e+00</td>\n",
       "      <td>4.560880e+00</td>\n",
       "      <td>4.507463e+00</td>\n",
       "      <td>4.625800e+00</td>\n",
       "      <td>4.375724e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.451499e+00</td>\n",
       "      <td>5.860880e+00</td>\n",
       "      <td>6.540797e+00</td>\n",
       "      <td>6.227387e+00</td>\n",
       "      <td>6.277160e+00</td>\n",
       "      <td>6.250764e+00</td>\n",
       "      <td>6.203072e+00</td>\n",
       "      <td>6.850399e+00</td>\n",
       "      <td>6.531313e+00</td>\n",
       "      <td>5.980712e+00</td>\n",
       "      <td>5.530168e+00</td>\n",
       "      <td>5.313009e+00</td>\n",
       "      <td>4.926056e+00</td>\n",
       "      <td>4.718812e+00</td>\n",
       "      <td>4.364640e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMO_14_5_3</th>\n",
       "      <td>-8.602935e+00</td>\n",
       "      <td>-7.135148e+00</td>\n",
       "      <td>-4.790027e+00</td>\n",
       "      <td>-2.876649e+00</td>\n",
       "      <td>-4.260819e-01</td>\n",
       "      <td>2.128454e+00</td>\n",
       "      <td>4.291891e+00</td>\n",
       "      <td>5.964388e+00</td>\n",
       "      <td>7.861155e+00</td>\n",
       "      <td>9.183219e+00</td>\n",
       "      <td>9.593370e+00</td>\n",
       "      <td>1.046453e+01</td>\n",
       "      <td>1.134416e+01</td>\n",
       "      <td>1.208001e+01</td>\n",
       "      <td>1.231196e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277640e+01</td>\n",
       "      <td>1.314110e+01</td>\n",
       "      <td>1.340582e+01</td>\n",
       "      <td>1.359309e+01</td>\n",
       "      <td>1.372333e+01</td>\n",
       "      <td>1.314619e+01</td>\n",
       "      <td>1.309611e+01</td>\n",
       "      <td>1.323007e+01</td>\n",
       "      <td>1.306971e+01</td>\n",
       "      <td>1.317130e+01</td>\n",
       "      <td>1.267662e+01</td>\n",
       "      <td>1.173229e+01</td>\n",
       "      <td>1.012879e+01</td>\n",
       "      <td>8.572832e+00</td>\n",
       "      <td>7.292039e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMOs_14_5_3</th>\n",
       "      <td>-8.954656e+00</td>\n",
       "      <td>-8.044902e+00</td>\n",
       "      <td>-6.417465e+00</td>\n",
       "      <td>-4.647057e+00</td>\n",
       "      <td>-2.536569e+00</td>\n",
       "      <td>-2.040576e-01</td>\n",
       "      <td>2.043917e+00</td>\n",
       "      <td>4.004152e+00</td>\n",
       "      <td>5.932654e+00</td>\n",
       "      <td>7.557936e+00</td>\n",
       "      <td>8.575653e+00</td>\n",
       "      <td>9.520089e+00</td>\n",
       "      <td>1.043212e+01</td>\n",
       "      <td>1.125607e+01</td>\n",
       "      <td>1.178401e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231051e+01</td>\n",
       "      <td>1.272581e+01</td>\n",
       "      <td>1.306581e+01</td>\n",
       "      <td>1.332945e+01</td>\n",
       "      <td>1.352639e+01</td>\n",
       "      <td>1.333629e+01</td>\n",
       "      <td>1.321620e+01</td>\n",
       "      <td>1.322313e+01</td>\n",
       "      <td>1.314642e+01</td>\n",
       "      <td>1.315886e+01</td>\n",
       "      <td>1.291774e+01</td>\n",
       "      <td>1.232501e+01</td>\n",
       "      <td>1.122690e+01</td>\n",
       "      <td>9.899868e+00</td>\n",
       "      <td>8.595953e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_LR</th>\n",
       "      <td>4.143850e+03</td>\n",
       "      <td>4.144042e+03</td>\n",
       "      <td>4.144233e+03</td>\n",
       "      <td>4.144424e+03</td>\n",
       "      <td>4.144615e+03</td>\n",
       "      <td>4.144806e+03</td>\n",
       "      <td>4.144998e+03</td>\n",
       "      <td>4.145189e+03</td>\n",
       "      <td>4.145380e+03</td>\n",
       "      <td>4.145571e+03</td>\n",
       "      <td>4.145762e+03</td>\n",
       "      <td>4.145954e+03</td>\n",
       "      <td>4.146145e+03</td>\n",
       "      <td>4.146336e+03</td>\n",
       "      <td>4.146527e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.781979e+03</td>\n",
       "      <td>5.782170e+03</td>\n",
       "      <td>5.782361e+03</td>\n",
       "      <td>5.782552e+03</td>\n",
       "      <td>5.782743e+03</td>\n",
       "      <td>5.782935e+03</td>\n",
       "      <td>5.783126e+03</td>\n",
       "      <td>5.783317e+03</td>\n",
       "      <td>5.783508e+03</td>\n",
       "      <td>5.783700e+03</td>\n",
       "      <td>5.783891e+03</td>\n",
       "      <td>5.784082e+03</td>\n",
       "      <td>5.784273e+03</td>\n",
       "      <td>5.784464e+03</td>\n",
       "      <td>5.784656e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_L_1</th>\n",
       "      <td>3.516495e+03</td>\n",
       "      <td>3.516687e+03</td>\n",
       "      <td>3.516878e+03</td>\n",
       "      <td>3.517069e+03</td>\n",
       "      <td>3.517260e+03</td>\n",
       "      <td>3.517451e+03</td>\n",
       "      <td>3.517643e+03</td>\n",
       "      <td>3.517834e+03</td>\n",
       "      <td>3.518025e+03</td>\n",
       "      <td>3.518216e+03</td>\n",
       "      <td>3.518407e+03</td>\n",
       "      <td>3.518599e+03</td>\n",
       "      <td>3.518790e+03</td>\n",
       "      <td>3.518981e+03</td>\n",
       "      <td>3.519172e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.154624e+03</td>\n",
       "      <td>5.154815e+03</td>\n",
       "      <td>5.155006e+03</td>\n",
       "      <td>5.155197e+03</td>\n",
       "      <td>5.155388e+03</td>\n",
       "      <td>5.155580e+03</td>\n",
       "      <td>5.155771e+03</td>\n",
       "      <td>5.155962e+03</td>\n",
       "      <td>5.156153e+03</td>\n",
       "      <td>5.156345e+03</td>\n",
       "      <td>5.156536e+03</td>\n",
       "      <td>5.156727e+03</td>\n",
       "      <td>5.156918e+03</td>\n",
       "      <td>5.157109e+03</td>\n",
       "      <td>5.157301e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_U_1</th>\n",
       "      <td>4.771205e+03</td>\n",
       "      <td>4.771396e+03</td>\n",
       "      <td>4.771588e+03</td>\n",
       "      <td>4.771779e+03</td>\n",
       "      <td>4.771970e+03</td>\n",
       "      <td>4.772161e+03</td>\n",
       "      <td>4.772353e+03</td>\n",
       "      <td>4.772544e+03</td>\n",
       "      <td>4.772735e+03</td>\n",
       "      <td>4.772926e+03</td>\n",
       "      <td>4.773117e+03</td>\n",
       "      <td>4.773309e+03</td>\n",
       "      <td>4.773500e+03</td>\n",
       "      <td>4.773691e+03</td>\n",
       "      <td>4.773882e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.409334e+03</td>\n",
       "      <td>6.409525e+03</td>\n",
       "      <td>6.409716e+03</td>\n",
       "      <td>6.409907e+03</td>\n",
       "      <td>6.410098e+03</td>\n",
       "      <td>6.410290e+03</td>\n",
       "      <td>6.410481e+03</td>\n",
       "      <td>6.410672e+03</td>\n",
       "      <td>6.410863e+03</td>\n",
       "      <td>6.411054e+03</td>\n",
       "      <td>6.411246e+03</td>\n",
       "      <td>6.411437e+03</td>\n",
       "      <td>6.411628e+03</td>\n",
       "      <td>6.411819e+03</td>\n",
       "      <td>6.412011e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_L_2</th>\n",
       "      <td>2.889140e+03</td>\n",
       "      <td>2.889332e+03</td>\n",
       "      <td>2.889523e+03</td>\n",
       "      <td>2.889714e+03</td>\n",
       "      <td>2.889905e+03</td>\n",
       "      <td>2.890096e+03</td>\n",
       "      <td>2.890288e+03</td>\n",
       "      <td>2.890479e+03</td>\n",
       "      <td>2.890670e+03</td>\n",
       "      <td>2.890861e+03</td>\n",
       "      <td>2.891053e+03</td>\n",
       "      <td>2.891244e+03</td>\n",
       "      <td>2.891435e+03</td>\n",
       "      <td>2.891626e+03</td>\n",
       "      <td>2.891817e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.527269e+03</td>\n",
       "      <td>4.527460e+03</td>\n",
       "      <td>4.527651e+03</td>\n",
       "      <td>4.527842e+03</td>\n",
       "      <td>4.528034e+03</td>\n",
       "      <td>4.528225e+03</td>\n",
       "      <td>4.528416e+03</td>\n",
       "      <td>4.528607e+03</td>\n",
       "      <td>4.528798e+03</td>\n",
       "      <td>4.528990e+03</td>\n",
       "      <td>4.529181e+03</td>\n",
       "      <td>4.529372e+03</td>\n",
       "      <td>4.529563e+03</td>\n",
       "      <td>4.529754e+03</td>\n",
       "      <td>4.529946e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_U_2</th>\n",
       "      <td>5.398560e+03</td>\n",
       "      <td>5.398751e+03</td>\n",
       "      <td>5.398943e+03</td>\n",
       "      <td>5.399134e+03</td>\n",
       "      <td>5.399325e+03</td>\n",
       "      <td>5.399516e+03</td>\n",
       "      <td>5.399708e+03</td>\n",
       "      <td>5.399899e+03</td>\n",
       "      <td>5.400090e+03</td>\n",
       "      <td>5.400281e+03</td>\n",
       "      <td>5.400472e+03</td>\n",
       "      <td>5.400664e+03</td>\n",
       "      <td>5.400855e+03</td>\n",
       "      <td>5.401046e+03</td>\n",
       "      <td>5.401237e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.036689e+03</td>\n",
       "      <td>7.036880e+03</td>\n",
       "      <td>7.037071e+03</td>\n",
       "      <td>7.037262e+03</td>\n",
       "      <td>7.037453e+03</td>\n",
       "      <td>7.037645e+03</td>\n",
       "      <td>7.037836e+03</td>\n",
       "      <td>7.038027e+03</td>\n",
       "      <td>7.038218e+03</td>\n",
       "      <td>7.038409e+03</td>\n",
       "      <td>7.038601e+03</td>\n",
       "      <td>7.038792e+03</td>\n",
       "      <td>7.038983e+03</td>\n",
       "      <td>7.039174e+03</td>\n",
       "      <td>7.039366e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_L_3</th>\n",
       "      <td>2.261785e+03</td>\n",
       "      <td>2.261977e+03</td>\n",
       "      <td>2.262168e+03</td>\n",
       "      <td>2.262359e+03</td>\n",
       "      <td>2.262550e+03</td>\n",
       "      <td>2.262741e+03</td>\n",
       "      <td>2.262933e+03</td>\n",
       "      <td>2.263124e+03</td>\n",
       "      <td>2.263315e+03</td>\n",
       "      <td>2.263506e+03</td>\n",
       "      <td>2.263698e+03</td>\n",
       "      <td>2.263889e+03</td>\n",
       "      <td>2.264080e+03</td>\n",
       "      <td>2.264271e+03</td>\n",
       "      <td>2.264462e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.899914e+03</td>\n",
       "      <td>3.900105e+03</td>\n",
       "      <td>3.900296e+03</td>\n",
       "      <td>3.900487e+03</td>\n",
       "      <td>3.900679e+03</td>\n",
       "      <td>3.900870e+03</td>\n",
       "      <td>3.901061e+03</td>\n",
       "      <td>3.901252e+03</td>\n",
       "      <td>3.901443e+03</td>\n",
       "      <td>3.901635e+03</td>\n",
       "      <td>3.901826e+03</td>\n",
       "      <td>3.902017e+03</td>\n",
       "      <td>3.902208e+03</td>\n",
       "      <td>3.902399e+03</td>\n",
       "      <td>3.902591e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOS_STDEVALL_U_3</th>\n",
       "      <td>6.025915e+03</td>\n",
       "      <td>6.026106e+03</td>\n",
       "      <td>6.026298e+03</td>\n",
       "      <td>6.026489e+03</td>\n",
       "      <td>6.026680e+03</td>\n",
       "      <td>6.026871e+03</td>\n",
       "      <td>6.027062e+03</td>\n",
       "      <td>6.027254e+03</td>\n",
       "      <td>6.027445e+03</td>\n",
       "      <td>6.027636e+03</td>\n",
       "      <td>6.027827e+03</td>\n",
       "      <td>6.028019e+03</td>\n",
       "      <td>6.028210e+03</td>\n",
       "      <td>6.028401e+03</td>\n",
       "      <td>6.028592e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.664043e+03</td>\n",
       "      <td>7.664235e+03</td>\n",
       "      <td>7.664426e+03</td>\n",
       "      <td>7.664617e+03</td>\n",
       "      <td>7.664808e+03</td>\n",
       "      <td>7.665000e+03</td>\n",
       "      <td>7.665191e+03</td>\n",
       "      <td>7.665382e+03</td>\n",
       "      <td>7.665573e+03</td>\n",
       "      <td>7.665764e+03</td>\n",
       "      <td>7.665956e+03</td>\n",
       "      <td>7.666147e+03</td>\n",
       "      <td>7.666338e+03</td>\n",
       "      <td>7.666529e+03</td>\n",
       "      <td>7.666720e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRENDFLEX_20_20_0.04</th>\n",
       "      <td>-1.122983e+00</td>\n",
       "      <td>-9.621153e-01</td>\n",
       "      <td>-7.737362e-01</td>\n",
       "      <td>-5.937342e-01</td>\n",
       "      <td>-4.189175e-01</td>\n",
       "      <td>-2.120235e-01</td>\n",
       "      <td>-3.191834e-02</td>\n",
       "      <td>7.850293e-02</td>\n",
       "      <td>1.769727e-01</td>\n",
       "      <td>2.887229e-01</td>\n",
       "      <td>3.798497e-01</td>\n",
       "      <td>4.803452e-01</td>\n",
       "      <td>6.591198e-01</td>\n",
       "      <td>8.701693e-01</td>\n",
       "      <td>1.013757e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.345613e-01</td>\n",
       "      <td>3.419521e-01</td>\n",
       "      <td>3.988178e-01</td>\n",
       "      <td>4.854378e-01</td>\n",
       "      <td>5.738011e-01</td>\n",
       "      <td>6.294633e-01</td>\n",
       "      <td>6.680247e-01</td>\n",
       "      <td>7.022326e-01</td>\n",
       "      <td>7.165596e-01</td>\n",
       "      <td>7.212541e-01</td>\n",
       "      <td>7.038339e-01</td>\n",
       "      <td>6.662732e-01</td>\n",
       "      <td>6.132570e-01</td>\n",
       "      <td>5.497612e-01</td>\n",
       "      <td>4.884444e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIX_30_9</th>\n",
       "      <td>5.305559e-03</td>\n",
       "      <td>5.019266e-03</td>\n",
       "      <td>4.762307e-03</td>\n",
       "      <td>4.513329e-03</td>\n",
       "      <td>4.308296e-03</td>\n",
       "      <td>4.150247e-03</td>\n",
       "      <td>4.011989e-03</td>\n",
       "      <td>3.884026e-03</td>\n",
       "      <td>3.792517e-03</td>\n",
       "      <td>3.721203e-03</td>\n",
       "      <td>3.663030e-03</td>\n",
       "      <td>3.636385e-03</td>\n",
       "      <td>3.680240e-03</td>\n",
       "      <td>3.767331e-03</td>\n",
       "      <td>3.890996e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.753779e-02</td>\n",
       "      <td>5.748568e-02</td>\n",
       "      <td>5.743222e-02</td>\n",
       "      <td>5.737740e-02</td>\n",
       "      <td>5.731896e-02</td>\n",
       "      <td>5.721271e-02</td>\n",
       "      <td>5.711138e-02</td>\n",
       "      <td>5.698013e-02</td>\n",
       "      <td>5.682867e-02</td>\n",
       "      <td>5.665035e-02</td>\n",
       "      <td>5.642067e-02</td>\n",
       "      <td>5.614318e-02</td>\n",
       "      <td>5.579746e-02</td>\n",
       "      <td>5.539173e-02</td>\n",
       "      <td>5.492671e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRIXs_30_9</th>\n",
       "      <td>6.146210e-03</td>\n",
       "      <td>6.004537e-03</td>\n",
       "      <td>5.803880e-03</td>\n",
       "      <td>5.571095e-03</td>\n",
       "      <td>5.325008e-03</td>\n",
       "      <td>5.078548e-03</td>\n",
       "      <td>4.839129e-03</td>\n",
       "      <td>4.616940e-03</td>\n",
       "      <td>4.416393e-03</td>\n",
       "      <td>4.240353e-03</td>\n",
       "      <td>4.089660e-03</td>\n",
       "      <td>3.964558e-03</td>\n",
       "      <td>3.871992e-03</td>\n",
       "      <td>3.811885e-03</td>\n",
       "      <td>3.783080e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.671379e-02</td>\n",
       "      <td>5.700357e-02</td>\n",
       "      <td>5.720408e-02</td>\n",
       "      <td>5.733201e-02</td>\n",
       "      <td>5.740000e-02</td>\n",
       "      <td>5.741596e-02</td>\n",
       "      <td>5.739166e-02</td>\n",
       "      <td>5.733503e-02</td>\n",
       "      <td>5.725388e-02</td>\n",
       "      <td>5.715528e-02</td>\n",
       "      <td>5.703694e-02</td>\n",
       "      <td>5.689372e-02</td>\n",
       "      <td>5.671817e-02</td>\n",
       "      <td>5.650403e-02</td>\n",
       "      <td>5.625003e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSI_13_25_13</th>\n",
       "      <td>-4.939295e+00</td>\n",
       "      <td>-4.525594e+00</td>\n",
       "      <td>-3.474663e+00</td>\n",
       "      <td>-3.153352e+00</td>\n",
       "      <td>-1.752822e+00</td>\n",
       "      <td>-3.033201e-01</td>\n",
       "      <td>2.612567e-01</td>\n",
       "      <td>5.133565e-01</td>\n",
       "      <td>1.641292e+00</td>\n",
       "      <td>2.235669e+00</td>\n",
       "      <td>2.615092e+00</td>\n",
       "      <td>3.681231e+00</td>\n",
       "      <td>6.184772e+00</td>\n",
       "      <td>7.719978e+00</td>\n",
       "      <td>9.108354e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.802363e+01</td>\n",
       "      <td>3.933187e+01</td>\n",
       "      <td>4.123717e+01</td>\n",
       "      <td>4.312191e+01</td>\n",
       "      <td>4.494656e+01</td>\n",
       "      <td>4.485782e+01</td>\n",
       "      <td>4.598642e+01</td>\n",
       "      <td>4.582359e+01</td>\n",
       "      <td>4.606950e+01</td>\n",
       "      <td>4.634154e+01</td>\n",
       "      <td>4.563893e+01</td>\n",
       "      <td>4.520910e+01</td>\n",
       "      <td>4.381906e+01</td>\n",
       "      <td>4.282568e+01</td>\n",
       "      <td>4.199008e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSIs_13_25_13</th>\n",
       "      <td>1.740578e+00</td>\n",
       "      <td>8.454105e-01</td>\n",
       "      <td>2.282571e-01</td>\n",
       "      <td>-2.548299e-01</td>\n",
       "      <td>-4.688288e-01</td>\n",
       "      <td>-4.451847e-01</td>\n",
       "      <td>-3.442645e-01</td>\n",
       "      <td>-2.217472e-01</td>\n",
       "      <td>4.440128e-02</td>\n",
       "      <td>3.574396e-01</td>\n",
       "      <td>6.799614e-01</td>\n",
       "      <td>1.108714e+00</td>\n",
       "      <td>1.833865e+00</td>\n",
       "      <td>2.674739e+00</td>\n",
       "      <td>3.593827e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.988342e+01</td>\n",
       "      <td>3.980462e+01</td>\n",
       "      <td>4.000927e+01</td>\n",
       "      <td>4.045394e+01</td>\n",
       "      <td>4.109574e+01</td>\n",
       "      <td>4.163318e+01</td>\n",
       "      <td>4.225507e+01</td>\n",
       "      <td>4.276486e+01</td>\n",
       "      <td>4.323695e+01</td>\n",
       "      <td>4.368046e+01</td>\n",
       "      <td>4.396024e+01</td>\n",
       "      <td>4.413865e+01</td>\n",
       "      <td>4.409300e+01</td>\n",
       "      <td>4.391195e+01</td>\n",
       "      <td>4.363740e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UI_14</th>\n",
       "      <td>4.861029e-01</td>\n",
       "      <td>5.001352e-01</td>\n",
       "      <td>5.099326e-01</td>\n",
       "      <td>5.232091e-01</td>\n",
       "      <td>5.251397e-01</td>\n",
       "      <td>5.238414e-01</td>\n",
       "      <td>5.120233e-01</td>\n",
       "      <td>5.012724e-01</td>\n",
       "      <td>4.324423e-01</td>\n",
       "      <td>3.904589e-01</td>\n",
       "      <td>3.597078e-01</td>\n",
       "      <td>3.301481e-01</td>\n",
       "      <td>2.726838e-01</td>\n",
       "      <td>2.426081e-01</td>\n",
       "      <td>2.050873e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.334618e-02</td>\n",
       "      <td>5.735406e-02</td>\n",
       "      <td>5.124493e-02</td>\n",
       "      <td>3.869508e-02</td>\n",
       "      <td>3.735938e-02</td>\n",
       "      <td>4.721081e-02</td>\n",
       "      <td>4.721081e-02</td>\n",
       "      <td>5.006249e-02</td>\n",
       "      <td>3.610353e-02</td>\n",
       "      <td>3.547338e-02</td>\n",
       "      <td>3.793993e-02</td>\n",
       "      <td>3.896937e-02</td>\n",
       "      <td>4.661579e-02</td>\n",
       "      <td>5.030457e-02</td>\n",
       "      <td>5.374075e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UO_7_14_28</th>\n",
       "      <td>5.604356e+01</td>\n",
       "      <td>6.703533e+01</td>\n",
       "      <td>6.613487e+01</td>\n",
       "      <td>6.330734e+01</td>\n",
       "      <td>6.457334e+01</td>\n",
       "      <td>6.784676e+01</td>\n",
       "      <td>6.396658e+01</td>\n",
       "      <td>6.239552e+01</td>\n",
       "      <td>6.713671e+01</td>\n",
       "      <td>6.124712e+01</td>\n",
       "      <td>6.296656e+01</td>\n",
       "      <td>5.844839e+01</td>\n",
       "      <td>6.609550e+01</td>\n",
       "      <td>6.173662e+01</td>\n",
       "      <td>6.082907e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.557620e+01</td>\n",
       "      <td>6.610483e+01</td>\n",
       "      <td>6.983166e+01</td>\n",
       "      <td>7.546038e+01</td>\n",
       "      <td>7.535806e+01</td>\n",
       "      <td>7.101469e+01</td>\n",
       "      <td>7.672695e+01</td>\n",
       "      <td>7.282680e+01</td>\n",
       "      <td>7.048927e+01</td>\n",
       "      <td>6.981889e+01</td>\n",
       "      <td>6.535797e+01</td>\n",
       "      <td>6.489388e+01</td>\n",
       "      <td>6.273215e+01</td>\n",
       "      <td>5.204607e+01</td>\n",
       "      <td>5.484732e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VHF_28</th>\n",
       "      <td>2.573290e-01</td>\n",
       "      <td>2.691652e-01</td>\n",
       "      <td>2.821429e-01</td>\n",
       "      <td>2.877960e-01</td>\n",
       "      <td>3.198381e-01</td>\n",
       "      <td>3.383298e-01</td>\n",
       "      <td>3.312369e-01</td>\n",
       "      <td>3.340381e-01</td>\n",
       "      <td>3.284823e-01</td>\n",
       "      <td>3.376068e-01</td>\n",
       "      <td>3.427332e-01</td>\n",
       "      <td>3.354565e-01</td>\n",
       "      <td>3.166333e-01</td>\n",
       "      <td>3.153693e-01</td>\n",
       "      <td>3.160000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.363636e-01</td>\n",
       "      <td>3.836634e-01</td>\n",
       "      <td>4.195122e-01</td>\n",
       "      <td>4.691196e-01</td>\n",
       "      <td>5.287356e-01</td>\n",
       "      <td>5.411765e-01</td>\n",
       "      <td>5.673534e-01</td>\n",
       "      <td>4.616639e-01</td>\n",
       "      <td>4.765343e-01</td>\n",
       "      <td>4.219331e-01</td>\n",
       "      <td>4.249513e-01</td>\n",
       "      <td>4.282908e-01</td>\n",
       "      <td>4.316832e-01</td>\n",
       "      <td>4.570231e-01</td>\n",
       "      <td>4.965831e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTXP_14</th>\n",
       "      <td>8.672439e-01</td>\n",
       "      <td>9.098837e-01</td>\n",
       "      <td>9.204204e-01</td>\n",
       "      <td>9.018405e-01</td>\n",
       "      <td>9.015385e-01</td>\n",
       "      <td>9.527559e-01</td>\n",
       "      <td>1.025210e+00</td>\n",
       "      <td>1.014925e+00</td>\n",
       "      <td>1.226374e+00</td>\n",
       "      <td>1.286765e+00</td>\n",
       "      <td>1.189474e+00</td>\n",
       "      <td>1.147757e+00</td>\n",
       "      <td>1.323615e+00</td>\n",
       "      <td>1.349673e+00</td>\n",
       "      <td>1.277397e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.102506e+00</td>\n",
       "      <td>1.174292e+00</td>\n",
       "      <td>1.279221e+00</td>\n",
       "      <td>1.244898e+00</td>\n",
       "      <td>1.294845e+00</td>\n",
       "      <td>1.201566e+00</td>\n",
       "      <td>1.136678e+00</td>\n",
       "      <td>1.208130e+00</td>\n",
       "      <td>1.274510e+00</td>\n",
       "      <td>1.277027e+00</td>\n",
       "      <td>1.266781e+00</td>\n",
       "      <td>1.240069e+00</td>\n",
       "      <td>1.253472e+00</td>\n",
       "      <td>1.235714e+00</td>\n",
       "      <td>1.262664e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VWAP_D</th>\n",
       "      <td>4.139412e+03</td>\n",
       "      <td>4.139616e+03</td>\n",
       "      <td>4.139616e+03</td>\n",
       "      <td>4.139631e+03</td>\n",
       "      <td>4.149583e+03</td>\n",
       "      <td>4.151329e+03</td>\n",
       "      <td>4.151107e+03</td>\n",
       "      <td>4.150831e+03</td>\n",
       "      <td>4.150975e+03</td>\n",
       "      <td>4.151136e+03</td>\n",
       "      <td>4.151165e+03</td>\n",
       "      <td>4.152068e+03</td>\n",
       "      <td>4.153240e+03</td>\n",
       "      <td>4.154314e+03</td>\n",
       "      <td>4.154794e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.967518e+03</td>\n",
       "      <td>5.973881e+03</td>\n",
       "      <td>5.979756e+03</td>\n",
       "      <td>5.982501e+03</td>\n",
       "      <td>5.984364e+03</td>\n",
       "      <td>5.985510e+03</td>\n",
       "      <td>5.987970e+03</td>\n",
       "      <td>5.991493e+03</td>\n",
       "      <td>5.992325e+03</td>\n",
       "      <td>5.992325e+03</td>\n",
       "      <td>6.005333e+03</td>\n",
       "      <td>6.004786e+03</td>\n",
       "      <td>6.004272e+03</td>\n",
       "      <td>6.004024e+03</td>\n",
       "      <td>6.003938e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSV_18_10</th>\n",
       "      <td>-2.076637e+06</td>\n",
       "      <td>-2.002493e+06</td>\n",
       "      <td>-2.002493e+06</td>\n",
       "      <td>-2.015180e+06</td>\n",
       "      <td>-1.973242e+06</td>\n",
       "      <td>-1.916944e+06</td>\n",
       "      <td>-2.075077e+06</td>\n",
       "      <td>-2.075479e+06</td>\n",
       "      <td>-2.065463e+06</td>\n",
       "      <td>-1.990046e+06</td>\n",
       "      <td>-1.617292e+06</td>\n",
       "      <td>-1.603314e+06</td>\n",
       "      <td>3.759792e+06</td>\n",
       "      <td>1.367926e+06</td>\n",
       "      <td>6.266358e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217585e+06</td>\n",
       "      <td>3.856410e+06</td>\n",
       "      <td>4.009367e+06</td>\n",
       "      <td>3.798969e+06</td>\n",
       "      <td>4.004647e+06</td>\n",
       "      <td>3.486299e+06</td>\n",
       "      <td>5.403606e+06</td>\n",
       "      <td>4.396376e+06</td>\n",
       "      <td>4.637672e+06</td>\n",
       "      <td>4.629050e+06</td>\n",
       "      <td>4.590988e+06</td>\n",
       "      <td>4.610027e+06</td>\n",
       "      <td>4.642172e+06</td>\n",
       "      <td>4.517216e+06</td>\n",
       "      <td>4.520971e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <td>-5.570004e+05</td>\n",
       "      <td>-1.086842e+06</td>\n",
       "      <td>-1.690910e+06</td>\n",
       "      <td>-2.404742e+06</td>\n",
       "      <td>-2.286844e+06</td>\n",
       "      <td>-2.166620e+06</td>\n",
       "      <td>-2.134145e+06</td>\n",
       "      <td>-2.118998e+06</td>\n",
       "      <td>-2.016504e+06</td>\n",
       "      <td>-2.019305e+06</td>\n",
       "      <td>-1.973371e+06</td>\n",
       "      <td>-1.933453e+06</td>\n",
       "      <td>-1.357224e+06</td>\n",
       "      <td>-1.018914e+06</td>\n",
       "      <td>-7.589260e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273433e+06</td>\n",
       "      <td>3.524712e+06</td>\n",
       "      <td>3.775964e+06</td>\n",
       "      <td>3.940801e+06</td>\n",
       "      <td>4.212663e+06</td>\n",
       "      <td>4.370122e+06</td>\n",
       "      <td>4.013046e+06</td>\n",
       "      <td>3.802685e+06</td>\n",
       "      <td>3.904339e+06</td>\n",
       "      <td>4.043998e+06</td>\n",
       "      <td>4.281338e+06</td>\n",
       "      <td>4.356700e+06</td>\n",
       "      <td>4.419981e+06</td>\n",
       "      <td>4.491805e+06</td>\n",
       "      <td>4.543438e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLR_14</th>\n",
       "      <td>-5.212766e+01</td>\n",
       "      <td>-4.946809e+01</td>\n",
       "      <td>-4.202128e+01</td>\n",
       "      <td>-4.787234e+01</td>\n",
       "      <td>-3.296089e+01</td>\n",
       "      <td>-2.409639e+01</td>\n",
       "      <td>-3.132530e+01</td>\n",
       "      <td>-1.791045e+01</td>\n",
       "      <td>-5.223881e+00</td>\n",
       "      <td>-1.065574e+01</td>\n",
       "      <td>-1.229508e+01</td>\n",
       "      <td>-1.176471e+01</td>\n",
       "      <td>-1.626016e+00</td>\n",
       "      <td>-1.785714e+01</td>\n",
       "      <td>-1.935484e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.442308e+01</td>\n",
       "      <td>-2.142857e+00</td>\n",
       "      <td>-4.487179e+00</td>\n",
       "      <td>-3.658537e+00</td>\n",
       "      <td>-3.508772e+00</td>\n",
       "      <td>-1.871345e+01</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-1.953488e+01</td>\n",
       "      <td>-1.250000e+01</td>\n",
       "      <td>-1.185567e+01</td>\n",
       "      <td>-1.917098e+01</td>\n",
       "      <td>-1.606218e+01</td>\n",
       "      <td>-2.500000e+01</td>\n",
       "      <td>-2.173913e+01</td>\n",
       "      <td>-2.380952e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <td>4.141477e+03</td>\n",
       "      <td>4.142754e+03</td>\n",
       "      <td>4.146299e+03</td>\n",
       "      <td>4.146472e+03</td>\n",
       "      <td>4.148749e+03</td>\n",
       "      <td>4.150931e+03</td>\n",
       "      <td>4.150989e+03</td>\n",
       "      <td>4.151173e+03</td>\n",
       "      <td>4.151869e+03</td>\n",
       "      <td>4.151620e+03</td>\n",
       "      <td>4.151780e+03</td>\n",
       "      <td>4.153275e+03</td>\n",
       "      <td>4.156270e+03</td>\n",
       "      <td>4.158266e+03</td>\n",
       "      <td>4.160173e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.973363e+03</td>\n",
       "      <td>5.978388e+03</td>\n",
       "      <td>5.985590e+03</td>\n",
       "      <td>5.992256e+03</td>\n",
       "      <td>5.998709e+03</td>\n",
       "      <td>5.999308e+03</td>\n",
       "      <td>6.002888e+03</td>\n",
       "      <td>6.003681e+03</td>\n",
       "      <td>6.005285e+03</td>\n",
       "      <td>6.008051e+03</td>\n",
       "      <td>6.006724e+03</td>\n",
       "      <td>6.006956e+03</td>\n",
       "      <td>6.005055e+03</td>\n",
       "      <td>6.003908e+03</td>\n",
       "      <td>6.003607e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZS_30</th>\n",
       "      <td>-4.243336e-01</td>\n",
       "      <td>-3.100699e-01</td>\n",
       "      <td>-6.485975e-02</td>\n",
       "      <td>-3.213398e-01</td>\n",
       "      <td>1.018548e-01</td>\n",
       "      <td>1.702538e-01</td>\n",
       "      <td>-1.581031e-01</td>\n",
       "      <td>-2.497979e-01</td>\n",
       "      <td>1.862238e-01</td>\n",
       "      <td>4.213366e-02</td>\n",
       "      <td>1.037961e-02</td>\n",
       "      <td>3.798855e-01</td>\n",
       "      <td>1.105363e+00</td>\n",
       "      <td>9.001579e-01</td>\n",
       "      <td>9.544857e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192044e+00</td>\n",
       "      <td>1.800801e+00</td>\n",
       "      <td>2.039608e+00</td>\n",
       "      <td>1.981715e+00</td>\n",
       "      <td>1.909438e+00</td>\n",
       "      <td>1.507856e+00</td>\n",
       "      <td>1.904292e+00</td>\n",
       "      <td>1.591887e+00</td>\n",
       "      <td>1.745361e+00</td>\n",
       "      <td>1.747173e+00</td>\n",
       "      <td>1.490349e+00</td>\n",
       "      <td>1.482607e+00</td>\n",
       "      <td>1.206776e+00</td>\n",
       "      <td>1.207136e+00</td>\n",
       "      <td>1.130451e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 8582 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0             1             2     \\\n",
       "Feature                                                              \n",
       "Close                     4.144000e+03  4.145250e+03  4.148750e+03   \n",
       "ACCBU_20                  4.176644e+03  4.175581e+03  4.174856e+03   \n",
       "AD                        1.391047e+05  1.874016e+05  1.874016e+05   \n",
       "DMP_14                    2.862029e+01  2.682599e+01  2.865985e+01   \n",
       "AO_5_34                  -9.730147e+00 -8.792647e+00 -7.901471e+00   \n",
       "OBV                      -1.577626e+06 -1.515530e+06 -1.515530e+06   \n",
       "OBV_min_2                -1.577626e+06 -1.577626e+06 -1.515530e+06   \n",
       "OBV_max_2                -1.400149e+06 -1.515530e+06 -1.515530e+06   \n",
       "OBVe_4                   -1.519474e+06 -1.517897e+06 -1.516950e+06   \n",
       "OBVe_12                  -1.587197e+06 -1.576171e+06 -1.566842e+06   \n",
       "BIAS_SMA_26              -1.633150e-03 -1.521668e-03 -7.225869e-04   \n",
       "open_Z_30_1              -4.443029e-01 -4.368429e-01 -3.823481e-01   \n",
       "high_Z_30_1              -9.500395e-01 -8.711936e-01 -4.760687e-01   \n",
       "low_Z_30_1               -4.641785e-01 -1.521588e-01 -2.583297e-02   \n",
       "close_Z_30_1             -4.243336e-01 -3.100699e-01 -6.485975e-02   \n",
       "CMF_20                    2.092556e-01  2.325357e-01  2.387055e-01   \n",
       "DPO_20                   -1.750000e+00 -1.237500e+00  1.662500e+00   \n",
       "EFI_13                   -3.867705e+04 -2.206319e+04 -1.891130e+04   \n",
       "BULLP_13                  5.583246e-01  7.642782e-01  3.976524e+00   \n",
       "FISHERT_9_1              -1.005900e+00 -7.067068e-01 -1.554691e-01   \n",
       "FISHERTs_9_1             -1.231003e+00 -1.005900e+00 -7.067068e-01   \n",
       "HL2                       4.141000e+03  4.143500e+03  4.146625e+03   \n",
       "HLC3                      4.142000e+03  4.144083e+03  4.147333e+03   \n",
       "HWL_1                     4.125659e+03  4.125213e+03  4.125620e+03   \n",
       "ICS_26                    4.129000e+03  4.132250e+03  4.128750e+03   \n",
       "INERTIA_20_14             6.067977e+01  6.107875e+01  6.133456e+01   \n",
       "JMA_7_0.0                 4.140373e+03  4.141970e+03  4.143967e+03   \n",
       "K_9_3                     4.395875e+01  4.838214e+01  6.469523e+01   \n",
       "D_9_3                     3.759301e+01  4.118938e+01  4.902467e+01   \n",
       "J_9_3                     5.669022e+01  6.276764e+01  9.603636e+01   \n",
       "KVO_34_55_13              4.560542e+03  5.615083e+03  5.231766e+03   \n",
       "KVOs_34_55_13             5.413537e+02  1.266172e+03  1.832686e+03   \n",
       "MACD_12_26_9             -2.042903e+00 -1.839279e+00 -1.379582e+00   \n",
       "MEDIAN_30                 4.150375e+03  4.149875e+03  4.150500e+03   \n",
       "MFI_14                    5.118593e+01  5.374093e+01  5.298481e+01   \n",
       "NVI_1                     1.002188e+03  1.002218e+03  1.002302e+03   \n",
       "PGO_14                   -3.525100e-01 -1.529799e-01  2.745441e-01   \n",
       "PVIe_255                  2.667326e+01  2.041344e+01  1.003936e+01   \n",
       "PVOs_12_26_9              1.280821e+01  1.432925e+01  1.347127e+01   \n",
       "PVT                      -9.885405e+05 -9.866675e+05 -9.866675e+05   \n",
       "QQE_14_5_4.236            5.063408e+01  5.063408e+01  5.063408e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  8.188000e+01  8.190500e+01  8.197500e+01   \n",
       "RSI_14                    4.823821e+01  4.908719e+01  5.148655e+01   \n",
       "RSX_14                    3.636083e+01  3.879892e+01  4.162162e+01   \n",
       "RVGI_14_4                -1.319969e-01 -1.120178e-01 -9.531936e-02   \n",
       "SINWMA_14                 4.146042e+03  4.144197e+03  4.142741e+03   \n",
       "SKEW_30                  -5.068092e-01 -4.768601e-01 -5.744812e-01   \n",
       "SMIo_5_20_5_1.0           2.336892e-02  3.125081e-02  4.505079e-02   \n",
       "SSF_20                    4.144125e+03  4.143338e+03  4.143053e+03   \n",
       "STOCHk_14_3_3             4.219858e+01  4.929078e+01  5.212766e+01   \n",
       "STOCHd_14_3_3             4.024823e+01  4.408983e+01  4.787234e+01   \n",
       "STOCHFd_14_3              4.219858e+01  4.929078e+01  5.212766e+01   \n",
       "T3_10_0.7                 4.146612e+03  4.144919e+03  4.143747e+03   \n",
       "THERMOma_20_2_0.5         7.262301e+00  7.023034e+00  6.711317e+00   \n",
       "TMO_14_5_3               -8.602935e+00 -7.135148e+00 -4.790027e+00   \n",
       "TMOs_14_5_3              -8.954656e+00 -8.044902e+00 -6.417465e+00   \n",
       "TOS_STDEVALL_LR           4.143850e+03  4.144042e+03  4.144233e+03   \n",
       "TOS_STDEVALL_L_1          3.516495e+03  3.516687e+03  3.516878e+03   \n",
       "TOS_STDEVALL_U_1          4.771205e+03  4.771396e+03  4.771588e+03   \n",
       "TOS_STDEVALL_L_2          2.889140e+03  2.889332e+03  2.889523e+03   \n",
       "TOS_STDEVALL_U_2          5.398560e+03  5.398751e+03  5.398943e+03   \n",
       "TOS_STDEVALL_L_3          2.261785e+03  2.261977e+03  2.262168e+03   \n",
       "TOS_STDEVALL_U_3          6.025915e+03  6.026106e+03  6.026298e+03   \n",
       "TRENDFLEX_20_20_0.04     -1.122983e+00 -9.621153e-01 -7.737362e-01   \n",
       "TRIX_30_9                 5.305559e-03  5.019266e-03  4.762307e-03   \n",
       "TRIXs_30_9                6.146210e-03  6.004537e-03  5.803880e-03   \n",
       "TSI_13_25_13             -4.939295e+00 -4.525594e+00 -3.474663e+00   \n",
       "TSIs_13_25_13             1.740578e+00  8.454105e-01  2.282571e-01   \n",
       "UI_14                     4.861029e-01  5.001352e-01  5.099326e-01   \n",
       "UO_7_14_28                5.604356e+01  6.703533e+01  6.613487e+01   \n",
       "VHF_28                    2.573290e-01  2.691652e-01  2.821429e-01   \n",
       "VTXP_14                   8.672439e-01  9.098837e-01  9.204204e-01   \n",
       "VWAP_D                    4.139412e+03  4.139616e+03  4.139616e+03   \n",
       "TSV_18_10                -2.076637e+06 -2.002493e+06 -2.002493e+06   \n",
       "TSVs_18_10               -5.570004e+05 -1.086842e+06 -1.690910e+06   \n",
       "WILLR_14                 -5.212766e+01 -4.946809e+01 -4.202128e+01   \n",
       "ZIGZAGv_5.0%_10           4.141477e+03  4.142754e+03  4.146299e+03   \n",
       "ZS_30                    -4.243336e-01 -3.100699e-01 -6.485975e-02   \n",
       "\n",
       "                                  3             4             5     \\\n",
       "Feature                                                              \n",
       "Close                     4.146000e+03  4.151500e+03  4.153000e+03   \n",
       "ACCBU_20                  4.174231e+03  4.174207e+03  4.173995e+03   \n",
       "AD                        1.844896e+05  1.915830e+05  1.921213e+05   \n",
       "DMP_14                    2.661271e+01  2.796181e+01  2.896453e+01   \n",
       "AO_5_34                  -5.724265e+00 -3.817647e+00 -1.354412e+00   \n",
       "OBV                      -1.518442e+06 -1.510115e+06 -1.500963e+06   \n",
       "OBV_min_2                -1.518442e+06 -1.518442e+06 -1.510115e+06   \n",
       "OBV_max_2                -1.515530e+06 -1.510115e+06 -1.500963e+06   \n",
       "OBVe_4                   -1.517547e+06 -1.514574e+06 -1.509130e+06   \n",
       "OBVe_12                  -1.559396e+06 -1.551814e+06 -1.543991e+06   \n",
       "BIAS_SMA_26              -1.327135e-03  9.264578e-06  3.868024e-04   \n",
       "open_Z_30_1              -8.580248e-02 -3.417861e-01  8.119890e-02   \n",
       "high_Z_30_1              -5.511279e-01 -2.822705e-01 -7.229326e-02   \n",
       "low_Z_30_1                9.978443e-02  7.132282e-03  3.413695e-01   \n",
       "close_Z_30_1             -3.213398e-01  1.018548e-01  1.702538e-01   \n",
       "CMF_20                    2.360134e-01  2.428811e-01  2.417800e-01   \n",
       "DPO_20                   -2.850000e+00  1.575000e+00  2.312500e+00   \n",
       "EFI_13                   -1.735369e+04 -8.331948e+03 -5.180527e+03   \n",
       "BULLP_13                  3.158449e+00  5.564385e+00  7.626616e+00   \n",
       "FISHERT_9_1               4.206918e-01  9.664706e-01  1.474705e+00   \n",
       "FISHERTs_9_1             -1.554691e-01  4.206918e-01  9.664706e-01   \n",
       "HL2                       4.147375e+03  4.148625e+03  4.152875e+03   \n",
       "HLC3                      4.146917e+03  4.149583e+03  4.152917e+03   \n",
       "HWL_1                     4.125313e+03  4.126031e+03  4.127276e+03   \n",
       "ICS_26                    4.135750e+03  4.136250e+03  4.137250e+03   \n",
       "INERTIA_20_14             6.054171e+01  6.069370e+01  6.208501e+01   \n",
       "JMA_7_0.0                 4.145308e+03  4.146967e+03  4.148811e+03   \n",
       "K_9_3                     7.229682e+01  8.092515e+01  8.509764e+01   \n",
       "D_9_3                     5.678205e+01  6.482975e+01  7.158572e+01   \n",
       "J_9_3                     1.033264e+02  1.131160e+02  1.121215e+02   \n",
       "KVO_34_55_13              4.810184e+03  4.657907e+03  4.527633e+03   \n",
       "KVOs_34_55_13             2.258042e+03  2.600880e+03  2.876131e+03   \n",
       "MACD_12_26_9             -1.223072e+00 -6.477656e-01 -6.998686e-02   \n",
       "MEDIAN_30                 4.150500e+03  4.151875e+03  4.152500e+03   \n",
       "MFI_14                    5.240571e+01  5.270321e+01  5.360207e+01   \n",
       "NVI_1                     1.002302e+03  1.002302e+03  1.002302e+03   \n",
       "PGO_14                    1.374858e-01  7.466142e-01  9.387765e-01   \n",
       "PVIe_255                  8.548557e-01 -6.857376e+00 -1.366399e+01   \n",
       "PVOs_12_26_9              1.094799e+01  7.386917e+00  3.176735e+00   \n",
       "PVT                      -9.868605e+05 -9.857558e+05 -9.854252e+05   \n",
       "QQE_14_5_4.236            5.063408e+01  5.063408e+01  4.543667e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  8.192000e+01  8.203000e+01  8.206000e+01   \n",
       "RSI_14                    4.951218e+01  5.336404e+01  5.438614e+01   \n",
       "RSX_14                    4.399646e+01  4.691764e+01  5.009676e+01   \n",
       "RVGI_14_4                -9.277079e-02 -9.235028e-02 -8.220230e-02   \n",
       "SINWMA_14                 4.141822e+03  4.141593e+03  4.142108e+03   \n",
       "SKEW_30                  -6.243520e-01 -7.356147e-01 -6.835443e-01   \n",
       "SMIo_5_20_5_1.0           3.537681e-02  4.958129e-02  5.586475e-02   \n",
       "SSF_20                    4.143130e+03  4.143516e+03  4.144288e+03   \n",
       "STOCHk_14_3_3             5.354610e+01  5.904850e+01  6.502346e+01   \n",
       "STOCHd_14_3_3             5.165485e+01  5.490742e+01  5.920602e+01   \n",
       "STOCHFd_14_3              5.354610e+01  5.904850e+01  6.502346e+01   \n",
       "T3_10_0.7                 4.143008e+03  4.142742e+03  4.142933e+03   \n",
       "THERMOma_20_2_0.5         6.286429e+00  5.997245e+00  5.949889e+00   \n",
       "TMO_14_5_3               -2.876649e+00 -4.260819e-01  2.128454e+00   \n",
       "TMOs_14_5_3              -4.647057e+00 -2.536569e+00 -2.040576e-01   \n",
       "TOS_STDEVALL_LR           4.144424e+03  4.144615e+03  4.144806e+03   \n",
       "TOS_STDEVALL_L_1          3.517069e+03  3.517260e+03  3.517451e+03   \n",
       "TOS_STDEVALL_U_1          4.771779e+03  4.771970e+03  4.772161e+03   \n",
       "TOS_STDEVALL_L_2          2.889714e+03  2.889905e+03  2.890096e+03   \n",
       "TOS_STDEVALL_U_2          5.399134e+03  5.399325e+03  5.399516e+03   \n",
       "TOS_STDEVALL_L_3          2.262359e+03  2.262550e+03  2.262741e+03   \n",
       "TOS_STDEVALL_U_3          6.026489e+03  6.026680e+03  6.026871e+03   \n",
       "TRENDFLEX_20_20_0.04     -5.937342e-01 -4.189175e-01 -2.120235e-01   \n",
       "TRIX_30_9                 4.513329e-03  4.308296e-03  4.150247e-03   \n",
       "TRIXs_30_9                5.571095e-03  5.325008e-03  5.078548e-03   \n",
       "TSI_13_25_13             -3.153352e+00 -1.752822e+00 -3.033201e-01   \n",
       "TSIs_13_25_13            -2.548299e-01 -4.688288e-01 -4.451847e-01   \n",
       "UI_14                     5.232091e-01  5.251397e-01  5.238414e-01   \n",
       "UO_7_14_28                6.330734e+01  6.457334e+01  6.784676e+01   \n",
       "VHF_28                    2.877960e-01  3.198381e-01  3.383298e-01   \n",
       "VTXP_14                   9.018405e-01  9.015385e-01  9.527559e-01   \n",
       "VWAP_D                    4.139631e+03  4.149583e+03  4.151329e+03   \n",
       "TSV_18_10                -2.015180e+06 -1.973242e+06 -1.916944e+06   \n",
       "TSVs_18_10               -2.404742e+06 -2.286844e+06 -2.166620e+06   \n",
       "WILLR_14                 -4.787234e+01 -3.296089e+01 -2.409639e+01   \n",
       "ZIGZAGv_5.0%_10           4.146472e+03  4.148749e+03  4.150931e+03   \n",
       "ZS_30                    -3.213398e-01  1.018548e-01  1.702538e-01   \n",
       "\n",
       "                                  6             7             8     \\\n",
       "Feature                                                              \n",
       "Close                     4.150000e+03  4.149000e+03  4.153250e+03   \n",
       "ACCBU_20                  4.173507e+03  4.172544e+03  4.171068e+03   \n",
       "AD                        1.906416e+05  1.902364e+05  1.943464e+05   \n",
       "DMP_14                    2.689564e+01  2.497452e+01  2.619063e+01   \n",
       "AO_5_34                  -1.389706e-01  1.036765e-01  3.823529e-01   \n",
       "OBV                      -1.506586e+06 -1.510233e+06 -1.506123e+06   \n",
       "OBV_min_2                -1.506586e+06 -1.510233e+06 -1.510233e+06   \n",
       "OBV_max_2                -1.500963e+06 -1.506586e+06 -1.506123e+06   \n",
       "OBVe_4                   -1.508112e+06 -1.508961e+06 -1.507826e+06   \n",
       "OBVe_12                  -1.538236e+06 -1.533928e+06 -1.529650e+06   \n",
       "BIAS_SMA_26              -2.710109e-04 -3.938230e-04  6.880718e-04   \n",
       "open_Z_30_1               1.476444e-01 -1.559204e-01 -2.221024e-01   \n",
       "high_Z_30_1              -3.233008e-01 -5.871734e-01 -2.373392e-01   \n",
       "low_Z_30_1                8.561091e-02  4.818218e-02  1.602014e-01   \n",
       "close_Z_30_1             -1.581031e-01 -2.497979e-01  1.862238e-01   \n",
       "CMF_20                    2.391435e-01  2.441664e-01  2.464029e-01   \n",
       "DPO_20                   -1.025000e+00 -2.087500e+00  2.587500e+00   \n",
       "EFI_13                   -6.850309e+03 -6.392693e+03 -2.984094e+03   \n",
       "BULLP_13                  5.251385e+00  2.322616e+00  4.562242e+00   \n",
       "FISHERT_9_1               1.734054e+00  1.661542e+00  1.664600e+00   \n",
       "FISHERTs_9_1              1.474705e+00  1.734054e+00  1.661542e+00   \n",
       "HL2                       4.150625e+03  4.149125e+03  4.151250e+03   \n",
       "HLC3                      4.150417e+03  4.149083e+03  4.151917e+03   \n",
       "HWL_1                     4.127319e+03  4.127189e+03  4.128491e+03   \n",
       "ICS_26                    4.139750e+03  4.146000e+03  4.151000e+03   \n",
       "INERTIA_20_14             6.263909e+01  6.104715e+01  6.081584e+01   \n",
       "JMA_7_0.0                 4.149992e+03  4.150427e+03  4.151001e+03   \n",
       "K_9_3                     8.460061e+01  8.131269e+01  8.438864e+01   \n",
       "D_9_3                     7.592402e+01  7.772024e+01  7.994304e+01   \n",
       "J_9_3                     1.019538e+02  8.849759e+01  9.327984e+01   \n",
       "KVO_34_55_13              4.083342e+03  3.713409e+03  3.535716e+03   \n",
       "KVOs_34_55_13             3.048589e+03  3.143564e+03  3.199585e+03   \n",
       "MACD_12_26_9              1.441701e-01  2.305419e-01  6.346162e-01   \n",
       "MEDIAN_30                 4.152500e+03  4.152125e+03  4.152250e+03   \n",
       "MFI_14                    5.468869e+01  5.180026e+01  6.389651e+01   \n",
       "NVI_1                     1.002230e+03  1.002206e+03  1.002206e+03   \n",
       "PGO_14                    6.384930e-01  5.415404e-01  7.799757e-01   \n",
       "PVIe_255                 -2.025853e+01 -2.651279e+01 -3.206708e+01   \n",
       "PVOs_12_26_9             -1.510318e+00 -6.510813e+00 -1.162207e+01   \n",
       "PVT                      -9.858313e+05 -9.859192e+05 -9.854982e+05   \n",
       "QQE_14_5_4.236            4.555952e+01  4.555952e+01  4.643741e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  8.200000e+01  8.198000e+01  8.206500e+01   \n",
       "RSI_14                    5.193457e+01  5.110757e+01  5.442890e+01   \n",
       "RSX_14                    5.258423e+01  5.429891e+01  5.628518e+01   \n",
       "RVGI_14_4                -5.003930e-02 -1.261657e-02  4.416592e-02   \n",
       "SINWMA_14                 4.143154e+03  4.144406e+03  4.145920e+03   \n",
       "SKEW_30                  -7.530572e-01 -7.162102e-01 -7.208955e-01   \n",
       "SMIo_5_20_5_1.0           3.856037e-02  2.183574e-02  3.105540e-02   \n",
       "SSF_20                    4.145217e+03  4.146069e+03  4.146919e+03   \n",
       "STOCHk_14_3_3             7.053914e+01  7.555596e+01  8.184679e+01   \n",
       "STOCHd_14_3_3             6.487037e+01  7.037285e+01  7.598063e+01   \n",
       "STOCHFd_14_3              7.053914e+01  7.555596e+01  8.184679e+01   \n",
       "T3_10_0.7                 4.143432e+03  4.144095e+03  4.144920e+03   \n",
       "THERMOma_20_2_0.5         5.621328e+00  5.347868e+00  5.124262e+00   \n",
       "TMO_14_5_3                4.291891e+00  5.964388e+00  7.861155e+00   \n",
       "TMOs_14_5_3               2.043917e+00  4.004152e+00  5.932654e+00   \n",
       "TOS_STDEVALL_LR           4.144998e+03  4.145189e+03  4.145380e+03   \n",
       "TOS_STDEVALL_L_1          3.517643e+03  3.517834e+03  3.518025e+03   \n",
       "TOS_STDEVALL_U_1          4.772353e+03  4.772544e+03  4.772735e+03   \n",
       "TOS_STDEVALL_L_2          2.890288e+03  2.890479e+03  2.890670e+03   \n",
       "TOS_STDEVALL_U_2          5.399708e+03  5.399899e+03  5.400090e+03   \n",
       "TOS_STDEVALL_L_3          2.262933e+03  2.263124e+03  2.263315e+03   \n",
       "TOS_STDEVALL_U_3          6.027062e+03  6.027254e+03  6.027445e+03   \n",
       "TRENDFLEX_20_20_0.04     -3.191834e-02  7.850293e-02  1.769727e-01   \n",
       "TRIX_30_9                 4.011989e-03  3.884026e-03  3.792517e-03   \n",
       "TRIXs_30_9                4.839129e-03  4.616940e-03  4.416393e-03   \n",
       "TSI_13_25_13              2.612567e-01  5.133565e-01  1.641292e+00   \n",
       "TSIs_13_25_13            -3.442645e-01 -2.217472e-01  4.440128e-02   \n",
       "UI_14                     5.120233e-01  5.012724e-01  4.324423e-01   \n",
       "UO_7_14_28                6.396658e+01  6.239552e+01  6.713671e+01   \n",
       "VHF_28                    3.312369e-01  3.340381e-01  3.284823e-01   \n",
       "VTXP_14                   1.025210e+00  1.014925e+00  1.226374e+00   \n",
       "VWAP_D                    4.151107e+03  4.150831e+03  4.150975e+03   \n",
       "TSV_18_10                -2.075077e+06 -2.075479e+06 -2.065463e+06   \n",
       "TSVs_18_10               -2.134145e+06 -2.118998e+06 -2.016504e+06   \n",
       "WILLR_14                 -3.132530e+01 -1.791045e+01 -5.223881e+00   \n",
       "ZIGZAGv_5.0%_10           4.150989e+03  4.151173e+03  4.151869e+03   \n",
       "ZS_30                    -1.581031e-01 -2.497979e-01  1.862238e-01   \n",
       "\n",
       "                                  9             10            11    \\\n",
       "Feature                                                              \n",
       "Close                     4.151750e+03  4.151250e+03  4.154500e+03   \n",
       "ACCBU_20                  4.169993e+03  4.168880e+03  4.168693e+03   \n",
       "AD                        1.921596e+05  1.917519e+05  1.960261e+05   \n",
       "DMP_14                    2.481987e+01  2.304702e+01  2.665080e+01   \n",
       "AO_5_34                   2.279412e-01 -5.463235e-01 -8.088235e-03   \n",
       "OBV                      -1.510934e+06 -1.517049e+06 -1.495678e+06   \n",
       "OBV_min_2                -1.510934e+06 -1.517049e+06 -1.517049e+06   \n",
       "OBV_max_2                -1.506123e+06 -1.510934e+06 -1.495678e+06   \n",
       "OBVe_4                   -1.509069e+06 -1.512261e+06 -1.505628e+06   \n",
       "OBVe_12                  -1.526771e+06 -1.525275e+06 -1.520722e+06   \n",
       "BIAS_SMA_26               4.054614e-04  3.684214e-04  1.218885e-03   \n",
       "open_Z_30_1               1.893360e-01  1.896667e-02  3.904895e-02   \n",
       "high_Z_30_1              -1.755755e-01 -2.105892e-01  4.028581e-01   \n",
       "low_Z_30_1                3.086522e-01  1.946480e-01  1.365797e-01   \n",
       "close_Z_30_1              4.213366e-02  1.037961e-02  3.798855e-01   \n",
       "CMF_20                    2.504205e-01  2.536061e-01  2.652109e-01   \n",
       "DPO_20                    2.450000e+00  3.500000e+00  8.175000e+00   \n",
       "EFI_13                   -3.588724e+03 -3.512835e+03  6.911249e+03   \n",
       "BULLP_13                  4.624779e+00  3.821239e+00  8.346776e+00   \n",
       "FISHERT_9_1               1.810056e+00  1.725823e+00  1.914921e+00   \n",
       "FISHERTs_9_1              1.664600e+00  1.810056e+00  1.725823e+00   \n",
       "HL2                       4.152375e+03  4.151375e+03  4.153500e+03   \n",
       "HLC3                      4.152167e+03  4.151333e+03  4.153833e+03   \n",
       "HWL_1                     4.129539e+03  4.130181e+03  4.131824e+03   \n",
       "ICS_26                    4.153500e+03  4.150750e+03  4.151750e+03   \n",
       "INERTIA_20_14             5.935274e+01  5.744669e+01  5.629583e+01   \n",
       "JMA_7_0.0                 4.151470e+03  4.151707e+03  4.152230e+03   \n",
       "K_9_3                     8.171364e+01  7.669798e+01  7.440243e+01   \n",
       "D_9_3                     8.053324e+01  7.925482e+01  7.763736e+01   \n",
       "J_9_3                     8.407444e+01  7.158430e+01  6.793257e+01   \n",
       "KVO_34_55_13              3.381965e+03  3.001147e+03  3.237775e+03   \n",
       "KVOs_34_55_13             3.225640e+03  3.193569e+03  3.199884e+03   \n",
       "MACD_12_26_9              8.243084e-01  9.236477e-01  1.250211e+00   \n",
       "MEDIAN_30                 4.151625e+03  4.151375e+03  4.151375e+03   \n",
       "MFI_14                    8.239771e+01  7.777802e+01  7.403082e+01   \n",
       "NVI_1                     1.002206e+03  1.002206e+03  1.002206e+03   \n",
       "PGO_14                    5.198066e-01  3.976809e-01  6.655036e-01   \n",
       "PVIe_255                 -3.690917e+01 -4.092875e+01 -4.073107e+01   \n",
       "PVOs_12_26_9             -1.667949e+01 -2.152934e+01 -2.536968e+01   \n",
       "PVT                      -9.856720e+05 -9.857456e+05 -9.840725e+05   \n",
       "QQE_14_5_4.236            4.671230e+01  4.678628e+01  4.780087e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  8.203500e+01  8.202500e+01  8.209000e+01   \n",
       "RSI_14                    5.305892e+01  5.258380e+01  5.538062e+01   \n",
       "RSX_14                    5.787393e+01  5.899489e+01  6.050834e+01   \n",
       "RVGI_14_4                 1.133467e-01  1.638225e-01  1.709651e-01   \n",
       "SINWMA_14                 4.147098e+03  4.148108e+03  4.149091e+03   \n",
       "SKEW_30                  -6.939644e-01 -6.506129e-01 -6.555396e-01   \n",
       "SMIo_5_20_5_1.0           2.363784e-02  1.494733e-02  2.570045e-02   \n",
       "SSF_20                    4.147800e+03  4.148586e+03  4.149348e+03   \n",
       "STOCHk_14_3_3             8.873664e+01  9.060843e+01  8.842816e+01   \n",
       "STOCHd_14_3_3             8.204646e+01  8.706396e+01  8.925775e+01   \n",
       "STOCHFd_14_3              8.873664e+01  9.060843e+01  8.842816e+01   \n",
       "T3_10_0.7                 4.145834e+03  4.146760e+03  4.147722e+03   \n",
       "THERMOma_20_2_0.5         4.802903e+00  4.488341e+00  4.560880e+00   \n",
       "TMO_14_5_3                9.183219e+00  9.593370e+00  1.046453e+01   \n",
       "TMOs_14_5_3               7.557936e+00  8.575653e+00  9.520089e+00   \n",
       "TOS_STDEVALL_LR           4.145571e+03  4.145762e+03  4.145954e+03   \n",
       "TOS_STDEVALL_L_1          3.518216e+03  3.518407e+03  3.518599e+03   \n",
       "TOS_STDEVALL_U_1          4.772926e+03  4.773117e+03  4.773309e+03   \n",
       "TOS_STDEVALL_L_2          2.890861e+03  2.891053e+03  2.891244e+03   \n",
       "TOS_STDEVALL_U_2          5.400281e+03  5.400472e+03  5.400664e+03   \n",
       "TOS_STDEVALL_L_3          2.263506e+03  2.263698e+03  2.263889e+03   \n",
       "TOS_STDEVALL_U_3          6.027636e+03  6.027827e+03  6.028019e+03   \n",
       "TRENDFLEX_20_20_0.04      2.887229e-01  3.798497e-01  4.803452e-01   \n",
       "TRIX_30_9                 3.721203e-03  3.663030e-03  3.636385e-03   \n",
       "TRIXs_30_9                4.240353e-03  4.089660e-03  3.964558e-03   \n",
       "TSI_13_25_13              2.235669e+00  2.615092e+00  3.681231e+00   \n",
       "TSIs_13_25_13             3.574396e-01  6.799614e-01  1.108714e+00   \n",
       "UI_14                     3.904589e-01  3.597078e-01  3.301481e-01   \n",
       "UO_7_14_28                6.124712e+01  6.296656e+01  5.844839e+01   \n",
       "VHF_28                    3.376068e-01  3.427332e-01  3.354565e-01   \n",
       "VTXP_14                   1.286765e+00  1.189474e+00  1.147757e+00   \n",
       "VWAP_D                    4.151136e+03  4.151165e+03  4.152068e+03   \n",
       "TSV_18_10                -1.990046e+06 -1.617292e+06 -1.603314e+06   \n",
       "TSVs_18_10               -2.019305e+06 -1.973371e+06 -1.933453e+06   \n",
       "WILLR_14                 -1.065574e+01 -1.229508e+01 -1.176471e+01   \n",
       "ZIGZAGv_5.0%_10           4.151620e+03  4.151780e+03  4.153275e+03   \n",
       "ZS_30                     4.213366e-02  1.037961e-02  3.798855e-01   \n",
       "\n",
       "                                  12            13            14    ...  \\\n",
       "Feature                                                             ...   \n",
       "Close                     4.161500e+03  4.159500e+03  4.160000e+03  ...   \n",
       "ACCBU_20                  4.168304e+03  4.167301e+03  4.166131e+03  ...   \n",
       "AD                        2.082303e+05  2.005389e+05  2.013147e+05  ...   \n",
       "DMP_14                    2.824718e+01  2.872952e+01  2.667741e+01  ...   \n",
       "AO_5_34                   1.528676e+00  3.318382e+00  4.690441e+00  ...   \n",
       "OBV                      -1.482038e+06 -1.494857e+06 -1.486323e+06  ...   \n",
       "OBV_min_2                -1.495678e+06 -1.494857e+06 -1.494857e+06  ...   \n",
       "OBV_max_2                -1.482038e+06 -1.482038e+06 -1.486323e+06  ...   \n",
       "OBVe_4                   -1.496192e+06 -1.495658e+06 -1.491924e+06  ...   \n",
       "OBVe_12                  -1.514770e+06 -1.511707e+06 -1.507802e+06  ...   \n",
       "BIAS_SMA_26               2.915155e-03  2.414575e-03  2.572243e-03  ...   \n",
       "open_Z_30_1               4.093402e-01  1.106992e+00  9.031592e-01  ...   \n",
       "high_Z_30_1               8.178374e-01  1.080181e+00  8.499573e-01  ...   \n",
       "low_Z_30_1                5.036993e-01  1.003081e+00  9.115885e-01  ...   \n",
       "close_Z_30_1              1.105363e+00  9.001579e-01  9.544857e-01  ...   \n",
       "CMF_20                    2.941479e-01  3.490623e-01  6.115053e-01  ...   \n",
       "DPO_20                    1.558750e+01  1.456250e+01  1.626250e+01  ...   \n",
       "EFI_13                    1.956393e+04  1.310651e+04  1.184372e+04  ...   \n",
       "BULLP_13                  1.022581e+01  1.162212e+01  8.604675e+00  ...   \n",
       "FISHERT_9_1               2.229439e+00  2.599733e+00  2.545516e+00  ...   \n",
       "FISHERTs_9_1              1.914921e+00  2.229439e+00  2.599733e+00  ...   \n",
       "HL2                       4.157250e+03  4.161375e+03  4.159750e+03  ...   \n",
       "HLC3                      4.158667e+03  4.160750e+03  4.159833e+03  ...   \n",
       "HWL_1                     4.135055e+03  4.137430e+03  4.139294e+03  ...   \n",
       "ICS_26                    4.154250e+03  4.152500e+03  4.145000e+03  ...   \n",
       "INERTIA_20_14             5.555212e+01  5.421098e+01  5.279196e+01  ...   \n",
       "JMA_7_0.0                 4.154276e+03  4.156193e+03  4.157766e+03  ...   \n",
       "K_9_3                     8.193993e+01  7.785894e+01  7.614839e+01  ...   \n",
       "D_9_3                     7.907155e+01  7.866734e+01  7.782769e+01  ...   \n",
       "J_9_3                     8.767669e+01  7.624213e+01  7.278977e+01  ...   \n",
       "KVO_34_55_13              3.280641e+03  3.295326e+03  2.844387e+03  ...   \n",
       "KVOs_34_55_13             3.211421e+03  3.223407e+03  3.169262e+03  ...   \n",
       "MACD_12_26_9              2.050223e+00  2.494104e+00  2.853337e+00  ...   \n",
       "MEDIAN_30                 4.151375e+03  4.151375e+03  4.151375e+03  ...   \n",
       "MFI_14                    9.586857e+01  9.448501e+01  8.354527e+01  ...   \n",
       "NVI_1                     1.002375e+03  1.002327e+03  1.002339e+03  ...   \n",
       "PGO_14                    1.250380e+00  9.244613e-01  8.664028e-01  ...   \n",
       "PVIe_255                 -4.228160e+01 -4.369558e+01 -4.600834e+01  ...   \n",
       "PVOs_12_26_9             -2.875207e+01 -3.174077e+01 -3.459429e+01  ...   \n",
       "PVT                      -9.817743e+05 -9.823903e+05 -9.822878e+05  ...   \n",
       "QQE_14_5_4.236            5.026645e+01  5.121144e+01  5.200040e+01  ...   \n",
       "REMAP_0.0_100.0_-1.0_1.0  8.223000e+01  8.219000e+01  8.220000e+01  ...   \n",
       "RSI_14                    6.075057e+01  5.858126e+01  5.897566e+01  ...   \n",
       "RSX_14                    6.365827e+01  6.646606e+01  6.886907e+01  ...   \n",
       "RVGI_14_4                 1.727795e-01  2.109228e-01  2.429954e-01  ...   \n",
       "SINWMA_14                 4.150191e+03  4.151167e+03  4.152196e+03  ...   \n",
       "SKEW_30                  -6.413590e-01 -6.451062e-01 -6.465694e-01  ...   \n",
       "SMIo_5_20_5_1.0           6.125374e-02  5.520772e-02  4.829349e-02  ...   \n",
       "SSF_20                    4.150356e+03  4.151612e+03  4.152905e+03  ...   \n",
       "STOCHk_14_3_3             9.143807e+01  8.958405e+01  8.705400e+01  ...   \n",
       "STOCHd_14_3_3             9.015822e+01  8.981676e+01  8.935870e+01  ...   \n",
       "STOCHFd_14_3              9.143807e+01  8.958405e+01  8.705400e+01  ...   \n",
       "T3_10_0.7                 4.148871e+03  4.150172e+03  4.151573e+03  ...   \n",
       "THERMOma_20_2_0.5         4.507463e+00  4.625800e+00  4.375724e+00  ...   \n",
       "TMO_14_5_3                1.134416e+01  1.208001e+01  1.231196e+01  ...   \n",
       "TMOs_14_5_3               1.043212e+01  1.125607e+01  1.178401e+01  ...   \n",
       "TOS_STDEVALL_LR           4.146145e+03  4.146336e+03  4.146527e+03  ...   \n",
       "TOS_STDEVALL_L_1          3.518790e+03  3.518981e+03  3.519172e+03  ...   \n",
       "TOS_STDEVALL_U_1          4.773500e+03  4.773691e+03  4.773882e+03  ...   \n",
       "TOS_STDEVALL_L_2          2.891435e+03  2.891626e+03  2.891817e+03  ...   \n",
       "TOS_STDEVALL_U_2          5.400855e+03  5.401046e+03  5.401237e+03  ...   \n",
       "TOS_STDEVALL_L_3          2.264080e+03  2.264271e+03  2.264462e+03  ...   \n",
       "TOS_STDEVALL_U_3          6.028210e+03  6.028401e+03  6.028592e+03  ...   \n",
       "TRENDFLEX_20_20_0.04      6.591198e-01  8.701693e-01  1.013757e+00  ...   \n",
       "TRIX_30_9                 3.680240e-03  3.767331e-03  3.890996e-03  ...   \n",
       "TRIXs_30_9                3.871992e-03  3.811885e-03  3.783080e-03  ...   \n",
       "TSI_13_25_13              6.184772e+00  7.719978e+00  9.108354e+00  ...   \n",
       "TSIs_13_25_13             1.833865e+00  2.674739e+00  3.593827e+00  ...   \n",
       "UI_14                     2.726838e-01  2.426081e-01  2.050873e-01  ...   \n",
       "UO_7_14_28                6.609550e+01  6.173662e+01  6.082907e+01  ...   \n",
       "VHF_28                    3.166333e-01  3.153693e-01  3.160000e-01  ...   \n",
       "VTXP_14                   1.323615e+00  1.349673e+00  1.277397e+00  ...   \n",
       "VWAP_D                    4.153240e+03  4.154314e+03  4.154794e+03  ...   \n",
       "TSV_18_10                 3.759792e+06  1.367926e+06  6.266358e+05  ...   \n",
       "TSVs_18_10               -1.357224e+06 -1.018914e+06 -7.589260e+05  ...   \n",
       "WILLR_14                 -1.626016e+00 -1.785714e+01 -1.935484e+01  ...   \n",
       "ZIGZAGv_5.0%_10           4.156270e+03  4.158266e+03  4.160173e+03  ...   \n",
       "ZS_30                     1.105363e+00  9.001579e-01  9.544857e-01  ...   \n",
       "\n",
       "                                  8567          8568          8569  \\\n",
       "Feature                                                              \n",
       "Close                     5.973250e+03  5.986000e+03  5.994500e+03   \n",
       "ACCBU_20                  5.984628e+03  5.987217e+03  5.988953e+03   \n",
       "AD                        2.693935e+07  2.707224e+07  2.718468e+07   \n",
       "DMP_14                    4.060165e+01  4.745153e+01  5.356214e+01   \n",
       "AO_5_34                   2.624265e+01  2.546985e+01  2.647279e+01   \n",
       "OBV                       1.236755e+07  1.251443e+07  1.267185e+07   \n",
       "OBV_min_2                 1.236755e+07  1.236755e+07  1.251443e+07   \n",
       "OBV_max_2                 1.236755e+07  1.251443e+07  1.267185e+07   \n",
       "OBVe_4                    1.235951e+07  1.242148e+07  1.252163e+07   \n",
       "OBVe_12                   1.231016e+07  1.234159e+07  1.239240e+07   \n",
       "BIAS_SMA_26               3.176418e-03  4.921751e-03  6.020684e-03   \n",
       "open_Z_30_1               1.205616e+00  1.190329e+00  1.787147e+00   \n",
       "high_Z_30_1               1.401504e+00  2.062503e+00  2.432652e+00   \n",
       "low_Z_30_1                1.067706e+00  1.203581e+00  1.712225e+00   \n",
       "close_Z_30_1              1.192044e+00  1.800801e+00  2.039608e+00   \n",
       "CMF_20                    2.108053e-01  2.892367e-01  3.496854e-01   \n",
       "DPO_20                   -1.307500e+01 -1.937500e+00  4.775000e+00   \n",
       "EFI_13                    6.140097e+04  3.201645e+05  4.655771e+05   \n",
       "BULLP_13                  1.171310e+01  1.850408e+01  2.425350e+01   \n",
       "FISHERT_9_1               2.568644e+00  2.920939e+00  3.303538e+00   \n",
       "FISHERTs_9_1              2.283366e+00  2.568644e+00  2.920939e+00   \n",
       "HL2                       5.972000e+03  5.978875e+03  5.990125e+03   \n",
       "HLC3                      5.972417e+03  5.981250e+03  5.991583e+03   \n",
       "HWL_1                     5.928553e+03  5.930691e+03  5.934403e+03   \n",
       "ICS_26                    6.021250e+03  6.022750e+03  6.024750e+03   \n",
       "INERTIA_20_14             6.206446e+01  6.258902e+01  6.417971e+01   \n",
       "JMA_7_0.0                 5.971116e+03  5.973944e+03  5.979500e+03   \n",
       "K_9_3                     8.183969e+01  8.698404e+01  8.974612e+01   \n",
       "D_9_3                     8.089347e+01  8.292366e+01  8.519781e+01   \n",
       "J_9_3                     8.373214e+01  9.510479e+01  9.884272e+01   \n",
       "KVO_34_55_13              2.474286e+03  4.971685e+03  7.457904e+03   \n",
       "KVOs_34_55_13             5.363817e+03  5.307798e+03  5.614956e+03   \n",
       "MACD_12_26_9              1.922638e+01  1.937748e+01  1.995310e+01   \n",
       "MEDIAN_30                 5.957250e+03  5.958250e+03  5.959625e+03   \n",
       "MFI_14                    8.281076e+01  9.334781e+01  9.551555e+01   \n",
       "NVI_1                     1.055676e+03  1.055676e+03  1.055676e+03   \n",
       "PGO_14                    5.040623e-01  1.249365e+00  1.712068e+00   \n",
       "PVIe_255                  1.000087e+02  1.000103e+02  1.000113e+02   \n",
       "PVOs_12_26_9             -3.644379e+01 -3.125328e+01 -2.344944e+01   \n",
       "PVT                      -3.634002e+05 -3.320480e+05 -3.096950e+05   \n",
       "QQE_14_5_4.236            7.355084e+01  7.355084e+01  7.355084e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  1.184650e+02  1.187200e+02  1.188900e+02   \n",
       "RSI_14                    6.950855e+01  7.412439e+01  7.666097e+01   \n",
       "RSX_14                    6.507449e+01  6.881229e+01  7.458174e+01   \n",
       "RVGI_14_4                 1.023827e-01  1.240573e-01  1.854329e-01   \n",
       "SINWMA_14                 5.966313e+03  5.967751e+03  5.969445e+03   \n",
       "SKEW_30                  -9.182607e-01 -8.495784e-01 -6.180142e-01   \n",
       "SMIo_5_20_5_1.0           1.108658e-02  4.280662e-02  6.874518e-02   \n",
       "SSF_20                    5.967594e+03  5.969037e+03  5.971235e+03   \n",
       "STOCHk_14_3_3             8.941286e+01  9.172888e+01  9.298230e+01   \n",
       "STOCHd_14_3_3             8.929195e+01  9.077733e+01  9.137468e+01   \n",
       "STOCHFd_14_3              8.941286e+01  9.172888e+01  9.298230e+01   \n",
       "T3_10_0.7                 5.973364e+03  5.974276e+03  5.975717e+03   \n",
       "THERMOma_20_2_0.5         5.451499e+00  5.860880e+00  6.540797e+00   \n",
       "TMO_14_5_3                1.277640e+01  1.314110e+01  1.340582e+01   \n",
       "TMOs_14_5_3               1.231051e+01  1.272581e+01  1.306581e+01   \n",
       "TOS_STDEVALL_LR           5.781979e+03  5.782170e+03  5.782361e+03   \n",
       "TOS_STDEVALL_L_1          5.154624e+03  5.154815e+03  5.155006e+03   \n",
       "TOS_STDEVALL_U_1          6.409334e+03  6.409525e+03  6.409716e+03   \n",
       "TOS_STDEVALL_L_2          4.527269e+03  4.527460e+03  4.527651e+03   \n",
       "TOS_STDEVALL_U_2          7.036689e+03  7.036880e+03  7.037071e+03   \n",
       "TOS_STDEVALL_L_3          3.899914e+03  3.900105e+03  3.900296e+03   \n",
       "TOS_STDEVALL_U_3          7.664043e+03  7.664235e+03  7.664426e+03   \n",
       "TRENDFLEX_20_20_0.04      3.345613e-01  3.419521e-01  3.988178e-01   \n",
       "TRIX_30_9                 5.753779e-02  5.748568e-02  5.743222e-02   \n",
       "TRIXs_30_9                5.671379e-02  5.700357e-02  5.720408e-02   \n",
       "TSI_13_25_13              3.802363e+01  3.933187e+01  4.123717e+01   \n",
       "TSIs_13_25_13             3.988342e+01  3.980462e+01  4.000927e+01   \n",
       "UI_14                     8.334618e-02  5.735406e-02  5.124493e-02   \n",
       "UO_7_14_28                5.557620e+01  6.610483e+01  6.983166e+01   \n",
       "VHF_28                    3.363636e-01  3.836634e-01  4.195122e-01   \n",
       "VTXP_14                   1.102506e+00  1.174292e+00  1.279221e+00   \n",
       "VWAP_D                    5.967518e+03  5.973881e+03  5.979756e+03   \n",
       "TSV_18_10                 2.217585e+06  3.856410e+06  4.009367e+06   \n",
       "TSVs_18_10                3.273433e+06  3.524712e+06  3.775964e+06   \n",
       "WILLR_14                 -1.442308e+01 -2.142857e+00 -4.487179e+00   \n",
       "ZIGZAGv_5.0%_10           5.973363e+03  5.978388e+03  5.985590e+03   \n",
       "ZS_30                     1.192044e+00  1.800801e+00  2.039608e+00   \n",
       "\n",
       "                                  8570          8571          8572  \\\n",
       "Feature                                                              \n",
       "Close                     5.997750e+03  6.000500e+03  5.994000e+03   \n",
       "ACCBU_20                  5.991153e+03  5.992202e+03  5.994153e+03   \n",
       "AD                        2.726441e+07  2.731116e+07  2.730461e+07   \n",
       "DMP_14                    5.273627e+01  5.171939e+01  4.802515e+01   \n",
       "AO_5_34                   2.810368e+01  3.026250e+01  3.244265e+01   \n",
       "OBV                       1.277815e+07  1.285295e+07  1.276783e+07   \n",
       "OBV_min_2                 1.267185e+07  1.277815e+07  1.276783e+07   \n",
       "OBV_max_2                 1.277815e+07  1.285295e+07  1.285295e+07   \n",
       "OBVe_4                    1.262424e+07  1.271572e+07  1.273657e+07   \n",
       "OBVe_12                   1.245175e+07  1.251347e+07  1.255260e+07   \n",
       "BIAS_SMA_26               6.148843e-03  6.013006e-03  4.426155e-03   \n",
       "open_Z_30_1               2.040170e+00  1.992514e+00  1.908267e+00   \n",
       "high_Z_30_1               2.320812e+00  2.212235e+00  1.947365e+00   \n",
       "low_Z_30_1                1.708237e+00  1.831435e+00  1.465294e+00   \n",
       "close_Z_30_1              1.981715e+00  1.909438e+00  1.507856e+00   \n",
       "CMF_20                    3.989106e-01  6.411883e-01  5.310785e-01   \n",
       "DPO_20                    5.950000e+00  6.712500e+00 -1.662500e+00   \n",
       "EFI_13                    4.484211e+05  4.137435e+05  2.756019e+05   \n",
       "BULLP_13                  2.357443e+01  2.277808e+01  1.966693e+01   \n",
       "FISHERT_9_1               3.699195e+00  4.100004e+00  3.567664e+00   \n",
       "FISHERTs_9_1              3.303538e+00  3.699195e+00  4.100004e+00   \n",
       "HL2                       5.993250e+03  5.998000e+03  5.994500e+03   \n",
       "HLC3                      5.994750e+03  5.998833e+03  5.994333e+03   \n",
       "HWL_1                     5.937319e+03  5.939943e+03  5.941053e+03   \n",
       "ICS_26                    6.034000e+03  6.033000e+03  6.027250e+03   \n",
       "INERTIA_20_14             6.674493e+01  7.016600e+01  7.105264e+01   \n",
       "JMA_7_0.0                 5.985653e+03  5.991209e+03  5.994500e+03   \n",
       "K_9_3                     9.185689e+01  9.323792e+01  8.833311e+01   \n",
       "D_9_3                     8.741750e+01  8.935764e+01  8.901613e+01   \n",
       "J_9_3                     1.007357e+02  1.009985e+02  8.696707e+01   \n",
       "KVO_34_55_13              8.607793e+03  8.960450e+03  5.836215e+03   \n",
       "KVOs_34_55_13             6.042504e+03  6.459354e+03  6.370334e+03   \n",
       "MACD_12_26_9              2.043596e+01  2.080075e+01  2.033100e+01   \n",
       "MEDIAN_30                 5.961000e+03  5.962750e+03  5.964875e+03   \n",
       "MFI_14                    9.632179e+01  9.671841e+01  8.498483e+01   \n",
       "NVI_1                     1.055730e+03  1.055776e+03  1.055776e+03   \n",
       "PGO_14                    1.776094e+00  1.819342e+00  1.200681e+00   \n",
       "PVIe_255                  1.000112e+02  1.000112e+02  1.000102e+02   \n",
       "PVOs_12_26_9             -1.620705e+01 -1.046451e+01 -5.711872e+00   \n",
       "PVT                      -3.039316e+05 -3.005023e+05 -3.097224e+05   \n",
       "QQE_14_5_4.236            6.942779e+01  7.081797e+01  7.081797e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  1.189550e+02  1.190100e+02  1.188800e+02   \n",
       "RSI_14                    7.756651e+01  7.833257e+01  7.206823e+01   \n",
       "RSX_14                    8.036372e+01  8.530430e+01  8.623272e+01   \n",
       "RVGI_14_4                 2.490076e-01  2.794944e-01  2.699282e-01   \n",
       "SINWMA_14                 5.971563e+03  5.974032e+03  5.976719e+03   \n",
       "SKEW_30                  -4.487516e-01 -3.694177e-01 -4.189862e-01   \n",
       "SMIo_5_20_5_1.0           7.633023e-02  7.483614e-02  2.445328e-02   \n",
       "SSF_20                    5.974140e+03  5.977502e+03  5.980844e+03   \n",
       "STOCHk_14_3_3             9.657048e+01  9.611517e+01  9.137308e+01   \n",
       "STOCHd_14_3_3             9.376055e+01  9.522265e+01  9.468624e+01   \n",
       "STOCHFd_14_3              9.657048e+01  9.611517e+01  9.137308e+01   \n",
       "T3_10_0.7                 5.977751e+03  5.980328e+03  5.983132e+03   \n",
       "THERMOma_20_2_0.5         6.227387e+00  6.277160e+00  6.250764e+00   \n",
       "TMO_14_5_3                1.359309e+01  1.372333e+01  1.314619e+01   \n",
       "TMOs_14_5_3               1.332945e+01  1.352639e+01  1.333629e+01   \n",
       "TOS_STDEVALL_LR           5.782552e+03  5.782743e+03  5.782935e+03   \n",
       "TOS_STDEVALL_L_1          5.155197e+03  5.155388e+03  5.155580e+03   \n",
       "TOS_STDEVALL_U_1          6.409907e+03  6.410098e+03  6.410290e+03   \n",
       "TOS_STDEVALL_L_2          4.527842e+03  4.528034e+03  4.528225e+03   \n",
       "TOS_STDEVALL_U_2          7.037262e+03  7.037453e+03  7.037645e+03   \n",
       "TOS_STDEVALL_L_3          3.900487e+03  3.900679e+03  3.900870e+03   \n",
       "TOS_STDEVALL_U_3          7.664617e+03  7.664808e+03  7.665000e+03   \n",
       "TRENDFLEX_20_20_0.04      4.854378e-01  5.738011e-01  6.294633e-01   \n",
       "TRIX_30_9                 5.737740e-02  5.731896e-02  5.721271e-02   \n",
       "TRIXs_30_9                5.733201e-02  5.740000e-02  5.741596e-02   \n",
       "TSI_13_25_13              4.312191e+01  4.494656e+01  4.485782e+01   \n",
       "TSIs_13_25_13             4.045394e+01  4.109574e+01  4.163318e+01   \n",
       "UI_14                     3.869508e-02  3.735938e-02  4.721081e-02   \n",
       "UO_7_14_28                7.546038e+01  7.535806e+01  7.101469e+01   \n",
       "VHF_28                    4.691196e-01  5.287356e-01  5.411765e-01   \n",
       "VTXP_14                   1.244898e+00  1.294845e+00  1.201566e+00   \n",
       "VWAP_D                    5.982501e+03  5.984364e+03  5.985510e+03   \n",
       "TSV_18_10                 3.798969e+06  4.004647e+06  3.486299e+06   \n",
       "TSVs_18_10                3.940801e+06  4.212663e+06  4.370122e+06   \n",
       "WILLR_14                 -3.658537e+00 -3.508772e+00 -1.871345e+01   \n",
       "ZIGZAGv_5.0%_10           5.992256e+03  5.998709e+03  5.999308e+03   \n",
       "ZS_30                     1.981715e+00  1.909438e+00  1.507856e+00   \n",
       "\n",
       "                                  8573          8574          8575  \\\n",
       "Feature                                                              \n",
       "Close                     6.006750e+03  6.002500e+03  6.006500e+03   \n",
       "ACCBU_20                  5.997556e+03  6.000494e+03  6.002481e+03   \n",
       "AD                        2.746039e+07  2.735296e+07  2.737218e+07   \n",
       "DMP_14                    5.034478e+01  5.299873e+01  4.921310e+01   \n",
       "AO_5_34                   3.408015e+01  3.528603e+01  3.592426e+01   \n",
       "OBV                       1.292362e+07  1.268396e+07  1.275444e+07   \n",
       "OBV_min_2                 1.276783e+07  1.268396e+07  1.268396e+07   \n",
       "OBV_max_2                 1.292362e+07  1.292362e+07  1.275444e+07   \n",
       "OBVe_4                    1.281139e+07  1.276042e+07  1.275803e+07   \n",
       "OBVe_12                   1.260968e+07  1.262111e+07  1.264162e+07   \n",
       "BIAS_SMA_26               6.103925e-03  4.992281e-03  5.299469e-03   \n",
       "open_Z_30_1               1.506266e+00  1.902491e+00  1.590901e+00   \n",
       "high_Z_30_1               2.044202e+00  2.130648e+00  1.805048e+00   \n",
       "low_Z_30_1                1.273022e+00  1.699312e+00  1.785438e+00   \n",
       "close_Z_30_1              1.904292e+00  1.591887e+00  1.745361e+00   \n",
       "CMF_20                    6.125747e-01  3.970077e-01  3.887067e-01   \n",
       "DPO_20                    9.212500e+00  3.212500e+00  5.562500e+00   \n",
       "EFI_13                    5.199815e+05  3.001936e+05  2.975825e+05   \n",
       "BULLP_13                  2.178594e+01  2.553080e+01  1.931212e+01   \n",
       "FISHERT_9_1               3.242039e+00  3.288318e+00  3.441850e+00   \n",
       "FISHERTs_9_1              3.567664e+00  3.242039e+00  3.288318e+00   \n",
       "HL2                       5.996125e+03  6.005750e+03  6.005375e+03   \n",
       "HLC3                      5.999667e+03  6.004667e+03  6.005750e+03   \n",
       "HWL_1                     5.945177e+03  5.948981e+03  5.952572e+03   \n",
       "ICS_26                    6.023500e+03  6.037500e+03  6.033000e+03   \n",
       "INERTIA_20_14             7.250672e+01  7.078785e+01  7.074790e+01   \n",
       "JMA_7_0.0                 5.998036e+03  6.000624e+03  6.002831e+03   \n",
       "K_9_3                     9.222208e+01  8.720602e+01  8.676054e+01   \n",
       "D_9_3                     9.008478e+01  8.912519e+01  8.833697e+01   \n",
       "J_9_3                     9.649666e+01  8.336768e+01  8.360766e+01   \n",
       "KVO_34_55_13              8.145944e+03  1.202650e+04  1.190490e+04   \n",
       "KVOs_34_55_13             6.623992e+03  7.395779e+03  8.039939e+03   \n",
       "MACD_12_26_9              2.074835e+01  2.049986e+01  2.039065e+01   \n",
       "MEDIAN_30                 5.966000e+03  5.966750e+03  5.967375e+03   \n",
       "MFI_14                    8.762314e+01  9.029606e+01  9.159947e+01   \n",
       "NVI_1                     1.055776e+03  1.055776e+03  1.055843e+03   \n",
       "PGO_14                    1.977739e+00  1.466952e+00  1.537809e+00   \n",
       "PVIe_255                  1.000118e+02  1.000112e+02  1.000111e+02   \n",
       "PVOs_12_26_9             -4.244935e-01  5.915452e+00  9.847815e+00   \n",
       "PVT                      -2.765849e+05 -2.935414e+05 -2.888448e+05   \n",
       "QQE_14_5_4.236            7.081797e+01  7.081797e+01  7.081797e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  1.191350e+02  1.190500e+02  1.191300e+02   \n",
       "RSI_14                    7.610490e+01  7.235141e+01  7.366774e+01   \n",
       "RSX_14                    8.629864e+01  8.450356e+01  8.269691e+01   \n",
       "RVGI_14_4                 2.526144e-01  2.394753e-01  2.476489e-01   \n",
       "SINWMA_14                 5.979823e+03  5.983191e+03  5.986720e+03   \n",
       "SKEW_30                  -3.539377e-01 -4.057929e-01 -2.981428e-02   \n",
       "SMIo_5_20_5_1.0           2.472880e-02 -3.127772e-03 -6.304254e-03   \n",
       "SSF_20                    5.984160e+03  5.987515e+03  5.990686e+03   \n",
       "STOCHk_14_3_3             9.259259e+01  8.725056e+01  8.932171e+01   \n",
       "STOCHd_14_3_3             9.336028e+01  9.040541e+01  8.972162e+01   \n",
       "STOCHFd_14_3              9.259259e+01  8.725056e+01  8.932171e+01   \n",
       "T3_10_0.7                 5.986226e+03  5.989422e+03  5.992646e+03   \n",
       "THERMOma_20_2_0.5         6.203072e+00  6.850399e+00  6.531313e+00   \n",
       "TMO_14_5_3                1.309611e+01  1.323007e+01  1.306971e+01   \n",
       "TMOs_14_5_3               1.321620e+01  1.322313e+01  1.314642e+01   \n",
       "TOS_STDEVALL_LR           5.783126e+03  5.783317e+03  5.783508e+03   \n",
       "TOS_STDEVALL_L_1          5.155771e+03  5.155962e+03  5.156153e+03   \n",
       "TOS_STDEVALL_U_1          6.410481e+03  6.410672e+03  6.410863e+03   \n",
       "TOS_STDEVALL_L_2          4.528416e+03  4.528607e+03  4.528798e+03   \n",
       "TOS_STDEVALL_U_2          7.037836e+03  7.038027e+03  7.038218e+03   \n",
       "TOS_STDEVALL_L_3          3.901061e+03  3.901252e+03  3.901443e+03   \n",
       "TOS_STDEVALL_U_3          7.665191e+03  7.665382e+03  7.665573e+03   \n",
       "TRENDFLEX_20_20_0.04      6.680247e-01  7.022326e-01  7.165596e-01   \n",
       "TRIX_30_9                 5.711138e-02  5.698013e-02  5.682867e-02   \n",
       "TRIXs_30_9                5.739166e-02  5.733503e-02  5.725388e-02   \n",
       "TSI_13_25_13              4.598642e+01  4.582359e+01  4.606950e+01   \n",
       "TSIs_13_25_13             4.225507e+01  4.276486e+01  4.323695e+01   \n",
       "UI_14                     4.721081e-02  5.006249e-02  3.610353e-02   \n",
       "UO_7_14_28                7.672695e+01  7.282680e+01  7.048927e+01   \n",
       "VHF_28                    5.673534e-01  4.616639e-01  4.765343e-01   \n",
       "VTXP_14                   1.136678e+00  1.208130e+00  1.274510e+00   \n",
       "VWAP_D                    5.987970e+03  5.991493e+03  5.992325e+03   \n",
       "TSV_18_10                 5.403606e+06  4.396376e+06  4.637672e+06   \n",
       "TSVs_18_10                4.013046e+06  3.802685e+06  3.904339e+06   \n",
       "WILLR_14                 -0.000000e+00 -1.953488e+01 -1.250000e+01   \n",
       "ZIGZAGv_5.0%_10           6.002888e+03  6.003681e+03  6.005285e+03   \n",
       "ZS_30                     1.904292e+00  1.591887e+00  1.745361e+00   \n",
       "\n",
       "                                  8576          8577          8578  \\\n",
       "Feature                                                              \n",
       "Close                     6.007250e+03  6.003750e+03  6.005250e+03   \n",
       "ACCBU_20                  6.005019e+03  6.006743e+03  6.008318e+03   \n",
       "AD                        2.737218e+07  2.736824e+07  2.737248e+07   \n",
       "DMP_14                    4.569788e+01  4.243375e+01  3.940276e+01   \n",
       "AO_5_34                   3.530294e+01  3.558750e+01  3.527721e+01   \n",
       "OBV                       1.275444e+07  1.274967e+07  1.275545e+07   \n",
       "OBV_min_2                 1.275444e+07  1.274967e+07  1.274967e+07   \n",
       "OBV_max_2                 1.275444e+07  1.275444e+07  1.275545e+07   \n",
       "OBVe_4                    1.275659e+07  1.275382e+07  1.275447e+07   \n",
       "OBVe_12                   1.265898e+07  1.267293e+07  1.268562e+07   \n",
       "BIAS_SMA_26               5.074003e-03  4.191166e-03  4.190115e-03   \n",
       "open_Z_30_1               1.796922e+00  1.737972e+00  1.492893e+00   \n",
       "high_Z_30_1               1.673110e+00  1.596713e+00  1.358206e+00   \n",
       "low_Z_30_1                1.784095e+00  1.839060e+00  1.683604e+00   \n",
       "close_Z_30_1              1.747173e+00  1.490349e+00  1.482607e+00   \n",
       "CMF_20                    3.930151e-01  3.890651e-01  3.920534e-01   \n",
       "DPO_20                    5.275000e+00  1.250000e+00  2.362500e+00   \n",
       "EFI_13                    2.550707e+05  2.162460e+05  1.865919e+05   \n",
       "BULLP_13                  1.637467e+01  1.478543e+01  9.958943e+00   \n",
       "FISHERT_9_1               3.642659e+00  3.946824e+00  3.289602e+00   \n",
       "FISHERTs_9_1              3.441850e+00  3.642659e+00  3.946824e+00   \n",
       "HL2                       6.005500e+03  6.006125e+03  6.003875e+03   \n",
       "HLC3                      6.006083e+03  6.005333e+03  6.004333e+03   \n",
       "HWL_1                     5.956892e+03  5.960123e+03  5.963754e+03   \n",
       "ICS_26                    6.035250e+03  6.033250e+03  6.034250e+03   \n",
       "INERTIA_20_14             7.101718e+01  6.953468e+01  6.949494e+01   \n",
       "JMA_7_0.0                 6.004699e+03  6.005616e+03  6.006017e+03   \n",
       "K_9_3                     8.661020e+01  8.044128e+01  7.756692e+01   \n",
       "D_9_3                     8.776138e+01  8.532135e+01  8.273654e+01   \n",
       "J_9_3                     8.430783e+01  7.068115e+01  6.722767e+01   \n",
       "KVO_34_55_13              1.025978e+04  8.640865e+03  7.129785e+03   \n",
       "KVOs_34_55_13             8.357059e+03  8.397603e+03  8.216486e+03   \n",
       "MACD_12_26_9              2.013254e+01  1.942168e+01  1.876307e+01   \n",
       "MEDIAN_30                 5.967625e+03  5.968500e+03  5.970125e+03   \n",
       "MFI_14                    9.144500e+01  9.093970e+01  9.036733e+01   \n",
       "NVI_1                     1.055855e+03  1.055855e+03  1.055855e+03   \n",
       "PGO_14                    1.391676e+00  9.290368e-01  8.694947e-01   \n",
       "PVIe_255                  1.000110e+02  1.000104e+02  1.000106e+02   \n",
       "PVOs_12_26_9              1.082991e+01  9.741585e+00  7.200476e+00   \n",
       "PVT                      -2.888448e+05 -2.891228e+05 -2.889784e+05   \n",
       "QQE_14_5_4.236            7.081797e+01  7.081797e+01  7.081797e+01   \n",
       "REMAP_0.0_100.0_-1.0_1.0  1.191450e+02  1.190750e+02  1.191050e+02   \n",
       "RSI_14                    7.391848e+01  7.054274e+01  7.115082e+01   \n",
       "RSX_14                    8.125428e+01  7.907256e+01  7.696025e+01   \n",
       "RVGI_14_4                 2.621413e-01  2.644284e-01  2.553011e-01   \n",
       "SINWMA_14                 5.990147e+03  5.993381e+03  5.996309e+03   \n",
       "SKEW_30                   3.743399e-01  4.159029e-01  4.265290e-01   \n",
       "SMIo_5_20_5_1.0          -5.370630e-03 -2.506413e-02 -2.729563e-02   \n",
       "SSF_20                    5.993692e+03  5.996329e+03  5.998510e+03   \n",
       "STOCHk_14_3_3             8.536982e+01  8.549112e+01  8.430372e+01   \n",
       "STOCHd_14_3_3             8.731403e+01  8.672755e+01  8.505488e+01   \n",
       "STOCHFd_14_3              8.536982e+01  8.549112e+01  8.430372e+01   \n",
       "T3_10_0.7                 5.995808e+03  5.998724e+03  6.001325e+03   \n",
       "THERMOma_20_2_0.5         5.980712e+00  5.530168e+00  5.313009e+00   \n",
       "TMO_14_5_3                1.317130e+01  1.267662e+01  1.173229e+01   \n",
       "TMOs_14_5_3               1.315886e+01  1.291774e+01  1.232501e+01   \n",
       "TOS_STDEVALL_LR           5.783700e+03  5.783891e+03  5.784082e+03   \n",
       "TOS_STDEVALL_L_1          5.156345e+03  5.156536e+03  5.156727e+03   \n",
       "TOS_STDEVALL_U_1          6.411054e+03  6.411246e+03  6.411437e+03   \n",
       "TOS_STDEVALL_L_2          4.528990e+03  4.529181e+03  4.529372e+03   \n",
       "TOS_STDEVALL_U_2          7.038409e+03  7.038601e+03  7.038792e+03   \n",
       "TOS_STDEVALL_L_3          3.901635e+03  3.901826e+03  3.902017e+03   \n",
       "TOS_STDEVALL_U_3          7.665764e+03  7.665956e+03  7.666147e+03   \n",
       "TRENDFLEX_20_20_0.04      7.212541e-01  7.038339e-01  6.662732e-01   \n",
       "TRIX_30_9                 5.665035e-02  5.642067e-02  5.614318e-02   \n",
       "TRIXs_30_9                5.715528e-02  5.703694e-02  5.689372e-02   \n",
       "TSI_13_25_13              4.634154e+01  4.563893e+01  4.520910e+01   \n",
       "TSIs_13_25_13             4.368046e+01  4.396024e+01  4.413865e+01   \n",
       "UI_14                     3.547338e-02  3.793993e-02  3.896937e-02   \n",
       "UO_7_14_28                6.981889e+01  6.535797e+01  6.489388e+01   \n",
       "VHF_28                    4.219331e-01  4.249513e-01  4.282908e-01   \n",
       "VTXP_14                   1.277027e+00  1.266781e+00  1.240069e+00   \n",
       "VWAP_D                    5.992325e+03  6.005333e+03  6.004786e+03   \n",
       "TSV_18_10                 4.629050e+06  4.590988e+06  4.610027e+06   \n",
       "TSVs_18_10                4.043998e+06  4.281338e+06  4.356700e+06   \n",
       "WILLR_14                 -1.185567e+01 -1.917098e+01 -1.606218e+01   \n",
       "ZIGZAGv_5.0%_10           6.008051e+03  6.006724e+03  6.006956e+03   \n",
       "ZS_30                     1.747173e+00  1.490349e+00  1.482607e+00   \n",
       "\n",
       "                                  8579          8580          8581  \n",
       "Feature                                                             \n",
       "Close                     6.001500e+03  6.003000e+03  6.003000e+03  \n",
       "ACCBU_20                  6.010281e+03  6.011655e+03  6.012930e+03  \n",
       "AD                        2.736764e+07  2.736796e+07  2.736673e+07  \n",
       "DMP_14                    3.783828e+01  3.513555e+01  3.362587e+01  \n",
       "AO_5_34                   3.250735e+01  2.967279e+01  2.694485e+01  \n",
       "OBV                       1.275014e+07  1.275370e+07  1.275370e+07  \n",
       "OBV_min_2                 1.275014e+07  1.275014e+07  1.275370e+07  \n",
       "OBV_max_2                 1.275545e+07  1.275370e+07  1.275370e+07  \n",
       "OBVe_4                    1.275274e+07  1.275312e+07  1.275336e+07  \n",
       "OBVe_12                   1.269555e+07  1.270450e+07  1.271207e+07  \n",
       "BIAS_SMA_26               3.274293e-03  3.200926e-03  2.926955e-03  \n",
       "open_Z_30_1               1.473237e+00  1.198790e+00  1.187124e+00  \n",
       "high_Z_30_1               1.336169e+00  1.114644e+00  1.093432e+00  \n",
       "low_Z_30_1                1.546743e+00  1.462134e+00  1.389301e+00  \n",
       "close_Z_30_1              1.206776e+00  1.207136e+00  1.130451e+00  \n",
       "CMF_20                    3.853398e-01  3.892919e-01  3.940495e-01  \n",
       "DPO_20                   -1.412500e+00 -6.375000e-01 -2.000000e+00  \n",
       "EFI_13                    1.570950e+05  1.354153e+05  1.160703e+05  \n",
       "BULLP_13                  1.039338e+01  6.730040e+00  6.947177e+00  \n",
       "FISHERT_9_1               2.733930e+00  2.194553e+00  1.822363e+00  \n",
       "FISHERTs_9_1              3.289602e+00  2.733930e+00  2.194553e+00  \n",
       "HL2                       6.004125e+03  6.002875e+03  6.003625e+03  \n",
       "HLC3                      6.003250e+03  6.002917e+03  6.003417e+03  \n",
       "HWL_1                     5.966748e+03  5.969986e+03  5.973269e+03  \n",
       "ICS_26                    6.036500e+03  6.036250e+03  6.037500e+03  \n",
       "INERTIA_20_14             6.825568e+01  6.747416e+01  6.632187e+01  \n",
       "JMA_7_0.0                 6.005595e+03  6.004954e+03  6.004355e+03  \n",
       "K_9_3                     7.110522e+01  6.861560e+01  6.695585e+01  \n",
       "D_9_3                     7.885943e+01  7.544482e+01  7.261516e+01  \n",
       "J_9_3                     5.559679e+01  5.495716e+01  5.563723e+01  \n",
       "KVO_34_55_13              5.751563e+03  4.524162e+03  3.543660e+03  \n",
       "KVOs_34_55_13             7.864354e+03  7.387184e+03  6.838109e+03  \n",
       "MACD_12_26_9              1.773410e+01  1.684548e+01  1.595730e+01  \n",
       "MEDIAN_30                 5.971000e+03  5.972125e+03  5.973250e+03  \n",
       "MFI_14                    9.086771e+01  9.041339e+01  9.013075e+01  \n",
       "NVI_1                     1.055793e+03  1.055818e+03  1.055818e+03  \n",
       "PGO_14                    4.001619e-01  3.572166e-01  1.834141e-01  \n",
       "PVIe_255                  1.000105e+02  1.000104e+02  1.000103e+02  \n",
       "PVOs_12_26_9              3.648669e+00 -6.170698e-01 -5.329524e+00  \n",
       "PVT                      -2.893096e+05 -2.892207e+05 -2.892207e+05  \n",
       "QQE_14_5_4.236            7.502906e+01  7.414827e+01  7.354265e+01  \n",
       "REMAP_0.0_100.0_-1.0_1.0  1.190300e+02  1.190600e+02  1.190600e+02  \n",
       "RSI_14                    6.740472e+01  6.812759e+01  6.812759e+01  \n",
       "RSX_14                    7.395762e+01  7.099563e+01  6.829002e+01  \n",
       "RVGI_14_4                 2.345183e-01  2.184874e-01  2.092199e-01  \n",
       "SINWMA_14                 5.998798e+03  6.000771e+03  6.002191e+03  \n",
       "SKEW_30                   3.277945e-01  2.215375e-01  9.341712e-02  \n",
       "SMIo_5_20_5_1.0          -4.828700e-02 -4.783649e-02 -4.237481e-02  \n",
       "SSF_20                    6.000201e+03  6.001409e+03  6.002278e+03  \n",
       "STOCHk_14_3_3             7.992228e+01  7.906623e+01  7.648378e+01  \n",
       "STOCHd_14_3_3             8.323904e+01  8.109741e+01  7.849076e+01  \n",
       "STOCHFd_14_3              7.992228e+01  7.906623e+01  7.648378e+01  \n",
       "T3_10_0.7                 6.003480e+03  6.005187e+03  6.006475e+03  \n",
       "THERMOma_20_2_0.5         4.926056e+00  4.718812e+00  4.364640e+00  \n",
       "TMO_14_5_3                1.012879e+01  8.572832e+00  7.292039e+00  \n",
       "TMOs_14_5_3               1.122690e+01  9.899868e+00  8.595953e+00  \n",
       "TOS_STDEVALL_LR           5.784273e+03  5.784464e+03  5.784656e+03  \n",
       "TOS_STDEVALL_L_1          5.156918e+03  5.157109e+03  5.157301e+03  \n",
       "TOS_STDEVALL_U_1          6.411628e+03  6.411819e+03  6.412011e+03  \n",
       "TOS_STDEVALL_L_2          4.529563e+03  4.529754e+03  4.529946e+03  \n",
       "TOS_STDEVALL_U_2          7.038983e+03  7.039174e+03  7.039366e+03  \n",
       "TOS_STDEVALL_L_3          3.902208e+03  3.902399e+03  3.902591e+03  \n",
       "TOS_STDEVALL_U_3          7.666338e+03  7.666529e+03  7.666720e+03  \n",
       "TRENDFLEX_20_20_0.04      6.132570e-01  5.497612e-01  4.884444e-01  \n",
       "TRIX_30_9                 5.579746e-02  5.539173e-02  5.492671e-02  \n",
       "TRIXs_30_9                5.671817e-02  5.650403e-02  5.625003e-02  \n",
       "TSI_13_25_13              4.381906e+01  4.282568e+01  4.199008e+01  \n",
       "TSIs_13_25_13             4.409300e+01  4.391195e+01  4.363740e+01  \n",
       "UI_14                     4.661579e-02  5.030457e-02  5.374075e-02  \n",
       "UO_7_14_28                6.273215e+01  5.204607e+01  5.484732e+01  \n",
       "VHF_28                    4.316832e-01  4.570231e-01  4.965831e-01  \n",
       "VTXP_14                   1.253472e+00  1.235714e+00  1.262664e+00  \n",
       "VWAP_D                    6.004272e+03  6.004024e+03  6.003938e+03  \n",
       "TSV_18_10                 4.642172e+06  4.517216e+06  4.520971e+06  \n",
       "TSVs_18_10                4.419981e+06  4.491805e+06  4.543438e+06  \n",
       "WILLR_14                 -2.500000e+01 -2.173913e+01 -2.380952e+01  \n",
       "ZIGZAGv_5.0%_10           6.005055e+03  6.003908e+03  6.003607e+03  \n",
       "ZS_30                     1.206776e+00  1.207136e+00  1.130451e+00  \n",
       "\n",
       "[78 rows x 8582 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30fa6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Close</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>AO_5_34</th>\n",
       "      <th>OBV</th>\n",
       "      <th>OBV_min_2</th>\n",
       "      <th>OBV_max_2</th>\n",
       "      <th>OBVe_4</th>\n",
       "      <th>OBVe_12</th>\n",
       "      <th>BIAS_SMA_26</th>\n",
       "      <th>open_Z_30_1</th>\n",
       "      <th>high_Z_30_1</th>\n",
       "      <th>low_Z_30_1</th>\n",
       "      <th>close_Z_30_1</th>\n",
       "      <th>...</th>\n",
       "      <th>TRENDFLEX_20_20_0.04</th>\n",
       "      <th>TRIX_30_9</th>\n",
       "      <th>TRIXs_30_9</th>\n",
       "      <th>TSI_13_25_13</th>\n",
       "      <th>TSIs_13_25_13</th>\n",
       "      <th>UI_14</th>\n",
       "      <th>UO_7_14_28</th>\n",
       "      <th>VHF_28</th>\n",
       "      <th>VTXP_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8.582000e+03</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "      <td>8582.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4971.369028</td>\n",
       "      <td>4993.623556</td>\n",
       "      <td>1.340812e+07</td>\n",
       "      <td>29.591185</td>\n",
       "      <td>3.101354</td>\n",
       "      <td>3.361060e+06</td>\n",
       "      <td>3.328784e+06</td>\n",
       "      <td>3.391687e+06</td>\n",
       "      <td>3.358572e+06</td>\n",
       "      <td>3.351895e+06</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.196671</td>\n",
       "      <td>0.218988</td>\n",
       "      <td>0.211504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127228</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>6.313017</td>\n",
       "      <td>6.284504</td>\n",
       "      <td>0.339710</td>\n",
       "      <td>53.603667</td>\n",
       "      <td>0.371867</td>\n",
       "      <td>1.028835</td>\n",
       "      <td>4970.328373</td>\n",
       "      <td>6.130658e+04</td>\n",
       "      <td>5.803934e+04</td>\n",
       "      <td>-43.064228</td>\n",
       "      <td>4971.250232</td>\n",
       "      <td>0.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>524.752898</td>\n",
       "      <td>526.434251</td>\n",
       "      <td>8.828154e+06</td>\n",
       "      <td>15.555372</td>\n",
       "      <td>23.122030</td>\n",
       "      <td>5.020762e+06</td>\n",
       "      <td>5.022009e+06</td>\n",
       "      <td>5.018556e+06</td>\n",
       "      <td>5.018413e+06</td>\n",
       "      <td>5.012848e+06</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>1.376886</td>\n",
       "      <td>1.385511</td>\n",
       "      <td>1.373628</td>\n",
       "      <td>1.376235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976137</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>24.370997</td>\n",
       "      <td>22.346811</td>\n",
       "      <td>0.318469</td>\n",
       "      <td>10.624797</td>\n",
       "      <td>0.123980</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>524.599557</td>\n",
       "      <td>1.087535e+07</td>\n",
       "      <td>9.797486e+06</td>\n",
       "      <td>29.923764</td>\n",
       "      <td>524.736750</td>\n",
       "      <td>1.376235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4114.250000</td>\n",
       "      <td>4147.612565</td>\n",
       "      <td>-3.823524e+05</td>\n",
       "      <td>4.986032</td>\n",
       "      <td>-129.576471</td>\n",
       "      <td>-5.927894e+06</td>\n",
       "      <td>-5.927894e+06</td>\n",
       "      <td>-5.737986e+06</td>\n",
       "      <td>-5.790038e+06</td>\n",
       "      <td>-5.726100e+06</td>\n",
       "      <td>-0.029679</td>\n",
       "      <td>-4.403214</td>\n",
       "      <td>-4.476283</td>\n",
       "      <td>-4.560944</td>\n",
       "      <td>-4.385604</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.884485</td>\n",
       "      <td>-0.090684</td>\n",
       "      <td>-0.089347</td>\n",
       "      <td>-65.352614</td>\n",
       "      <td>-60.485628</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>19.927252</td>\n",
       "      <td>0.124649</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>4128.490581</td>\n",
       "      <td>-5.115391e+07</td>\n",
       "      <td>-4.768276e+07</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>4117.611277</td>\n",
       "      <td>-4.385604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4481.500000</td>\n",
       "      <td>4499.271814</td>\n",
       "      <td>5.156797e+06</td>\n",
       "      <td>18.973068</td>\n",
       "      <td>-8.734559</td>\n",
       "      <td>-1.153896e+06</td>\n",
       "      <td>-1.199333e+06</td>\n",
       "      <td>-1.114016e+06</td>\n",
       "      <td>-1.159055e+06</td>\n",
       "      <td>-1.176162e+06</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>-0.886838</td>\n",
       "      <td>-0.916913</td>\n",
       "      <td>-0.862197</td>\n",
       "      <td>-0.885305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513427</td>\n",
       "      <td>-0.006087</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-10.743464</td>\n",
       "      <td>-9.679059</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>46.801784</td>\n",
       "      <td>0.275762</td>\n",
       "      <td>0.898931</td>\n",
       "      <td>4480.592071</td>\n",
       "      <td>-3.025269e+06</td>\n",
       "      <td>-2.970080e+06</td>\n",
       "      <td>-69.219589</td>\n",
       "      <td>4481.626754</td>\n",
       "      <td>-0.885305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4994.875000</td>\n",
       "      <td>5020.571812</td>\n",
       "      <td>1.358438e+07</td>\n",
       "      <td>26.268617</td>\n",
       "      <td>3.542647</td>\n",
       "      <td>2.494496e+06</td>\n",
       "      <td>2.474825e+06</td>\n",
       "      <td>2.539476e+06</td>\n",
       "      <td>2.501736e+06</td>\n",
       "      <td>2.506730e+06</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.384981</td>\n",
       "      <td>0.404707</td>\n",
       "      <td>0.374760</td>\n",
       "      <td>0.386546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172247</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>6.263132</td>\n",
       "      <td>6.302026</td>\n",
       "      <td>0.240286</td>\n",
       "      <td>53.810459</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>1.024521</td>\n",
       "      <td>4993.077538</td>\n",
       "      <td>1.543264e+05</td>\n",
       "      <td>1.414864e+05</td>\n",
       "      <td>-39.415426</td>\n",
       "      <td>4995.074052</td>\n",
       "      <td>0.386546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5433.812500</td>\n",
       "      <td>5454.574095</td>\n",
       "      <td>2.244842e+07</td>\n",
       "      <td>36.044503</td>\n",
       "      <td>16.429044</td>\n",
       "      <td>7.636449e+06</td>\n",
       "      <td>7.615726e+06</td>\n",
       "      <td>7.650844e+06</td>\n",
       "      <td>7.621711e+06</td>\n",
       "      <td>7.607829e+06</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>1.258464</td>\n",
       "      <td>1.239783</td>\n",
       "      <td>1.291862</td>\n",
       "      <td>1.255873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>23.121858</td>\n",
       "      <td>21.352101</td>\n",
       "      <td>0.447556</td>\n",
       "      <td>60.966863</td>\n",
       "      <td>0.451664</td>\n",
       "      <td>1.157719</td>\n",
       "      <td>5433.314248</td>\n",
       "      <td>3.195216e+06</td>\n",
       "      <td>2.904035e+06</td>\n",
       "      <td>-15.544957</td>\n",
       "      <td>5434.269850</td>\n",
       "      <td>1.255873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6007.250000</td>\n",
       "      <td>6012.929817</td>\n",
       "      <td>2.775727e+07</td>\n",
       "      <td>136.613030</td>\n",
       "      <td>119.566912</td>\n",
       "      <td>1.338759e+07</td>\n",
       "      <td>1.338501e+07</td>\n",
       "      <td>1.338759e+07</td>\n",
       "      <td>1.338139e+07</td>\n",
       "      <td>1.335468e+07</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>4.894773</td>\n",
       "      <td>4.902612</td>\n",
       "      <td>4.769860</td>\n",
       "      <td>4.896828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.802761</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>0.057739</td>\n",
       "      <td>67.635660</td>\n",
       "      <td>61.029423</td>\n",
       "      <td>2.378919</td>\n",
       "      <td>83.836611</td>\n",
       "      <td>0.802158</td>\n",
       "      <td>2.272425</td>\n",
       "      <td>6005.333333</td>\n",
       "      <td>1.200730e+08</td>\n",
       "      <td>1.165228e+08</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>6008.050989</td>\n",
       "      <td>4.896828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature        Close     ACCBU_20            AD       DMP_14      AO_5_34  \\\n",
       "count    8582.000000  8582.000000  8.582000e+03  8582.000000  8582.000000   \n",
       "mean     4971.369028  4993.623556  1.340812e+07    29.591185     3.101354   \n",
       "std       524.752898   526.434251  8.828154e+06    15.555372    23.122030   \n",
       "min      4114.250000  4147.612565 -3.823524e+05     4.986032  -129.576471   \n",
       "25%      4481.500000  4499.271814  5.156797e+06    18.973068    -8.734559   \n",
       "50%      4994.875000  5020.571812  1.358438e+07    26.268617     3.542647   \n",
       "75%      5433.812500  5454.574095  2.244842e+07    36.044503    16.429044   \n",
       "max      6007.250000  6012.929817  2.775727e+07   136.613030   119.566912   \n",
       "\n",
       "Feature           OBV     OBV_min_2     OBV_max_2        OBVe_4       OBVe_12  \\\n",
       "count    8.582000e+03  8.582000e+03  8.582000e+03  8.582000e+03  8.582000e+03   \n",
       "mean     3.361060e+06  3.328784e+06  3.391687e+06  3.358572e+06  3.351895e+06   \n",
       "std      5.020762e+06  5.022009e+06  5.018556e+06  5.018413e+06  5.012848e+06   \n",
       "min     -5.927894e+06 -5.927894e+06 -5.737986e+06 -5.790038e+06 -5.726100e+06   \n",
       "25%     -1.153896e+06 -1.199333e+06 -1.114016e+06 -1.159055e+06 -1.176162e+06   \n",
       "50%      2.494496e+06  2.474825e+06  2.539476e+06  2.501736e+06  2.506730e+06   \n",
       "75%      7.636449e+06  7.615726e+06  7.650844e+06  7.621711e+06  7.607829e+06   \n",
       "max      1.338759e+07  1.338501e+07  1.338759e+07  1.338139e+07  1.335468e+07   \n",
       "\n",
       "Feature  BIAS_SMA_26  open_Z_30_1  high_Z_30_1   low_Z_30_1  close_Z_30_1  \\\n",
       "count    8582.000000  8582.000000  8582.000000  8582.000000   8582.000000   \n",
       "mean        0.000541     0.211382     0.196671     0.218988      0.211504   \n",
       "std         0.004559     1.376886     1.385511     1.373628      1.376235   \n",
       "min        -0.029679    -4.403214    -4.476283    -4.560944     -4.385604   \n",
       "25%        -0.001841    -0.886838    -0.916913    -0.862197     -0.885305   \n",
       "50%         0.000684     0.384981     0.404707     0.374760      0.386546   \n",
       "75%         0.003074     1.258464     1.239783     1.291862      1.255873   \n",
       "max         0.022117     4.894773     4.902612     4.769860      4.896828   \n",
       "\n",
       "Feature  ...  TRENDFLEX_20_20_0.04    TRIX_30_9   TRIXs_30_9  TSI_13_25_13  \\\n",
       "count    ...           8582.000000  8582.000000  8582.000000   8582.000000   \n",
       "mean     ...              0.127228     0.004101     0.004078      6.313017   \n",
       "std      ...              0.976137     0.018358     0.018241     24.370997   \n",
       "min      ...             -2.884485    -0.090684    -0.089347    -65.352614   \n",
       "25%      ...             -0.513427    -0.006087    -0.006059    -10.743464   \n",
       "50%      ...              0.172247     0.004985     0.004955      6.263132   \n",
       "75%      ...              0.782500     0.015657     0.015603     23.121858   \n",
       "max      ...              2.802761     0.058011     0.057739     67.635660   \n",
       "\n",
       "Feature  TSIs_13_25_13        UI_14   UO_7_14_28       VHF_28      VTXP_14  \\\n",
       "count      8582.000000  8582.000000  8582.000000  8582.000000  8582.000000   \n",
       "mean          6.284504     0.339710    53.603667     0.371867     1.028835   \n",
       "std          22.346811     0.318469    10.624797     0.123980     0.193355   \n",
       "min         -60.485628     0.002963    19.927252     0.124649     0.460265   \n",
       "25%          -9.679059     0.122099    46.801784     0.275762     0.898931   \n",
       "50%           6.302026     0.240286    53.810459     0.349398     1.024521   \n",
       "75%          21.352101     0.447556    60.966863     0.451664     1.157719   \n",
       "max          61.029423     2.378919    83.836611     0.802158     2.272425   \n",
       "\n",
       "Feature       VWAP_D     TSV_18_10    TSVs_18_10     WILLR_14  \\\n",
       "count    8582.000000  8.582000e+03  8.582000e+03  8582.000000   \n",
       "mean     4970.328373  6.130658e+04  5.803934e+04   -43.064228   \n",
       "std       524.599557  1.087535e+07  9.797486e+06    29.923764   \n",
       "min      4128.490581 -5.115391e+07 -4.768276e+07  -100.000000   \n",
       "25%      4480.592071 -3.025269e+06 -2.970080e+06   -69.219589   \n",
       "50%      4993.077538  1.543264e+05  1.414864e+05   -39.415426   \n",
       "75%      5433.314248  3.195216e+06  2.904035e+06   -15.544957   \n",
       "max      6005.333333  1.200730e+08  1.165228e+08    -0.000000   \n",
       "\n",
       "Feature  ZIGZAGv_5.0%_10        ZS_30  \n",
       "count        8582.000000  8582.000000  \n",
       "mean         4971.250232     0.211504  \n",
       "std           524.736750     1.376235  \n",
       "min          4117.611277    -4.385604  \n",
       "25%          4481.626754    -0.885305  \n",
       "50%          4995.074052     0.386546  \n",
       "75%          5434.269850     1.255873  \n",
       "max          6008.050989     4.896828  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f5ee9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define seed\n",
    "def set_seeds(seed=42): \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bab60a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19950b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53b7e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('resultsESF', 'lstm_time_series')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec5f9a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 330)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cee4c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>VTXP_14</th>\n",
       "      <th>VTXM_14</th>\n",
       "      <th>VWAP_D</th>\n",
       "      <th>VWMA_10</th>\n",
       "      <th>TSV_18_10</th>\n",
       "      <th>TSVs_18_10</th>\n",
       "      <th>TSVr_18_10</th>\n",
       "      <th>WCP</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>ZIGZAGs_5.0%_10</th>\n",
       "      <th>ZIGZAGv_5.0%_10</th>\n",
       "      <th>ZIGZAGd_5.0%_10</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-11 19:00:00+00:00</th>\n",
       "      <td>4144.00</td>\n",
       "      <td>4145.50</td>\n",
       "      <td>4136.50</td>\n",
       "      <td>4144.50</td>\n",
       "      <td>177477.0</td>\n",
       "      <td>4139.066667</td>\n",
       "      <td>4150.536503</td>\n",
       "      <td>4127.596830</td>\n",
       "      <td>11.469837</td>\n",
       "      <td>4127.519138</td>\n",
       "      <td>4151.7375</td>\n",
       "      <td>4176.644138</td>\n",
       "      <td>1.391047e+05</td>\n",
       "      <td>133049.775078</td>\n",
       "      <td>23.121759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>1.105339</td>\n",
       "      <td>4139.411662</td>\n",
       "      <td>4137.969551</td>\n",
       "      <td>-2076637.00</td>\n",
       "      <td>-5.570004e+05</td>\n",
       "      <td>3.728251</td>\n",
       "      <td>4142.5000</td>\n",
       "      <td>-52.127660</td>\n",
       "      <td>4140.572727</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>4141.476818</td>\n",
       "      <td>-0.424334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 20:00:00+00:00</th>\n",
       "      <td>4145.25</td>\n",
       "      <td>4145.75</td>\n",
       "      <td>4141.25</td>\n",
       "      <td>4144.00</td>\n",
       "      <td>62096.0</td>\n",
       "      <td>4140.300000</td>\n",
       "      <td>4151.305181</td>\n",
       "      <td>4129.294819</td>\n",
       "      <td>11.005181</td>\n",
       "      <td>4126.893913</td>\n",
       "      <td>4150.9125</td>\n",
       "      <td>4175.581413</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>153792.518856</td>\n",
       "      <td>22.782025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909884</td>\n",
       "      <td>1.097384</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>4138.089410</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1.086842e+06</td>\n",
       "      <td>1.842487</td>\n",
       "      <td>4144.3750</td>\n",
       "      <td>-49.468085</td>\n",
       "      <td>4141.177273</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>4142.753760</td>\n",
       "      <td>-0.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 22:00:00+00:00</th>\n",
       "      <td>4148.75</td>\n",
       "      <td>4149.50</td>\n",
       "      <td>4143.75</td>\n",
       "      <td>4144.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4141.716667</td>\n",
       "      <td>4152.371502</td>\n",
       "      <td>4131.061831</td>\n",
       "      <td>10.654835</td>\n",
       "      <td>4126.106448</td>\n",
       "      <td>4150.3750</td>\n",
       "      <td>4174.856448</td>\n",
       "      <td>1.874016e+05</td>\n",
       "      <td>148297.048687</td>\n",
       "      <td>21.977115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920420</td>\n",
       "      <td>1.112613</td>\n",
       "      <td>4139.616049</td>\n",
       "      <td>4137.872708</td>\n",
       "      <td>-2002493.25</td>\n",
       "      <td>-1.690910e+06</td>\n",
       "      <td>1.184269</td>\n",
       "      <td>4147.6875</td>\n",
       "      <td>-42.021277</td>\n",
       "      <td>4142.659091</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>4146.298531</td>\n",
       "      <td>-0.064860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 23:00:00+00:00</th>\n",
       "      <td>4146.00</td>\n",
       "      <td>4148.75</td>\n",
       "      <td>4146.00</td>\n",
       "      <td>4148.50</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>4144.250000</td>\n",
       "      <td>4154.377846</td>\n",
       "      <td>4134.122154</td>\n",
       "      <td>10.127846</td>\n",
       "      <td>4125.481448</td>\n",
       "      <td>4149.6625</td>\n",
       "      <td>4174.231448</td>\n",
       "      <td>1.844896e+05</td>\n",
       "      <td>131640.806465</td>\n",
       "      <td>21.229698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901840</td>\n",
       "      <td>1.119632</td>\n",
       "      <td>4139.630997</td>\n",
       "      <td>4137.302401</td>\n",
       "      <td>-2015179.75</td>\n",
       "      <td>-2.404742e+06</td>\n",
       "      <td>0.838002</td>\n",
       "      <td>4146.6875</td>\n",
       "      <td>-47.872340</td>\n",
       "      <td>4143.604545</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>4146.471526</td>\n",
       "      <td>-0.321340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12 00:00:00+00:00</th>\n",
       "      <td>4151.50</td>\n",
       "      <td>4152.00</td>\n",
       "      <td>4145.25</td>\n",
       "      <td>4145.75</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>4145.983333</td>\n",
       "      <td>4155.885990</td>\n",
       "      <td>4136.080677</td>\n",
       "      <td>9.902657</td>\n",
       "      <td>4124.269449</td>\n",
       "      <td>4149.2250</td>\n",
       "      <td>4174.206949</td>\n",
       "      <td>1.915830e+05</td>\n",
       "      <td>115116.524631</td>\n",
       "      <td>20.097679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901538</td>\n",
       "      <td>1.101538</td>\n",
       "      <td>4149.583333</td>\n",
       "      <td>4140.376301</td>\n",
       "      <td>-1973241.50</td>\n",
       "      <td>-2.286844e+06</td>\n",
       "      <td>0.862867</td>\n",
       "      <td>4150.0625</td>\n",
       "      <td>-32.960894</td>\n",
       "      <td>4145.577273</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>4148.749430</td>\n",
       "      <td>0.101855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 17:00:00+00:00</th>\n",
       "      <td>5630.75</td>\n",
       "      <td>5633.00</td>\n",
       "      <td>5618.75</td>\n",
       "      <td>5632.00</td>\n",
       "      <td>174057.0</td>\n",
       "      <td>5661.333333</td>\n",
       "      <td>5680.177744</td>\n",
       "      <td>5642.488923</td>\n",
       "      <td>18.844410</td>\n",
       "      <td>5676.998297</td>\n",
       "      <td>5713.6375</td>\n",
       "      <td>5757.060797</td>\n",
       "      <td>3.030610e+07</td>\n",
       "      <td>-289516.717266</td>\n",
       "      <td>41.091296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553522</td>\n",
       "      <td>1.405306</td>\n",
       "      <td>5672.262205</td>\n",
       "      <td>5661.292394</td>\n",
       "      <td>-24642615.50</td>\n",
       "      <td>-1.064921e+07</td>\n",
       "      <td>2.314032</td>\n",
       "      <td>5628.3125</td>\n",
       "      <td>-90.697674</td>\n",
       "      <td>5670.350000</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>5630.046629</td>\n",
       "      <td>-2.633574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 18:00:00+00:00</th>\n",
       "      <td>5628.75</td>\n",
       "      <td>5636.50</td>\n",
       "      <td>5619.75</td>\n",
       "      <td>5630.75</td>\n",
       "      <td>143085.0</td>\n",
       "      <td>5643.833333</td>\n",
       "      <td>5662.538116</td>\n",
       "      <td>5625.128550</td>\n",
       "      <td>18.704783</td>\n",
       "      <td>5669.975476</td>\n",
       "      <td>5708.0875</td>\n",
       "      <td>5752.725476</td>\n",
       "      <td>3.031678e+07</td>\n",
       "      <td>-242010.490013</td>\n",
       "      <td>42.999767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578440</td>\n",
       "      <td>1.375986</td>\n",
       "      <td>5667.881518</td>\n",
       "      <td>5656.732734</td>\n",
       "      <td>-24970470.50</td>\n",
       "      <td>-1.296109e+07</td>\n",
       "      <td>1.926573</td>\n",
       "      <td>5628.4375</td>\n",
       "      <td>-92.248062</td>\n",
       "      <td>5659.177273</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>5624.947242</td>\n",
       "      <td>-2.345638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 19:00:00+00:00</th>\n",
       "      <td>5624.50</td>\n",
       "      <td>5634.25</td>\n",
       "      <td>5617.25</td>\n",
       "      <td>5628.75</td>\n",
       "      <td>295029.0</td>\n",
       "      <td>5634.483333</td>\n",
       "      <td>5653.074464</td>\n",
       "      <td>5615.892202</td>\n",
       "      <td>18.591131</td>\n",
       "      <td>5663.452339</td>\n",
       "      <td>5702.5125</td>\n",
       "      <td>5748.202339</td>\n",
       "      <td>3.027339e+07</td>\n",
       "      <td>-214380.003569</td>\n",
       "      <td>44.818261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586847</td>\n",
       "      <td>1.375211</td>\n",
       "      <td>5660.624908</td>\n",
       "      <td>5650.222595</td>\n",
       "      <td>-26203976.75</td>\n",
       "      <td>-1.488171e+07</td>\n",
       "      <td>1.760817</td>\n",
       "      <td>5625.1250</td>\n",
       "      <td>-94.444444</td>\n",
       "      <td>5648.995455</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>5620.911379</td>\n",
       "      <td>-2.169653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 20:00:00+00:00</th>\n",
       "      <td>5602.50</td>\n",
       "      <td>5625.25</td>\n",
       "      <td>5602.25</td>\n",
       "      <td>5624.50</td>\n",
       "      <td>85426.0</td>\n",
       "      <td>5626.100000</td>\n",
       "      <td>5644.985055</td>\n",
       "      <td>5607.214945</td>\n",
       "      <td>18.885055</td>\n",
       "      <td>5656.280342</td>\n",
       "      <td>5695.5875</td>\n",
       "      <td>5743.280342</td>\n",
       "      <td>3.018982e+07</td>\n",
       "      <td>-210177.640213</td>\n",
       "      <td>46.766461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>1.406639</td>\n",
       "      <td>5658.242543</td>\n",
       "      <td>5647.042187</td>\n",
       "      <td>-28105848.75</td>\n",
       "      <td>-1.746749e+07</td>\n",
       "      <td>1.609038</td>\n",
       "      <td>5608.1250</td>\n",
       "      <td>-99.818182</td>\n",
       "      <td>5636.631818</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>5612.200220</td>\n",
       "      <td>-2.342159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30 22:00:00+00:00</th>\n",
       "      <td>5594.25</td>\n",
       "      <td>5600.00</td>\n",
       "      <td>5580.25</td>\n",
       "      <td>5590.00</td>\n",
       "      <td>22300.0</td>\n",
       "      <td>5616.533333</td>\n",
       "      <td>5635.642718</td>\n",
       "      <td>5597.423948</td>\n",
       "      <td>19.109385</td>\n",
       "      <td>5647.083490</td>\n",
       "      <td>5688.4000</td>\n",
       "      <td>5737.458490</td>\n",
       "      <td>3.019914e+07</td>\n",
       "      <td>-186387.509316</td>\n",
       "      <td>48.882431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572020</td>\n",
       "      <td>1.432119</td>\n",
       "      <td>5591.500000</td>\n",
       "      <td>5645.744790</td>\n",
       "      <td>-28299001.50</td>\n",
       "      <td>-2.028136e+07</td>\n",
       "      <td>1.395321</td>\n",
       "      <td>5592.1875</td>\n",
       "      <td>-91.222571</td>\n",
       "      <td>5625.177273</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>5602.300180</td>\n",
       "      <td>-2.249456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10728 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Close     High      Low     Open    Volume  \\\n",
       "Datetime                                                                  \n",
       "2023-05-11 19:00:00+00:00  4144.00  4145.50  4136.50  4144.50  177477.0   \n",
       "2023-05-11 20:00:00+00:00  4145.25  4145.75  4141.25  4144.00   62096.0   \n",
       "2023-05-11 22:00:00+00:00  4148.75  4149.50  4143.75  4144.50       0.0   \n",
       "2023-05-11 23:00:00+00:00  4146.00  4148.75  4146.00  4148.50    2912.0   \n",
       "2023-05-12 00:00:00+00:00  4151.50  4152.00  4145.25  4145.75    8327.0   \n",
       "...                            ...      ...      ...      ...       ...   \n",
       "2025-03-28 17:00:00+00:00  5630.75  5633.00  5618.75  5632.00  174057.0   \n",
       "2025-03-28 18:00:00+00:00  5628.75  5636.50  5619.75  5630.75  143085.0   \n",
       "2025-03-28 19:00:00+00:00  5624.50  5634.25  5617.25  5628.75  295029.0   \n",
       "2025-03-28 20:00:00+00:00  5602.50  5625.25  5602.25  5624.50   85426.0   \n",
       "2025-03-30 22:00:00+00:00  5594.25  5600.00  5580.25  5590.00   22300.0   \n",
       "\n",
       "                           ABER_ZG_5_15  ABER_SG_5_15  ABER_XG_5_15  \\\n",
       "Datetime                                                              \n",
       "2023-05-11 19:00:00+00:00   4139.066667   4150.536503   4127.596830   \n",
       "2023-05-11 20:00:00+00:00   4140.300000   4151.305181   4129.294819   \n",
       "2023-05-11 22:00:00+00:00   4141.716667   4152.371502   4131.061831   \n",
       "2023-05-11 23:00:00+00:00   4144.250000   4154.377846   4134.122154   \n",
       "2023-05-12 00:00:00+00:00   4145.983333   4155.885990   4136.080677   \n",
       "...                                 ...           ...           ...   \n",
       "2025-03-28 17:00:00+00:00   5661.333333   5680.177744   5642.488923   \n",
       "2025-03-28 18:00:00+00:00   5643.833333   5662.538116   5625.128550   \n",
       "2025-03-28 19:00:00+00:00   5634.483333   5653.074464   5615.892202   \n",
       "2025-03-28 20:00:00+00:00   5626.100000   5644.985055   5607.214945   \n",
       "2025-03-30 22:00:00+00:00   5616.533333   5635.642718   5597.423948   \n",
       "\n",
       "                           ABER_ATR_5_15     ACCBL_20   ACCBM_20     ACCBU_20  \\\n",
       "Datetime                                                                        \n",
       "2023-05-11 19:00:00+00:00      11.469837  4127.519138  4151.7375  4176.644138   \n",
       "2023-05-11 20:00:00+00:00      11.005181  4126.893913  4150.9125  4175.581413   \n",
       "2023-05-11 22:00:00+00:00      10.654835  4126.106448  4150.3750  4174.856448   \n",
       "2023-05-11 23:00:00+00:00      10.127846  4125.481448  4149.6625  4174.231448   \n",
       "2023-05-12 00:00:00+00:00       9.902657  4124.269449  4149.2250  4174.206949   \n",
       "...                                  ...          ...        ...          ...   \n",
       "2025-03-28 17:00:00+00:00      18.844410  5676.998297  5713.6375  5757.060797   \n",
       "2025-03-28 18:00:00+00:00      18.704783  5669.975476  5708.0875  5752.725476   \n",
       "2025-03-28 19:00:00+00:00      18.591131  5663.452339  5702.5125  5748.202339   \n",
       "2025-03-28 20:00:00+00:00      18.885055  5656.280342  5695.5875  5743.280342   \n",
       "2025-03-30 22:00:00+00:00      19.109385  5647.083490  5688.4000  5737.458490   \n",
       "\n",
       "                                     AD     ADOSC_3_10     ADX_14  ...  \\\n",
       "Datetime                                                           ...   \n",
       "2023-05-11 19:00:00+00:00  1.391047e+05  133049.775078  23.121759  ...   \n",
       "2023-05-11 20:00:00+00:00  1.874016e+05  153792.518856  22.782025  ...   \n",
       "2023-05-11 22:00:00+00:00  1.874016e+05  148297.048687  21.977115  ...   \n",
       "2023-05-11 23:00:00+00:00  1.844896e+05  131640.806465  21.229698  ...   \n",
       "2023-05-12 00:00:00+00:00  1.915830e+05  115116.524631  20.097679  ...   \n",
       "...                                 ...            ...        ...  ...   \n",
       "2025-03-28 17:00:00+00:00  3.030610e+07 -289516.717266  41.091296  ...   \n",
       "2025-03-28 18:00:00+00:00  3.031678e+07 -242010.490013  42.999767  ...   \n",
       "2025-03-28 19:00:00+00:00  3.027339e+07 -214380.003569  44.818261  ...   \n",
       "2025-03-28 20:00:00+00:00  3.018982e+07 -210177.640213  46.766461  ...   \n",
       "2025-03-30 22:00:00+00:00  3.019914e+07 -186387.509316  48.882431  ...   \n",
       "\n",
       "                            VTXP_14   VTXM_14       VWAP_D      VWMA_10  \\\n",
       "Datetime                                                                  \n",
       "2023-05-11 19:00:00+00:00  0.867244  1.105339  4139.411662  4137.969551   \n",
       "2023-05-11 20:00:00+00:00  0.909884  1.097384  4139.616049  4138.089410   \n",
       "2023-05-11 22:00:00+00:00  0.920420  1.112613  4139.616049  4137.872708   \n",
       "2023-05-11 23:00:00+00:00  0.901840  1.119632  4139.630997  4137.302401   \n",
       "2023-05-12 00:00:00+00:00  0.901538  1.101538  4149.583333  4140.376301   \n",
       "...                             ...       ...          ...          ...   \n",
       "2025-03-28 17:00:00+00:00  0.553522  1.405306  5672.262205  5661.292394   \n",
       "2025-03-28 18:00:00+00:00  0.578440  1.375986  5667.881518  5656.732734   \n",
       "2025-03-28 19:00:00+00:00  0.586847  1.375211  5660.624908  5650.222595   \n",
       "2025-03-28 20:00:00+00:00  0.577593  1.406639  5658.242543  5647.042187   \n",
       "2025-03-30 22:00:00+00:00  0.572020  1.432119  5591.500000  5645.744790   \n",
       "\n",
       "                             TSV_18_10    TSVs_18_10  TSVr_18_10        WCP  \\\n",
       "Datetime                                                                      \n",
       "2023-05-11 19:00:00+00:00  -2076637.00 -5.570004e+05    3.728251  4142.5000   \n",
       "2023-05-11 20:00:00+00:00  -2002493.25 -1.086842e+06    1.842487  4144.3750   \n",
       "2023-05-11 22:00:00+00:00  -2002493.25 -1.690910e+06    1.184269  4147.6875   \n",
       "2023-05-11 23:00:00+00:00  -2015179.75 -2.404742e+06    0.838002  4146.6875   \n",
       "2023-05-12 00:00:00+00:00  -1973241.50 -2.286844e+06    0.862867  4150.0625   \n",
       "...                                ...           ...         ...        ...   \n",
       "2025-03-28 17:00:00+00:00 -24642615.50 -1.064921e+07    2.314032  5628.3125   \n",
       "2025-03-28 18:00:00+00:00 -24970470.50 -1.296109e+07    1.926573  5628.4375   \n",
       "2025-03-28 19:00:00+00:00 -26203976.75 -1.488171e+07    1.760817  5625.1250   \n",
       "2025-03-28 20:00:00+00:00 -28105848.75 -1.746749e+07    1.609038  5608.1250   \n",
       "2025-03-30 22:00:00+00:00 -28299001.50 -2.028136e+07    1.395321  5592.1875   \n",
       "\n",
       "                            WILLR_14       WMA_10  ZIGZAGs_5.0%_10  \\\n",
       "Datetime                                                             \n",
       "2023-05-11 19:00:00+00:00 -52.127660  4140.572727      4141.476818   \n",
       "2023-05-11 20:00:00+00:00 -49.468085  4141.177273      4142.753760   \n",
       "2023-05-11 22:00:00+00:00 -42.021277  4142.659091      4146.298531   \n",
       "2023-05-11 23:00:00+00:00 -47.872340  4143.604545      4146.471526   \n",
       "2023-05-12 00:00:00+00:00 -32.960894  4145.577273      4148.749430   \n",
       "...                              ...          ...              ...   \n",
       "2025-03-28 17:00:00+00:00 -90.697674  5670.350000      5630.046629   \n",
       "2025-03-28 18:00:00+00:00 -92.248062  5659.177273      5624.947242   \n",
       "2025-03-28 19:00:00+00:00 -94.444444  5648.995455      5620.911379   \n",
       "2025-03-28 20:00:00+00:00 -99.818182  5636.631818      5612.200220   \n",
       "2025-03-30 22:00:00+00:00 -91.222571  5625.177273      5602.300180   \n",
       "\n",
       "                           ZIGZAGv_5.0%_10  ZIGZAGd_5.0%_10    ZL_EMA_10  \\\n",
       "Datetime                                                                   \n",
       "2023-05-11 19:00:00+00:00      4141.476818      4141.476818  4141.476818   \n",
       "2023-05-11 20:00:00+00:00      4142.753760      4142.753760  4142.753760   \n",
       "2023-05-11 22:00:00+00:00      4146.298531      4146.298531  4146.298531   \n",
       "2023-05-11 23:00:00+00:00      4146.471526      4146.471526  4146.471526   \n",
       "2023-05-12 00:00:00+00:00      4148.749430      4148.749430  4148.749430   \n",
       "...                                    ...              ...          ...   \n",
       "2025-03-28 17:00:00+00:00      5630.046629      5630.046629  5630.046629   \n",
       "2025-03-28 18:00:00+00:00      5624.947242      5624.947242  5624.947242   \n",
       "2025-03-28 19:00:00+00:00      5620.911379      5620.911379  5620.911379   \n",
       "2025-03-28 20:00:00+00:00      5612.200220      5612.200220  5612.200220   \n",
       "2025-03-30 22:00:00+00:00      5602.300180      5602.300180  5602.300180   \n",
       "\n",
       "                              ZS_30  \n",
       "Datetime                             \n",
       "2023-05-11 19:00:00+00:00 -0.424334  \n",
       "2023-05-11 20:00:00+00:00 -0.310070  \n",
       "2023-05-11 22:00:00+00:00 -0.064860  \n",
       "2023-05-11 23:00:00+00:00 -0.321340  \n",
       "2023-05-12 00:00:00+00:00  0.101855  \n",
       "...                             ...  \n",
       "2025-03-28 17:00:00+00:00 -2.633574  \n",
       "2025-03-28 18:00:00+00:00 -2.345638  \n",
       "2025-03-28 19:00:00+00:00 -2.169653  \n",
       "2025-03-28 20:00:00+00:00 -2.342159  \n",
       "2025-03-30 22:00:00+00:00 -2.249456  \n",
       "\n",
       "[10728 rows x 330 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6013941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40ce6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(X, columns =sel['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a60e4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 78)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53fd8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Size (8582, 78), (8582,), (2146, 78), (2146,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the datasets into training and testing data.\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X1, y, test_size=0.2, shuffle=False)\n",
    "# train, test = train_test_split(X, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {Xtrain.shape}, {ytrain.shape}, {Xtest.shape}, {ytest.shape}\")\n",
    "# print(f\"Train and Test Size {train.shape}, {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0df1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaledtrain = scaler.fit_transform(Xtrain)\n",
    "scaledtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce0e202b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence length\n",
    "seqlen = 21\n",
    "\n",
    "# number of features\n",
    "numfeat = X1.shape[1]\n",
    "numfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbf46d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train and test sequence data\n",
    "g = TimeseriesGenerator(scaledtrain, ytrain, length=seqlen)\n",
    "g_ = TimeseriesGenerator(scaledtest, ytest, length=seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b132f1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 17)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify length\n",
    "len(g), len(g_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8acaad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(128, 21, 78) (128,)\n",
      "(113, 21, 78) (113,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(g)):\n",
    "    a, b = g[i]\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68bb72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "def create_model(hu=256, lookback=60, features=1):\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "\n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Drouput1'))\n",
    "    \n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    model.add(Dropout(0.4, name='Drouput2'))\n",
    "    \n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))             \n",
    "    \n",
    "    # specify optimizer separately (preferred method))\n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08, decay=0.0)       \n",
    "    \n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', \n",
    "                           Precision(),\n",
    "                           Recall(),\n",
    "                           tf.keras.metrics.AUC(),\n",
    "                           tf.keras.metrics.TruePositives(),\n",
    "                           tf.keras.metrics.TrueNegatives(),\n",
    "                           tf.keras.metrics.FalseNegatives(),\n",
    "                           tf.keras.metrics.FalsePositives()\n",
    "                          ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d966de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lstm network\n",
    "model = create_model(hu=10, lookback=seqlen, features=numfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d829cdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ LSTM1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ LSTM1 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)              │           \u001b[38;5;34m7,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM2 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │           \u001b[38;5;34m1,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM3 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m840\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,011</span> (39.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,011\u001b[0m (39.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,011</span> (39.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,011\u001b[0m (39.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4dc5e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify callback functions\n",
    "model_path = (results_path / 'model.h5').as_posix()\n",
    "logdir = os.path.join(\"./tensorboard/ESFlogs\", dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=20, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e129384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5107 - auc: 0.4899 - false_negatives: 1197.7462 - false_positives: 941.3881 - loss: 0.7072 - precision: 0.4231 - recall: 0.3254 - true_negatives: 1447.6865 - true_positives: 764.9552\n",
      "Epoch 1: loss improved from inf to 0.70680, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.5107 - auc: 0.4899 - false_negatives: 1216.5883 - false_positives: 952.2059 - loss: 0.7072 - precision: 0.4234 - recall: 0.3258 - true_negatives: 1471.3235 - true_positives: 773.5588\n",
      "Epoch 2/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5193 - auc: 0.4848 - false_negatives: 1445.6268 - false_positives: 677.5821 - loss: 0.7066 - precision: 0.4192 - recall: 0.2077 - true_negatives: 1711.4926 - true_positives: 517.0746\n",
      "Epoch 2: loss improved from 0.70680 to 0.70615, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5192 - auc: 0.4848 - false_negatives: 1465.3383 - false_positives: 687.8235 - loss: 0.7065 - precision: 0.4194 - recall: 0.2087 - true_negatives: 1735.7059 - true_positives: 524.8088\n",
      "Epoch 3/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5264 - auc: 0.4993 - false_negatives: 1398.7462 - false_positives: 709.1791 - loss: 0.7062 - precision: 0.4596 - recall: 0.2140 - true_negatives: 1679.8955 - true_positives: 563.9552\n",
      "Epoch 3: loss improved from 0.70615 to 0.70604, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5263 - auc: 0.4993 - false_negatives: 1417.4117 - false_positives: 720.3970 - loss: 0.7062 - precision: 0.4593 - recall: 0.2153 - true_negatives: 1703.1323 - true_positives: 572.7353\n",
      "Epoch 4/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5426 - auc: 0.5048 - false_negatives: 1642.1343 - false_positives: 376.2686 - loss: 0.7061 - precision: 0.4840 - recall: 0.1458 - true_negatives: 2012.8060 - true_positives: 320.5672\n",
      "Epoch 4: loss improved from 0.70604 to 0.70594, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5426 - auc: 0.5047 - false_negatives: 1666.3088 - false_positives: 380.3088 - loss: 0.7061 - precision: 0.4836 - recall: 0.1458 - true_negatives: 2043.2206 - true_positives: 323.8382\n",
      "Epoch 5/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5237 - auc: 0.5055 - false_negatives: 1300.5758 - false_positives: 769.6212 - loss: 0.7060 - precision: 0.4602 - recall: 0.3112 - true_negatives: 1583.9546 - true_positives: 633.8485\n",
      "Epoch 5: loss improved from 0.70594 to 0.70587, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5235 - auc: 0.5053 - false_negatives: 1340.9706 - false_positives: 789.9853 - loss: 0.7060 - precision: 0.4596 - recall: 0.3109 - true_negatives: 1633.5441 - true_positives: 649.1765\n",
      "Epoch 6/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5246 - auc: 0.5139 - false_negatives: 1268.6364 - false_positives: 763.7879 - loss: 0.7058 - precision: 0.4628 - recall: 0.3396 - true_negatives: 1589.7878 - true_positives: 665.7879\n",
      "Epoch 6: loss improved from 0.70587 to 0.70566, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5249 - auc: 0.5137 - false_negatives: 1312.8529 - false_positives: 777.2647 - loss: 0.7058 - precision: 0.4629 - recall: 0.3378 - true_negatives: 1646.2646 - true_positives: 677.2941\n",
      "Epoch 7/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5109 - auc: 0.5021 - false_negatives: 1216.7878 - false_positives: 893.5455 - loss: 0.7061 - precision: 0.4406 - recall: 0.3316 - true_negatives: 1460.0303 - true_positives: 717.6364\n",
      "Epoch 7: loss did not improve from 0.70566\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5109 - auc: 0.5021 - false_negatives: 1252.6765 - false_positives: 918.5294 - loss: 0.7061 - precision: 0.4407 - recall: 0.3325 - true_negatives: 1505.0000 - true_positives: 737.4706\n",
      "Epoch 8/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5307 - auc: 0.5121 - false_negatives: 1357.4329 - false_positives: 666.8060 - loss: 0.7059 - precision: 0.4736 - recall: 0.3548 - true_negatives: 1722.2687 - true_positives: 605.2687\n",
      "Epoch 8: loss improved from 0.70566 to 0.70564, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5308 - auc: 0.5121 - false_negatives: 1380.1912 - false_positives: 671.9706 - loss: 0.7059 - precision: 0.4736 - recall: 0.3531 - true_negatives: 1751.5588 - true_positives: 609.9559\n",
      "Epoch 9/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5221 - auc: 0.5103 - false_negatives: 1198.3284 - false_positives: 860.9254 - loss: 0.7060 - precision: 0.4681 - recall: 0.4418 - true_negatives: 1528.1493 - true_positives: 764.3731\n",
      "Epoch 9: loss improved from 0.70564 to 0.70561, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5223 - auc: 0.5103 - false_negatives: 1220.0146 - false_positives: 867.7353 - loss: 0.7060 - precision: 0.4681 - recall: 0.4397 - true_negatives: 1555.7941 - true_positives: 770.1323\n",
      "Epoch 10/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5087 - auc: 0.5129 - false_negatives: 1167.4926 - false_positives: 952.5671 - loss: 0.7059 - precision: 0.4510 - recall: 0.4137 - true_negatives: 1436.5074 - true_positives: 795.2090\n",
      "Epoch 10: loss improved from 0.70561 to 0.70559, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5089 - auc: 0.5129 - false_negatives: 1188.1617 - false_positives: 960.6323 - loss: 0.7059 - precision: 0.4511 - recall: 0.4125 - true_negatives: 1462.8971 - true_positives: 801.9853\n",
      "Epoch 11/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5254 - auc: 0.5227 - false_negatives: 983.3284 - false_positives: 1082.8657 - loss: 0.7057 - precision: 0.4760 - recall: 0.5492 - true_negatives: 1306.2090 - true_positives: 979.3731\n",
      "Epoch 11: loss improved from 0.70559 to 0.70551, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5255 - auc: 0.5226 - false_negatives: 1002.6470 - false_positives: 1092.3971 - loss: 0.7057 - precision: 0.4759 - recall: 0.5470 - true_negatives: 1331.1323 - true_positives: 987.5000\n",
      "Epoch 12/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5133 - auc: 0.5157 - false_negatives: 970.4243 - false_positives: 1114.2576 - loss: 0.7058 - precision: 0.4628 - recall: 0.4999 - true_negatives: 1239.3182 - true_positives: 964.0000\n",
      "Epoch 12: loss improved from 0.70551 to 0.70541, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5136 - auc: 0.5157 - false_negatives: 1007.2941 - false_positives: 1136.2500 - loss: 0.7058 - precision: 0.4628 - recall: 0.4975 - true_negatives: 1287.2794 - true_positives: 982.8530\n",
      "Epoch 13/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5245 - auc: 0.5259 - false_negatives: 960.1061 - false_positives: 1085.5454 - loss: 0.7053 - precision: 0.4738 - recall: 0.5051 - true_negatives: 1268.0303 - true_positives: 974.3182\n",
      "Epoch 13: loss improved from 0.70541 to 0.70523, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5247 - auc: 0.5258 - false_negatives: 997.5441 - false_positives: 1106.1765 - loss: 0.7053 - precision: 0.4738 - recall: 0.5025 - true_negatives: 1317.3529 - true_positives: 992.6030\n",
      "Epoch 14/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5223 - auc: 0.5246 - false_negatives: 1021.2424 - false_positives: 1018.7727 - loss: 0.7052 - precision: 0.4702 - recall: 0.4798 - true_negatives: 1334.8030 - true_positives: 913.1818\n",
      "Epoch 14: loss improved from 0.70523 to 0.70454, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5226 - auc: 0.5247 - false_negatives: 1058.5883 - false_positives: 1039.2206 - loss: 0.7052 - precision: 0.4703 - recall: 0.4775 - true_negatives: 1384.3088 - true_positives: 931.5588\n",
      "Epoch 15/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5102 - auc: 0.5243 - false_negatives: 848.3030 - false_positives: 1236.5909 - loss: 0.7053 - precision: 0.4652 - recall: 0.5767 - true_negatives: 1116.9849 - true_positives: 1086.1212\n",
      "Epoch 15: loss improved from 0.70454 to 0.70444, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5105 - auc: 0.5245 - false_negatives: 881.8530 - false_positives: 1261.9265 - loss: 0.7053 - precision: 0.4652 - recall: 0.5738 - true_negatives: 1161.6029 - true_positives: 1108.2941\n",
      "Epoch 16/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5371 - auc: 0.5373 - false_negatives: 901.0895 - false_positives: 1123.8060 - loss: 0.7040 - precision: 0.4861 - recall: 0.5305 - true_negatives: 1265.2687 - true_positives: 1061.6119\n",
      "Epoch 16: loss improved from 0.70444 to 0.70372, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5371 - auc: 0.5373 - false_negatives: 916.6323 - false_positives: 1136.7354 - loss: 0.7040 - precision: 0.4860 - recall: 0.5299 - true_negatives: 1286.7941 - true_positives: 1073.5146\n",
      "Epoch 17/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5258 - auc: 0.5300 - false_negatives: 905.3433 - false_positives: 1196.7164 - loss: 0.7046 - precision: 0.4754 - recall: 0.4927 - true_negatives: 1192.3582 - true_positives: 1057.3582\n",
      "Epoch 17: loss improved from 0.70372 to 0.70369, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5257 - auc: 0.5300 - false_negatives: 919.6617 - false_positives: 1211.6029 - loss: 0.7046 - precision: 0.4753 - recall: 0.4930 - true_negatives: 1211.9265 - true_positives: 1070.4854\n",
      "Epoch 18/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5341 - auc: 0.5421 - false_negatives: 1013.0746 - false_positives: 1018.7463 - loss: 0.7034 - precision: 0.4779 - recall: 0.4394 - true_negatives: 1370.3284 - true_positives: 949.6269\n",
      "Epoch 18: loss improved from 0.70369 to 0.70167, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5343 - auc: 0.5423 - false_negatives: 1027.5441 - false_positives: 1031.9412 - loss: 0.7034 - precision: 0.4780 - recall: 0.4400 - true_negatives: 1391.5883 - true_positives: 962.6030\n",
      "Epoch 19/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5356 - auc: 0.5372 - false_negatives: 992.0000 - false_positives: 993.0000 - loss: 0.7042 - precision: 0.4822 - recall: 0.4654 - true_negatives: 1360.5758 - true_positives: 942.4243\n",
      "Epoch 19: loss did not improve from 0.70167\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5357 - auc: 0.5376 - false_negatives: 1018.1765 - false_positives: 1024.2646 - loss: 0.7041 - precision: 0.4824 - recall: 0.4667 - true_negatives: 1399.2646 - true_positives: 971.9706\n",
      "Epoch 20/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5339 - auc: 0.5435 - false_negatives: 952.8657 - false_positives: 1073.4329 - loss: 0.7032 - precision: 0.4838 - recall: 0.5020 - true_negatives: 1315.6418 - true_positives: 1009.8358\n",
      "Epoch 20: loss improved from 0.70167 to 0.70047, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5341 - auc: 0.5437 - false_negatives: 966.8677 - false_positives: 1086.8088 - loss: 0.7032 - precision: 0.4839 - recall: 0.5020 - true_negatives: 1336.7206 - true_positives: 1023.2794\n",
      "Epoch 21/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5064 - auc: 0.5377 - false_negatives: 777.1791 - false_positives: 1325.8060 - loss: 0.7046 - precision: 0.4673 - recall: 0.6494 - true_negatives: 1063.2687 - true_positives: 1185.5223\n",
      "Epoch 21: loss improved from 0.70047 to 0.69861, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5069 - auc: 0.5380 - false_negatives: 790.5000 - false_positives: 1339.5146 - loss: 0.7045 - precision: 0.4676 - recall: 0.6481 - true_negatives: 1084.0146 - true_positives: 1199.6471\n",
      "Epoch 22/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5254 - auc: 0.5548 - false_negatives: 765.7121 - false_positives: 1239.3636 - loss: 0.7016 - precision: 0.4809 - recall: 0.6229 - true_negatives: 1114.2122 - true_positives: 1168.7122\n",
      "Epoch 22: loss improved from 0.69861 to 0.69729, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5258 - auc: 0.5552 - false_negatives: 788.5441 - false_positives: 1273.9117 - loss: 0.7015 - precision: 0.4811 - recall: 0.6221 - true_negatives: 1149.6177 - true_positives: 1201.6029\n",
      "Epoch 23/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5178 - auc: 0.5498 - false_negatives: 879.8788 - false_positives: 1123.2273 - loss: 0.7019 - precision: 0.4757 - recall: 0.6024 - true_negatives: 1230.3485 - true_positives: 1054.5454\n",
      "Epoch 23: loss improved from 0.69729 to 0.69534, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5188 - auc: 0.5506 - false_negatives: 904.9412 - false_positives: 1151.9854 - loss: 0.7017 - precision: 0.4764 - recall: 0.6008 - true_negatives: 1271.5441 - true_positives: 1085.2059\n",
      "Epoch 24/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5281 - auc: 0.5400 - false_negatives: 1134.7612 - false_positives: 843.7164 - loss: 0.7047 - precision: 0.4828 - recall: 0.4763 - true_negatives: 1545.3582 - true_positives: 827.9403\n",
      "Epoch 24: loss did not improve from 0.69534\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5287 - auc: 0.5407 - false_negatives: 1149.7794 - false_positives: 854.0441 - loss: 0.7046 - precision: 0.4833 - recall: 0.4757 - true_negatives: 1569.4854 - true_positives: 840.3677\n",
      "Epoch 25/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5320 - auc: 0.5650 - false_negatives: 740.9254 - false_positives: 1228.7910 - loss: 0.7014 - precision: 0.4891 - recall: 0.6718 - true_negatives: 1160.2836 - true_positives: 1221.7761\n",
      "Epoch 25: loss improved from 0.69534 to 0.69248, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5325 - auc: 0.5654 - false_negatives: 753.0000 - false_positives: 1242.4559 - loss: 0.7012 - precision: 0.4895 - recall: 0.6707 - true_negatives: 1181.0735 - true_positives: 1237.1471\n",
      "Epoch 26/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5190 - auc: 0.5626 - false_negatives: 691.3939 - false_positives: 1293.0303 - loss: 0.7036 - precision: 0.4812 - recall: 0.7103 - true_negatives: 1060.5454 - true_positives: 1243.0303\n",
      "Epoch 26: loss did not improve from 0.69248\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5201 - auc: 0.5632 - false_negatives: 716.2353 - false_positives: 1321.4412 - loss: 0.7033 - precision: 0.4819 - recall: 0.7070 - true_negatives: 1102.0883 - true_positives: 1273.9117\n",
      "Epoch 27/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5053 - auc: 0.5333 - false_negatives: 676.0606 - false_positives: 1423.1364 - loss: 0.7055 - precision: 0.4641 - recall: 0.6471 - true_negatives: 930.4394 - true_positives: 1258.3636\n",
      "Epoch 27: loss did not improve from 0.69248\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5062 - auc: 0.5343 - false_negatives: 697.7059 - false_positives: 1456.8677 - loss: 0.7053 - precision: 0.4647 - recall: 0.6467 - true_negatives: 966.6617 - true_positives: 1292.4412\n",
      "Epoch 28/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5658 - auc: 0.5792 - false_negatives: 947.2615 - false_positives: 876.3846 - loss: 0.6962 - precision: 0.5175 - recall: 0.4832 - true_negatives: 1441.8000 - true_positives: 958.5538\n",
      "Epoch 28: loss improved from 0.69248 to 0.68578, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5666 - auc: 0.5807 - false_negatives: 985.5000 - false_positives: 914.1617 - loss: 0.6958 - precision: 0.5183 - recall: 0.4850 - true_negatives: 1509.3677 - true_positives: 1004.6470\n",
      "Epoch 29/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5658 - auc: 0.6019 - false_negatives: 798.6515 - false_positives: 1027.1970 - loss: 0.6894 - precision: 0.5171 - recall: 0.6011 - true_negatives: 1326.3788 - true_positives: 1135.7727\n",
      "Epoch 29: loss improved from 0.68578 to 0.68002, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5665 - auc: 0.6026 - false_negatives: 820.2206 - false_positives: 1055.6912 - loss: 0.6891 - precision: 0.5176 - recall: 0.6011 - true_negatives: 1367.8383 - true_positives: 1169.9265\n",
      "Epoch 30/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5586 - auc: 0.5972 - false_negatives: 810.0606 - false_positives: 1013.1212 - loss: 0.6939 - precision: 0.5133 - recall: 0.6157 - true_negatives: 1340.4546 - true_positives: 1124.3636\n",
      "Epoch 30: loss did not improve from 0.68002\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5596 - auc: 0.5981 - false_negatives: 832.2647 - false_positives: 1040.5000 - loss: 0.6935 - precision: 0.5141 - recall: 0.6149 - true_negatives: 1383.0294 - true_positives: 1157.8823\n",
      "Epoch 31/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5543 - auc: 0.5929 - false_negatives: 757.7846 - false_positives: 1059.2924 - loss: 0.6978 - precision: 0.5090 - recall: 0.6525 - true_negatives: 1258.8923 - true_positives: 1148.0308\n",
      "Epoch 31: loss did not improve from 0.68002\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5560 - auc: 0.5946 - false_negatives: 792.9853 - false_positives: 1096.9117 - loss: 0.6971 - precision: 0.5105 - recall: 0.6498 - true_negatives: 1326.6177 - true_positives: 1197.1617\n",
      "Epoch 32/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5668 - auc: 0.6042 - false_negatives: 744.3881 - false_positives: 1099.1642 - loss: 0.6901 - precision: 0.5168 - recall: 0.6519 - true_negatives: 1289.9104 - true_positives: 1218.3135\n",
      "Epoch 32: loss improved from 0.68002 to 0.67839, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5672 - auc: 0.6047 - false_negatives: 755.7500 - false_positives: 1111.6765 - loss: 0.6899 - precision: 0.5172 - recall: 0.6512 - true_negatives: 1311.8529 - true_positives: 1234.3971\n",
      "Epoch 33/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5731 - auc: 0.6301 - false_negatives: 731.3582 - false_positives: 1055.6567 - loss: 0.6828 - precision: 0.5255 - recall: 0.6746 - true_negatives: 1333.4180 - true_positives: 1231.3433\n",
      "Epoch 33: loss improved from 0.67839 to 0.66583, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5737 - auc: 0.6306 - false_negatives: 742.1617 - false_positives: 1067.2059 - loss: 0.6825 - precision: 0.5260 - recall: 0.6737 - true_negatives: 1356.3235 - true_positives: 1247.9854\n",
      "Epoch 34/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6092 - auc: 0.6542 - false_negatives: 686.5231 - false_positives: 942.8461 - loss: 0.6685 - precision: 0.5571 - recall: 0.6527 - true_negatives: 1375.3385 - true_positives: 1219.2924\n",
      "Epoch 34: loss improved from 0.66583 to 0.65470, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6101 - auc: 0.6552 - false_negatives: 717.4412 - false_positives: 979.6470 - loss: 0.6679 - precision: 0.5580 - recall: 0.6520 - true_negatives: 1443.8823 - true_positives: 1272.7059\n",
      "Epoch 35/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6067 - auc: 0.6596 - false_negatives: 703.6667 - false_positives: 914.2879 - loss: 0.6658 - precision: 0.5590 - recall: 0.6620 - true_negatives: 1439.2878 - true_positives: 1230.7576\n",
      "Epoch 35: loss improved from 0.65470 to 0.64963, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6075 - auc: 0.6604 - false_negatives: 723.8235 - false_positives: 938.8970 - loss: 0.6653 - precision: 0.5597 - recall: 0.6612 - true_negatives: 1484.6323 - true_positives: 1266.3235\n",
      "Epoch 36/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6188 - auc: 0.6727 - false_negatives: 651.2273 - false_positives: 918.2576 - loss: 0.6625 - precision: 0.5683 - recall: 0.6928 - true_negatives: 1435.3182 - true_positives: 1283.1970\n",
      "Epoch 36: loss improved from 0.64963 to 0.63931, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6197 - auc: 0.6737 - false_negatives: 669.6323 - false_positives: 941.7794 - loss: 0.6618 - precision: 0.5692 - recall: 0.6920 - true_negatives: 1481.7500 - true_positives: 1320.5146\n",
      "Epoch 37/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6506 - auc: 0.7129 - false_negatives: 706.8030 - false_positives: 767.0303 - loss: 0.6332 - precision: 0.6074 - recall: 0.6411 - true_negatives: 1586.5454 - true_positives: 1227.6212\n",
      "Epoch 37: loss improved from 0.63931 to 0.61632, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6511 - auc: 0.7135 - false_negatives: 725.8383 - false_positives: 788.3530 - loss: 0.6327 - precision: 0.6079 - recall: 0.6412 - true_negatives: 1635.1765 - true_positives: 1264.3088\n",
      "Epoch 38/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6325 - auc: 0.6981 - false_negatives: 690.1061 - false_positives: 822.8485 - loss: 0.6500 - precision: 0.5871 - recall: 0.6719 - true_negatives: 1530.7273 - true_positives: 1244.3182\n",
      "Epoch 38: loss did not improve from 0.61632\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6333 - auc: 0.6990 - false_negatives: 708.5735 - false_positives: 844.8823 - loss: 0.6491 - precision: 0.5879 - recall: 0.6714 - true_negatives: 1578.6471 - true_positives: 1281.5735\n",
      "Epoch 39/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6558 - auc: 0.7258 - false_negatives: 623.9552 - false_positives: 821.5224 - loss: 0.6248 - precision: 0.6047 - recall: 0.7011 - true_negatives: 1567.5522 - true_positives: 1338.7462\n",
      "Epoch 39: loss improved from 0.61632 to 0.60763, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6561 - auc: 0.7261 - false_negatives: 632.3530 - false_positives: 832.3530 - loss: 0.6245 - precision: 0.6051 - recall: 0.7009 - true_negatives: 1591.1765 - true_positives: 1357.7941\n",
      "Epoch 40/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6637 - auc: 0.7320 - false_negatives: 626.3134 - false_positives: 793.8806 - loss: 0.6211 - precision: 0.6139 - recall: 0.6963 - true_negatives: 1595.1940 - true_positives: 1336.3881\n",
      "Epoch 40: loss improved from 0.60763 to 0.60553, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6640 - auc: 0.7322 - false_negatives: 634.9117 - false_positives: 804.7059 - loss: 0.6209 - precision: 0.6141 - recall: 0.6961 - true_negatives: 1618.8235 - true_positives: 1355.2354\n",
      "Epoch 41/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6492 - auc: 0.7072 - false_negatives: 679.3731 - false_positives: 805.0895 - loss: 0.6351 - precision: 0.6023 - recall: 0.6588 - true_negatives: 1583.9851 - true_positives: 1283.3284\n",
      "Epoch 41: loss did not improve from 0.60553\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6495 - auc: 0.7076 - false_negatives: 688.3530 - false_positives: 815.6912 - loss: 0.6348 - precision: 0.6026 - recall: 0.6589 - true_negatives: 1607.8383 - true_positives: 1301.7941\n",
      "Epoch 42/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6651 - auc: 0.7263 - false_negatives: 562.3134 - false_positives: 846.0597 - loss: 0.6270 - precision: 0.6083 - recall: 0.7327 - true_negatives: 1543.0149 - true_positives: 1400.3881\n",
      "Epoch 42: loss improved from 0.60553 to 0.59875, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6655 - auc: 0.7267 - false_negatives: 570.5441 - false_positives: 855.9853 - loss: 0.6266 - precision: 0.6088 - recall: 0.7323 - true_negatives: 1567.5441 - true_positives: 1419.6029\n",
      "Epoch 43/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6725 - auc: 0.7342 - false_negatives: 613.1515 - false_positives: 743.1515 - loss: 0.6197 - precision: 0.6261 - recall: 0.6738 - true_negatives: 1610.4242 - true_positives: 1321.2727\n",
      "Epoch 43: loss improved from 0.59875 to 0.58925, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6732 - auc: 0.7351 - false_negatives: 629.5883 - false_positives: 763.4706 - loss: 0.6188 - precision: 0.6268 - recall: 0.6744 - true_negatives: 1660.0588 - true_positives: 1360.5588\n",
      "Epoch 44/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6966 - auc: 0.7698 - false_negatives: 609.1791 - false_positives: 685.3433 - loss: 0.5829 - precision: 0.6543 - recall: 0.6926 - true_negatives: 1703.7313 - true_positives: 1353.5223\n",
      "Epoch 44: loss improved from 0.58925 to 0.57183, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6967 - auc: 0.7700 - false_negatives: 617.0883 - false_positives: 695.2794 - loss: 0.5827 - precision: 0.6544 - recall: 0.6927 - true_negatives: 1728.2500 - true_positives: 1373.0588\n",
      "Epoch 45/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6986 - auc: 0.7734 - false_negatives: 623.9552 - false_positives: 671.7463 - loss: 0.5831 - precision: 0.6578 - recall: 0.6870 - true_negatives: 1717.3284 - true_positives: 1338.7462\n",
      "Epoch 45: loss did not improve from 0.57183\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6987 - auc: 0.7734 - false_negatives: 632.7647 - false_positives: 680.9117 - loss: 0.5830 - precision: 0.6580 - recall: 0.6869 - true_negatives: 1742.6177 - true_positives: 1357.3823\n",
      "Epoch 46/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7080 - auc: 0.7827 - false_negatives: 531.8508 - false_positives: 728.6418 - loss: 0.5756 - precision: 0.6548 - recall: 0.7430 - true_negatives: 1660.4329 - true_positives: 1430.8507\n",
      "Epoch 46: loss improved from 0.57183 to 0.56511, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7081 - auc: 0.7828 - false_negatives: 540.1470 - false_positives: 737.7500 - loss: 0.5755 - precision: 0.6550 - recall: 0.7426 - true_negatives: 1685.7794 - true_positives: 1450.0000\n",
      "Epoch 47/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6867 - auc: 0.7569 - false_negatives: 598.5151 - false_positives: 742.9243 - loss: 0.6026 - precision: 0.6467 - recall: 0.6862 - true_negatives: 1610.6515 - true_positives: 1335.9091\n",
      "Epoch 47: loss did not improve from 0.56511\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6870 - auc: 0.7573 - false_negatives: 616.7353 - false_positives: 761.9265 - loss: 0.6021 - precision: 0.6469 - recall: 0.6861 - true_negatives: 1661.6029 - true_positives: 1373.4117\n",
      "Epoch 48/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6965 - auc: 0.7766 - false_negatives: 502.6970 - false_positives: 784.9849 - loss: 0.5807 - precision: 0.6402 - recall: 0.7420 - true_negatives: 1568.5909 - true_positives: 1431.7273\n",
      "Epoch 48: loss did not improve from 0.56511\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6969 - auc: 0.7770 - false_negatives: 518.4706 - false_positives: 804.1912 - loss: 0.5804 - precision: 0.6408 - recall: 0.7416 - true_negatives: 1619.3383 - true_positives: 1471.6765\n",
      "Epoch 49/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6795 - auc: 0.7493 - false_negatives: 620.6418 - false_positives: 742.5074 - loss: 0.6082 - precision: 0.6451 - recall: 0.6513 - true_negatives: 1646.5671 - true_positives: 1342.0597\n",
      "Epoch 49: loss did not improve from 0.56511\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6798 - auc: 0.7498 - false_negatives: 628.7500 - false_positives: 751.9265 - loss: 0.6077 - precision: 0.6453 - recall: 0.6519 - true_negatives: 1671.6029 - true_positives: 1361.3971\n",
      "Epoch 50/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7165 - auc: 0.7868 - false_negatives: 562.6818 - false_positives: 636.0606 - loss: 0.5674 - precision: 0.6812 - recall: 0.6912 - true_negatives: 1717.5151 - true_positives: 1371.7424\n",
      "Epoch 50: loss improved from 0.56511 to 0.55393, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7167 - auc: 0.7872 - false_negatives: 578.5735 - false_positives: 654.1470 - loss: 0.5670 - precision: 0.6814 - recall: 0.6919 - true_negatives: 1769.3823 - true_positives: 1411.5735\n",
      "Epoch 51/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7172 - auc: 0.7882 - false_negatives: 552.9243 - false_positives: 657.6667 - loss: 0.5677 - precision: 0.6807 - recall: 0.6992 - true_negatives: 1695.9091 - true_positives: 1381.5000\n",
      "Epoch 51: loss did not improve from 0.55393\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7174 - auc: 0.7884 - false_negatives: 568.9265 - false_positives: 676.0294 - loss: 0.5675 - precision: 0.6807 - recall: 0.6997 - true_negatives: 1747.5000 - true_positives: 1421.2206\n",
      "Epoch 52/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7229 - auc: 0.7938 - false_negatives: 550.3731 - false_positives: 653.0298 - loss: 0.5591 - precision: 0.6875 - recall: 0.7047 - true_negatives: 1736.0448 - true_positives: 1412.3284\n",
      "Epoch 52: loss improved from 0.55393 to 0.54747, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7230 - auc: 0.7940 - false_negatives: 557.8823 - false_positives: 661.7500 - loss: 0.5589 - precision: 0.6875 - recall: 0.7049 - true_negatives: 1761.7794 - true_positives: 1432.2646\n",
      "Epoch 53/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7226 - auc: 0.7981 - false_negatives: 560.9849 - false_positives: 643.0757 - loss: 0.5553 - precision: 0.6905 - recall: 0.6970 - true_negatives: 1710.5000 - true_positives: 1373.4395\n",
      "Epoch 53: loss did not improve from 0.54747\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7226 - auc: 0.7982 - false_negatives: 577.2206 - false_positives: 661.5735 - loss: 0.5552 - precision: 0.6902 - recall: 0.6974 - true_negatives: 1761.9559 - true_positives: 1412.9265\n",
      "Epoch 54/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7215 - auc: 0.7930 - false_negatives: 557.5373 - false_positives: 649.7612 - loss: 0.5623 - precision: 0.6885 - recall: 0.6961 - true_negatives: 1739.3135 - true_positives: 1405.1642\n",
      "Epoch 54: loss did not improve from 0.54747\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7216 - auc: 0.7931 - false_negatives: 565.2500 - false_positives: 658.5735 - loss: 0.5621 - precision: 0.6885 - recall: 0.6964 - true_negatives: 1764.9559 - true_positives: 1424.8971\n",
      "Epoch 55/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7161 - auc: 0.7945 - false_negatives: 539.1539 - false_positives: 632.3538 - loss: 0.5589 - precision: 0.6807 - recall: 0.6897 - true_negatives: 1685.8308 - true_positives: 1366.6615\n",
      "Epoch 55: loss improved from 0.54747 to 0.54423, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7168 - auc: 0.7951 - false_negatives: 560.4265 - false_positives: 660.2941 - loss: 0.5583 - precision: 0.6811 - recall: 0.6916 - true_negatives: 1763.2354 - true_positives: 1429.7206\n",
      "Epoch 56/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7319 - auc: 0.8018 - false_negatives: 544.8788 - false_positives: 605.9849 - loss: 0.5533 - precision: 0.7031 - recall: 0.7014 - true_negatives: 1747.5909 - true_positives: 1389.5454\n",
      "Epoch 56: loss improved from 0.54423 to 0.54278, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7320 - auc: 0.8020 - false_negatives: 559.7059 - false_positives: 623.6030 - loss: 0.5530 - precision: 0.7029 - recall: 0.7021 - true_negatives: 1799.9265 - true_positives: 1430.4412\n",
      "Epoch 57/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7280 - auc: 0.8073 - false_negatives: 513.9243 - false_positives: 639.8485 - loss: 0.5447 - precision: 0.6840 - recall: 0.7349 - true_negatives: 1713.7273 - true_positives: 1420.5000\n",
      "Epoch 57: loss did not improve from 0.54278\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7282 - auc: 0.8074 - false_negatives: 529.3088 - false_positives: 657.0883 - loss: 0.5447 - precision: 0.6843 - recall: 0.7347 - true_negatives: 1766.4412 - true_positives: 1460.8383\n",
      "Epoch 58/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7353 - auc: 0.8089 - false_negatives: 500.9091 - false_positives: 641.2273 - loss: 0.5439 - precision: 0.6928 - recall: 0.7378 - true_negatives: 1712.3485 - true_positives: 1433.5151\n",
      "Epoch 58: loss improved from 0.54278 to 0.54232, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7352 - auc: 0.8090 - false_negatives: 516.0000 - false_positives: 659.2794 - loss: 0.5439 - precision: 0.6928 - recall: 0.7378 - true_negatives: 1764.2500 - true_positives: 1474.1471\n",
      "Epoch 59/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7254 - auc: 0.8049 - false_negatives: 546.3182 - false_positives: 632.1212 - loss: 0.5470 - precision: 0.6930 - recall: 0.7010 - true_negatives: 1721.4546 - true_positives: 1388.1061\n",
      "Epoch 59: loss improved from 0.54232 to 0.53955, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7257 - auc: 0.8051 - false_negatives: 560.9559 - false_positives: 649.9117 - loss: 0.5468 - precision: 0.6929 - recall: 0.7018 - true_negatives: 1773.6177 - true_positives: 1429.1912\n",
      "Epoch 60/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7276 - auc: 0.8046 - false_negatives: 561.0757 - false_positives: 614.4849 - loss: 0.5481 - precision: 0.6957 - recall: 0.7008 - true_negatives: 1739.0909 - true_positives: 1373.3485\n",
      "Epoch 60: loss did not improve from 0.53955\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7277 - auc: 0.8047 - false_negatives: 577.0147 - false_positives: 631.3235 - loss: 0.5480 - precision: 0.6957 - recall: 0.7011 - true_negatives: 1792.2059 - true_positives: 1413.1323\n",
      "Epoch 61/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7293 - auc: 0.8145 - false_negatives: 503.2090 - false_positives: 678.9850 - loss: 0.5385 - precision: 0.6797 - recall: 0.7521 - true_negatives: 1710.0896 - true_positives: 1459.4926\n",
      "Epoch 61: loss improved from 0.53955 to 0.53434, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7294 - auc: 0.8145 - false_negatives: 510.6471 - false_positives: 687.7206 - loss: 0.5384 - precision: 0.6798 - recall: 0.7519 - true_negatives: 1735.8088 - true_positives: 1479.5000\n",
      "Epoch 62/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7398 - auc: 0.8121 - false_negatives: 539.1045 - false_positives: 600.8358 - loss: 0.5427 - precision: 0.7150 - recall: 0.7053 - true_negatives: 1788.2388 - true_positives: 1423.5970\n",
      "Epoch 62: loss improved from 0.53434 to 0.53278, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7399 - auc: 0.8122 - false_negatives: 546.3088 - false_positives: 609.3383 - loss: 0.5426 - precision: 0.7148 - recall: 0.7057 - true_negatives: 1814.1912 - true_positives: 1443.8383\n",
      "Epoch 63/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7381 - auc: 0.8116 - false_negatives: 531.3881 - false_positives: 611.5373 - loss: 0.5408 - precision: 0.7060 - recall: 0.7161 - true_negatives: 1777.5374 - true_positives: 1431.3135\n",
      "Epoch 63: loss did not improve from 0.53278\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7382 - auc: 0.8117 - false_negatives: 538.7941 - false_positives: 619.7941 - loss: 0.5407 - precision: 0.7060 - recall: 0.7163 - true_negatives: 1803.7354 - true_positives: 1451.3529\n",
      "Epoch 64/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7397 - auc: 0.8186 - false_negatives: 508.6866 - false_positives: 629.8358 - loss: 0.5319 - precision: 0.6997 - recall: 0.7364 - true_negatives: 1759.2388 - true_positives: 1454.0149\n",
      "Epoch 64: loss improved from 0.53278 to 0.53168, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7397 - auc: 0.8187 - false_negatives: 516.0441 - false_positives: 638.3677 - loss: 0.5319 - precision: 0.6997 - recall: 0.7364 - true_negatives: 1785.1617 - true_positives: 1474.1029\n",
      "Epoch 65/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7421 - auc: 0.8219 - false_negatives: 502.0151 - false_positives: 611.1667 - loss: 0.5292 - precision: 0.7060 - recall: 0.7307 - true_negatives: 1742.4091 - true_positives: 1432.4091\n",
      "Epoch 65: loss improved from 0.53168 to 0.52702, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7422 - auc: 0.8219 - false_negatives: 516.3383 - false_positives: 628.4853 - loss: 0.5291 - precision: 0.7059 - recall: 0.7310 - true_negatives: 1795.0441 - true_positives: 1473.8088\n",
      "Epoch 66/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7487 - auc: 0.8235 - false_negatives: 509.7612 - false_positives: 600.2239 - loss: 0.5243 - precision: 0.7139 - recall: 0.7359 - true_negatives: 1788.8507 - true_positives: 1452.9403\n",
      "Epoch 66: loss improved from 0.52702 to 0.52324, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7486 - auc: 0.8235 - false_negatives: 516.8970 - false_positives: 608.9706 - loss: 0.5243 - precision: 0.7138 - recall: 0.7360 - true_negatives: 1814.5588 - true_positives: 1473.2500\n",
      "Epoch 67/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7408 - auc: 0.8209 - false_negatives: 530.7727 - false_positives: 587.1818 - loss: 0.5276 - precision: 0.7108 - recall: 0.7144 - true_negatives: 1766.3939 - true_positives: 1403.6515\n",
      "Epoch 67: loss did not improve from 0.52324\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7409 - auc: 0.8210 - false_negatives: 544.9559 - false_positives: 604.5000 - loss: 0.5275 - precision: 0.7106 - recall: 0.7150 - true_negatives: 1819.0294 - true_positives: 1445.1912\n",
      "Epoch 68/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7439 - auc: 0.8272 - false_negatives: 497.7164 - false_positives: 605.1791 - loss: 0.5230 - precision: 0.7036 - recall: 0.7427 - true_negatives: 1783.8955 - true_positives: 1464.9851\n",
      "Epoch 68: loss improved from 0.52324 to 0.52076, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7440 - auc: 0.8272 - false_negatives: 504.6912 - false_positives: 613.4853 - loss: 0.5230 - precision: 0.7036 - recall: 0.7428 - true_negatives: 1810.0441 - true_positives: 1485.4559\n",
      "Epoch 69/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7527 - auc: 0.8352 - false_negatives: 492.7761 - false_positives: 589.6418 - loss: 0.5103 - precision: 0.7186 - recall: 0.7396 - true_negatives: 1799.4329 - true_positives: 1469.9254\n",
      "Epoch 69: loss improved from 0.52076 to 0.51485, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7527 - auc: 0.8351 - false_negatives: 499.9853 - false_positives: 597.7647 - loss: 0.5104 - precision: 0.7186 - recall: 0.7396 - true_negatives: 1825.7646 - true_positives: 1490.1617\n",
      "Epoch 70/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7539 - auc: 0.8342 - false_negatives: 469.1667 - false_positives: 600.5606 - loss: 0.5113 - precision: 0.7120 - recall: 0.7597 - true_negatives: 1753.0151 - true_positives: 1465.2576\n",
      "Epoch 70: loss improved from 0.51485 to 0.51450, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7539 - auc: 0.8341 - false_negatives: 483.2206 - false_positives: 617.5147 - loss: 0.5114 - precision: 0.7120 - recall: 0.7595 - true_negatives: 1806.0146 - true_positives: 1506.9265\n",
      "Epoch 71/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7530 - auc: 0.8291 - false_negatives: 496.5454 - false_positives: 566.6515 - loss: 0.5170 - precision: 0.7235 - recall: 0.7298 - true_negatives: 1786.9242 - true_positives: 1437.8788\n",
      "Epoch 71: loss did not improve from 0.51450\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7530 - auc: 0.8291 - false_negatives: 510.5588 - false_positives: 583.6912 - loss: 0.5171 - precision: 0.7232 - recall: 0.7303 - true_negatives: 1839.8383 - true_positives: 1479.5883\n",
      "Epoch 72/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7504 - auc: 0.8310 - false_negatives: 476.0298 - false_positives: 606.6567 - loss: 0.5149 - precision: 0.7092 - recall: 0.7526 - true_negatives: 1782.4180 - true_positives: 1486.6716\n",
      "Epoch 72: loss improved from 0.51450 to 0.51102, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7504 - auc: 0.8310 - false_negatives: 482.8088 - false_positives: 614.9117 - loss: 0.5149 - precision: 0.7092 - recall: 0.7527 - true_negatives: 1808.6177 - true_positives: 1507.3383\n",
      "Epoch 73/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7503 - auc: 0.8260 - false_negatives: 490.7424 - false_positives: 586.4394 - loss: 0.5225 - precision: 0.7186 - recall: 0.7322 - true_negatives: 1767.1364 - true_positives: 1443.6818\n",
      "Epoch 73: loss did not improve from 0.51102\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7503 - auc: 0.8261 - false_negatives: 504.7794 - false_positives: 603.0441 - loss: 0.5223 - precision: 0.7184 - recall: 0.7326 - true_negatives: 1820.4854 - true_positives: 1485.3677\n",
      "Epoch 74/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7561 - auc: 0.8377 - false_negatives: 447.5606 - false_positives: 609.6212 - loss: 0.5060 - precision: 0.7132 - recall: 0.7650 - true_negatives: 1743.9546 - true_positives: 1486.8636\n",
      "Epoch 74: loss improved from 0.51102 to 0.50794, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7562 - auc: 0.8377 - false_negatives: 460.7206 - false_positives: 626.3677 - loss: 0.5061 - precision: 0.7132 - recall: 0.7651 - true_negatives: 1797.1617 - true_positives: 1529.4265\n",
      "Epoch 75/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7506 - auc: 0.8285 - false_negatives: 472.3788 - false_positives: 599.4394 - loss: 0.5208 - precision: 0.7146 - recall: 0.7411 - true_negatives: 1754.1364 - true_positives: 1462.0454\n",
      "Epoch 75: loss did not improve from 0.50794\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7506 - auc: 0.8286 - false_negatives: 485.7794 - false_positives: 617.1617 - loss: 0.5205 - precision: 0.7144 - recall: 0.7416 - true_negatives: 1806.3677 - true_positives: 1504.3677\n",
      "Epoch 76/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7625 - auc: 0.8409 - false_negatives: 460.2727 - false_positives: 572.5455 - loss: 0.5033 - precision: 0.7251 - recall: 0.7598 - true_negatives: 1781.0303 - true_positives: 1474.1515\n",
      "Epoch 76: loss improved from 0.50794 to 0.50689, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7624 - auc: 0.8408 - false_negatives: 473.8529 - false_positives: 589.0000 - loss: 0.5034 - precision: 0.7249 - recall: 0.7598 - true_negatives: 1834.5294 - true_positives: 1516.2941\n",
      "Epoch 77/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7499 - auc: 0.8331 - false_negatives: 457.5373 - false_positives: 619.9702 - loss: 0.5125 - precision: 0.7029 - recall: 0.7699 - true_negatives: 1769.1045 - true_positives: 1505.1642\n",
      "Epoch 77: loss did not improve from 0.50689\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7500 - auc: 0.8331 - false_negatives: 464.2941 - false_positives: 628.1912 - loss: 0.5125 - precision: 0.7031 - recall: 0.7698 - true_negatives: 1795.3383 - true_positives: 1525.8529\n",
      "Epoch 78/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7616 - auc: 0.8416 - false_negatives: 460.0000 - false_positives: 583.6418 - loss: 0.5027 - precision: 0.7249 - recall: 0.7567 - true_negatives: 1805.4329 - true_positives: 1502.7015\n",
      "Epoch 78: loss improved from 0.50689 to 0.50335, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7616 - auc: 0.8416 - false_negatives: 466.6176 - false_positives: 591.8235 - loss: 0.5027 - precision: 0.7248 - recall: 0.7568 - true_negatives: 1831.7059 - true_positives: 1523.5294\n",
      "Epoch 79/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7529 - auc: 0.8377 - false_negatives: 494.6567 - false_positives: 573.6567 - loss: 0.5075 - precision: 0.7224 - recall: 0.7310 - true_negatives: 1815.4180 - true_positives: 1468.0448\n",
      "Epoch 79: loss did not improve from 0.50335\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7529 - auc: 0.8377 - false_negatives: 501.0147 - false_positives: 581.9117 - loss: 0.5074 - precision: 0.7224 - recall: 0.7314 - true_negatives: 1841.6177 - true_positives: 1489.1323\n",
      "Epoch 80/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7578 - auc: 0.8405 - false_negatives: 474.2985 - false_positives: 584.7164 - loss: 0.5023 - precision: 0.7201 - recall: 0.7536 - true_negatives: 1804.3582 - true_positives: 1488.4030\n",
      "Epoch 80: loss did not improve from 0.50335\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7578 - auc: 0.8405 - false_negatives: 480.9265 - false_positives: 593.2941 - loss: 0.5023 - precision: 0.7200 - recall: 0.7537 - true_negatives: 1830.2354 - true_positives: 1509.2206\n",
      "Epoch 81/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7684 - auc: 0.8434 - false_negatives: 457.7612 - false_positives: 558.4627 - loss: 0.4991 - precision: 0.7323 - recall: 0.7635 - true_negatives: 1830.6119 - true_positives: 1504.9403\n",
      "Epoch 81: loss improved from 0.50335 to 0.50007, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7683 - auc: 0.8434 - false_negatives: 463.9853 - false_positives: 566.6912 - loss: 0.4991 - precision: 0.7322 - recall: 0.7636 - true_negatives: 1856.8383 - true_positives: 1526.1617\n",
      "Epoch 82/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7584 - auc: 0.8370 - false_negatives: 463.9077 - false_positives: 556.4615 - loss: 0.5076 - precision: 0.7237 - recall: 0.7476 - true_negatives: 1761.7230 - true_positives: 1441.9077\n",
      "Epoch 82: loss did not improve from 0.50007\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7584 - auc: 0.8370 - false_negatives: 484.5588 - false_positives: 581.5441 - loss: 0.5076 - precision: 0.7235 - recall: 0.7480 - true_negatives: 1841.9854 - true_positives: 1505.5883\n",
      "Epoch 83/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7593 - auc: 0.8427 - false_negatives: 439.8333 - false_positives: 578.1970 - loss: 0.5006 - precision: 0.7160 - recall: 0.7705 - true_negatives: 1775.3788 - true_positives: 1494.5909\n",
      "Epoch 83: loss improved from 0.50007 to 0.49827, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7595 - auc: 0.8428 - false_negatives: 452.8971 - false_positives: 594.1323 - loss: 0.5005 - precision: 0.7162 - recall: 0.7705 - true_negatives: 1829.3971 - true_positives: 1537.2500\n",
      "Epoch 84/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7706 - auc: 0.8477 - false_negatives: 464.4925 - false_positives: 542.4478 - loss: 0.4939 - precision: 0.7388 - recall: 0.7566 - true_negatives: 1846.6268 - true_positives: 1498.2090\n",
      "Epoch 84: loss improved from 0.49827 to 0.49681, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7705 - auc: 0.8477 - false_negatives: 471.0000 - false_positives: 550.3235 - loss: 0.4940 - precision: 0.7386 - recall: 0.7567 - true_negatives: 1873.2059 - true_positives: 1519.1471\n",
      "Epoch 85/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7692 - auc: 0.8497 - false_negatives: 457.3881 - false_positives: 562.4030 - loss: 0.4902 - precision: 0.7347 - recall: 0.7611 - true_negatives: 1826.6716 - true_positives: 1505.3135\n",
      "Epoch 85: loss improved from 0.49681 to 0.49493, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7691 - auc: 0.8497 - false_negatives: 463.7647 - false_positives: 570.5294 - loss: 0.4903 - precision: 0.7346 - recall: 0.7612 - true_negatives: 1853.0000 - true_positives: 1526.3823\n",
      "Epoch 86/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7685 - auc: 0.8469 - false_negatives: 453.6567 - false_positives: 560.0298 - loss: 0.4941 - precision: 0.7306 - recall: 0.7677 - true_negatives: 1829.0448 - true_positives: 1509.0448\n",
      "Epoch 86: loss improved from 0.49493 to 0.49464, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7685 - auc: 0.8469 - false_negatives: 460.0294 - false_positives: 568.0000 - loss: 0.4941 - precision: 0.7305 - recall: 0.7678 - true_negatives: 1855.5294 - true_positives: 1530.1177\n",
      "Epoch 87/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7699 - auc: 0.8522 - false_negatives: 471.8806 - false_positives: 537.2239 - loss: 0.4869 - precision: 0.7393 - recall: 0.7532 - true_negatives: 1851.8507 - true_positives: 1490.8209\n",
      "Epoch 87: loss improved from 0.49464 to 0.49315, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7699 - auc: 0.8521 - false_negatives: 478.5588 - false_positives: 545.0883 - loss: 0.4870 - precision: 0.7392 - recall: 0.7533 - true_negatives: 1878.4412 - true_positives: 1511.5883\n",
      "Epoch 88/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7617 - auc: 0.8455 - false_negatives: 445.3636 - false_positives: 565.4697 - loss: 0.4958 - precision: 0.7174 - recall: 0.7798 - true_negatives: 1788.1061 - true_positives: 1489.0605\n",
      "Epoch 88: loss did not improve from 0.49315\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7617 - auc: 0.8454 - false_negatives: 459.3235 - false_positives: 581.6323 - loss: 0.4959 - precision: 0.7176 - recall: 0.7792 - true_negatives: 1841.8971 - true_positives: 1530.8235\n",
      "Epoch 89/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7673 - auc: 0.8491 - false_negatives: 452.4478 - false_positives: 561.2537 - loss: 0.4920 - precision: 0.7311 - recall: 0.7617 - true_negatives: 1827.8209 - true_positives: 1510.2538\n",
      "Epoch 89: loss improved from 0.49315 to 0.49210, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7673 - auc: 0.8491 - false_negatives: 458.7941 - false_positives: 569.2647 - loss: 0.4920 - precision: 0.7311 - recall: 0.7618 - true_negatives: 1854.2646 - true_positives: 1531.3529\n",
      "Epoch 90/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7688 - auc: 0.8502 - false_negatives: 445.6567 - false_positives: 543.9850 - loss: 0.4886 - precision: 0.7314 - recall: 0.7653 - true_negatives: 1845.0896 - true_positives: 1517.0448\n",
      "Epoch 90: loss improved from 0.49210 to 0.48556, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7689 - auc: 0.8503 - false_negatives: 451.8529 - false_positives: 551.5294 - loss: 0.4886 - precision: 0.7315 - recall: 0.7654 - true_negatives: 1872.0000 - true_positives: 1538.2941\n",
      "Epoch 91/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7724 - auc: 0.8521 - false_negatives: 432.3788 - false_positives: 547.6667 - loss: 0.4859 - precision: 0.7344 - recall: 0.7724 - true_negatives: 1805.9091 - true_positives: 1502.0454\n",
      "Epoch 91: loss improved from 0.48556 to 0.48546, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7724 - auc: 0.8521 - false_negatives: 444.6324 - false_positives: 563.5883 - loss: 0.4859 - precision: 0.7343 - recall: 0.7725 - true_negatives: 1859.9412 - true_positives: 1545.5146\n",
      "Epoch 92/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7641 - auc: 0.8485 - false_negatives: 476.0448 - false_positives: 530.8060 - loss: 0.4915 - precision: 0.7333 - recall: 0.7444 - true_negatives: 1858.2687 - true_positives: 1486.6567\n",
      "Epoch 92: loss did not improve from 0.48546\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7642 - auc: 0.8485 - false_negatives: 482.4412 - false_positives: 538.2941 - loss: 0.4914 - precision: 0.7333 - recall: 0.7447 - true_negatives: 1885.2354 - true_positives: 1507.7059\n",
      "Epoch 93/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7718 - auc: 0.8565 - false_negatives: 441.4776 - false_positives: 549.2239 - loss: 0.4800 - precision: 0.7319 - recall: 0.7770 - true_negatives: 1839.8507 - true_positives: 1521.2239\n",
      "Epoch 93: loss improved from 0.48546 to 0.48336, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7718 - auc: 0.8564 - false_negatives: 447.8676 - false_positives: 557.1323 - loss: 0.4800 - precision: 0.7319 - recall: 0.7770 - true_negatives: 1866.3971 - true_positives: 1542.2794\n",
      "Epoch 94/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7786 - auc: 0.8551 - false_negatives: 460.9105 - false_positives: 524.2985 - loss: 0.4826 - precision: 0.7516 - recall: 0.7587 - true_negatives: 1864.7761 - true_positives: 1501.7910\n",
      "Epoch 94: loss did not improve from 0.48336\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7785 - auc: 0.8550 - false_negatives: 467.3088 - false_positives: 532.1765 - loss: 0.4827 - precision: 0.7513 - recall: 0.7588 - true_negatives: 1891.3529 - true_positives: 1522.8383\n",
      "Epoch 95/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7558 - auc: 0.8431 - false_negatives: 459.8507 - false_positives: 579.4627 - loss: 0.5000 - precision: 0.7120 - recall: 0.7736 - true_negatives: 1809.6119 - true_positives: 1502.8507\n",
      "Epoch 95: loss did not improve from 0.48336\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7559 - auc: 0.8432 - false_negatives: 466.3824 - false_positives: 587.0735 - loss: 0.4998 - precision: 0.7122 - recall: 0.7734 - true_negatives: 1836.4559 - true_positives: 1523.7646\n",
      "Epoch 96/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7689 - auc: 0.8521 - false_negatives: 457.4925 - false_positives: 541.5224 - loss: 0.4862 - precision: 0.7357 - recall: 0.7552 - true_negatives: 1847.5522 - true_positives: 1505.2090\n",
      "Epoch 96: loss improved from 0.48336 to 0.48260, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7690 - auc: 0.8521 - false_negatives: 463.7353 - false_positives: 548.9853 - loss: 0.4861 - precision: 0.7357 - recall: 0.7554 - true_negatives: 1874.5441 - true_positives: 1526.4117\n",
      "Epoch 97/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7749 - auc: 0.8567 - false_negatives: 446.6119 - false_positives: 534.5671 - loss: 0.4791 - precision: 0.7415 - recall: 0.7650 - true_negatives: 1854.5074 - true_positives: 1516.0896\n",
      "Epoch 97: loss improved from 0.48260 to 0.47788, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7749 - auc: 0.8567 - false_negatives: 452.6471 - false_positives: 542.1323 - loss: 0.4791 - precision: 0.7415 - recall: 0.7652 - true_negatives: 1881.3971 - true_positives: 1537.5000\n",
      "Epoch 98/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7754 - auc: 0.8526 - false_negatives: 463.9702 - false_positives: 518.2836 - loss: 0.4853 - precision: 0.7445 - recall: 0.7606 - true_negatives: 1870.7910 - true_positives: 1498.7313\n",
      "Epoch 98: loss did not improve from 0.47788\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7754 - auc: 0.8527 - false_negatives: 470.2941 - false_positives: 525.9117 - loss: 0.4853 - precision: 0.7444 - recall: 0.7607 - true_negatives: 1897.6177 - true_positives: 1519.8529\n",
      "Epoch 99/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7727 - auc: 0.8507 - false_negatives: 438.7612 - false_positives: 548.4329 - loss: 0.4894 - precision: 0.7321 - recall: 0.7809 - true_negatives: 1840.6418 - true_positives: 1523.9403\n",
      "Epoch 99: loss did not improve from 0.47788\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7727 - auc: 0.8508 - false_negatives: 445.0147 - false_positives: 556.1765 - loss: 0.4893 - precision: 0.7321 - recall: 0.7808 - true_negatives: 1867.3529 - true_positives: 1545.1323\n",
      "Epoch 100/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7738 - auc: 0.8561 - false_negatives: 435.6364 - false_positives: 530.2121 - loss: 0.4797 - precision: 0.7359 - recall: 0.7739 - true_negatives: 1823.3636 - true_positives: 1498.7878\n",
      "Epoch 100: loss did not improve from 0.47788\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7739 - auc: 0.8561 - false_negatives: 448.2647 - false_positives: 545.4412 - loss: 0.4798 - precision: 0.7360 - recall: 0.7739 - true_negatives: 1878.0883 - true_positives: 1541.8823\n",
      "Epoch 101/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7712 - auc: 0.8515 - false_negatives: 450.4925 - false_positives: 532.7015 - loss: 0.4877 - precision: 0.7367 - recall: 0.7620 - true_negatives: 1856.3732 - true_positives: 1512.2090\n",
      "Epoch 101: loss did not improve from 0.47788\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7713 - auc: 0.8515 - false_negatives: 456.4853 - false_positives: 540.1617 - loss: 0.4876 - precision: 0.7368 - recall: 0.7622 - true_negatives: 1883.3677 - true_positives: 1533.6617\n",
      "Epoch 102/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7801 - auc: 0.8609 - false_negatives: 433.6866 - false_positives: 527.3284 - loss: 0.4732 - precision: 0.7419 - recall: 0.7843 - true_negatives: 1861.7462 - true_positives: 1529.0149\n",
      "Epoch 102: loss did not improve from 0.47788\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7801 - auc: 0.8608 - false_negatives: 439.9853 - false_positives: 534.9412 - loss: 0.4733 - precision: 0.7418 - recall: 0.7842 - true_negatives: 1888.5883 - true_positives: 1550.1617\n",
      "Epoch 103/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7720 - auc: 0.8550 - false_negatives: 436.7576 - false_positives: 532.2121 - loss: 0.4816 - precision: 0.7354 - recall: 0.7686 - true_negatives: 1821.3636 - true_positives: 1497.6666\n",
      "Epoch 103: loss improved from 0.47788 to 0.47485, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7723 - auc: 0.8551 - false_negatives: 448.9118 - false_positives: 547.0294 - loss: 0.4814 - precision: 0.7356 - recall: 0.7689 - true_negatives: 1876.5000 - true_positives: 1541.2354\n",
      "Epoch 104/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7817 - auc: 0.8566 - false_negatives: 427.7879 - false_positives: 507.6212 - loss: 0.4798 - precision: 0.7497 - recall: 0.7708 - true_negatives: 1845.9546 - true_positives: 1506.6364\n",
      "Epoch 104: loss did not improve from 0.47485\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7818 - auc: 0.8567 - false_negatives: 439.5000 - false_positives: 522.8088 - loss: 0.4797 - precision: 0.7496 - recall: 0.7712 - true_negatives: 1900.7206 - true_positives: 1550.6471\n",
      "Epoch 105/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7775 - auc: 0.8547 - false_negatives: 433.3846 - false_positives: 504.4308 - loss: 0.4832 - precision: 0.7422 - recall: 0.7749 - true_negatives: 1813.7539 - true_positives: 1472.4308\n",
      "Epoch 105: loss did not improve from 0.47485\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7776 - auc: 0.8547 - false_negatives: 452.2059 - false_positives: 526.9853 - loss: 0.4831 - precision: 0.7423 - recall: 0.7749 - true_negatives: 1896.5441 - true_positives: 1537.9412\n",
      "Epoch 106/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7785 - auc: 0.8579 - false_negatives: 434.2686 - false_positives: 528.6269 - loss: 0.4784 - precision: 0.7415 - recall: 0.7789 - true_negatives: 1860.4478 - true_positives: 1528.4329\n",
      "Epoch 106: loss did not improve from 0.47485\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7786 - auc: 0.8579 - false_negatives: 440.3382 - false_positives: 536.0735 - loss: 0.4783 - precision: 0.7415 - recall: 0.7789 - true_negatives: 1887.4559 - true_positives: 1549.8088\n",
      "Epoch 107/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7826 - auc: 0.8618 - false_negatives: 415.5224 - false_positives: 529.6567 - loss: 0.4732 - precision: 0.7440 - recall: 0.7858 - true_negatives: 1859.4180 - true_positives: 1547.1791\n",
      "Epoch 107: loss improved from 0.47485 to 0.47462, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7825 - auc: 0.8618 - false_negatives: 421.6029 - false_positives: 537.1470 - loss: 0.4732 - precision: 0.7440 - recall: 0.7857 - true_negatives: 1886.3823 - true_positives: 1568.5441\n",
      "Epoch 108/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7720 - auc: 0.8532 - false_negatives: 454.2686 - false_positives: 520.8358 - loss: 0.4841 - precision: 0.7374 - recall: 0.7644 - true_negatives: 1868.2388 - true_positives: 1508.4329\n",
      "Epoch 108: loss did not improve from 0.47462\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7721 - auc: 0.8533 - false_negatives: 460.3382 - false_positives: 528.1617 - loss: 0.4840 - precision: 0.7375 - recall: 0.7645 - true_negatives: 1895.3677 - true_positives: 1529.8088\n",
      "Epoch 109/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7734 - auc: 0.8607 - false_negatives: 451.7273 - false_positives: 515.3485 - loss: 0.4734 - precision: 0.7416 - recall: 0.7595 - true_negatives: 1838.2273 - true_positives: 1482.6970\n",
      "Epoch 109: loss improved from 0.47462 to 0.47253, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7736 - auc: 0.8607 - false_negatives: 463.8824 - false_positives: 530.4559 - loss: 0.4734 - precision: 0.7416 - recall: 0.7599 - true_negatives: 1893.0735 - true_positives: 1526.2646\n",
      "Epoch 110/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7805 - auc: 0.8615 - false_negatives: 419.7910 - false_positives: 533.2836 - loss: 0.4726 - precision: 0.7390 - recall: 0.7922 - true_negatives: 1855.7910 - true_positives: 1542.9104\n",
      "Epoch 110: loss did not improve from 0.47253\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7806 - auc: 0.8615 - false_negatives: 425.7059 - false_positives: 540.5441 - loss: 0.4726 - precision: 0.7391 - recall: 0.7921 - true_negatives: 1882.9854 - true_positives: 1564.4412\n",
      "Epoch 111/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7843 - auc: 0.8645 - false_negatives: 433.1060 - false_positives: 494.6212 - loss: 0.4683 - precision: 0.7543 - recall: 0.7698 - true_negatives: 1858.9546 - true_positives: 1501.3182\n",
      "Epoch 111: loss improved from 0.47253 to 0.46946, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7843 - auc: 0.8645 - false_negatives: 445.1324 - false_positives: 509.3382 - loss: 0.4684 - precision: 0.7542 - recall: 0.7701 - true_negatives: 1914.1912 - true_positives: 1545.0146\n",
      "Epoch 112/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7790 - auc: 0.8650 - false_negatives: 430.8209 - false_positives: 523.0150 - loss: 0.4669 - precision: 0.7433 - recall: 0.7754 - true_negatives: 1866.0597 - true_positives: 1531.8806\n",
      "Epoch 112: loss improved from 0.46946 to 0.46656, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7791 - auc: 0.8650 - false_negatives: 436.6618 - false_positives: 530.3235 - loss: 0.4669 - precision: 0.7433 - recall: 0.7755 - true_negatives: 1893.2059 - true_positives: 1553.4854\n",
      "Epoch 113/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7813 - auc: 0.8615 - false_negatives: 424.9851 - false_positives: 525.5373 - loss: 0.4719 - precision: 0.7427 - recall: 0.7863 - true_negatives: 1863.5374 - true_positives: 1537.7164\n",
      "Epoch 113: loss did not improve from 0.46656\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7814 - auc: 0.8615 - false_negatives: 430.6912 - false_positives: 533.0000 - loss: 0.4719 - precision: 0.7427 - recall: 0.7863 - true_negatives: 1890.5294 - true_positives: 1559.4559\n",
      "Epoch 114/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7855 - auc: 0.8601 - false_negatives: 439.6667 - false_positives: 484.3940 - loss: 0.4746 - precision: 0.7577 - recall: 0.7680 - true_negatives: 1869.1818 - true_positives: 1494.7576\n",
      "Epoch 114: loss did not improve from 0.46656\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7856 - auc: 0.8601 - false_negatives: 451.8529 - false_positives: 498.7353 - loss: 0.4746 - precision: 0.7576 - recall: 0.7683 - true_negatives: 1924.7941 - true_positives: 1538.2941\n",
      "Epoch 115/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7816 - auc: 0.8605 - false_negatives: 413.8030 - false_positives: 511.2879 - loss: 0.4742 - precision: 0.7433 - recall: 0.7848 - true_negatives: 1842.2878 - true_positives: 1520.6212\n",
      "Epoch 115: loss did not improve from 0.46656\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7818 - auc: 0.8607 - false_negatives: 425.4853 - false_positives: 525.7500 - loss: 0.4741 - precision: 0.7435 - recall: 0.7849 - true_negatives: 1897.7794 - true_positives: 1564.6617\n",
      "Epoch 116/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7811 - auc: 0.8640 - false_negatives: 422.4179 - false_positives: 526.2537 - loss: 0.4677 - precision: 0.7450 - recall: 0.7779 - true_negatives: 1862.8209 - true_positives: 1540.2836\n",
      "Epoch 116: loss improved from 0.46656 to 0.46595, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7811 - auc: 0.8641 - false_negatives: 428.2353 - false_positives: 533.7941 - loss: 0.4677 - precision: 0.7449 - recall: 0.7780 - true_negatives: 1889.7354 - true_positives: 1561.9117\n",
      "Epoch 117/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7684 - auc: 0.8550 - false_negatives: 457.3881 - false_positives: 518.1343 - loss: 0.4821 - precision: 0.7360 - recall: 0.7534 - true_negatives: 1870.9403 - true_positives: 1505.3135\n",
      "Epoch 117: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7686 - auc: 0.8551 - false_negatives: 463.2059 - false_positives: 525.3823 - loss: 0.4819 - precision: 0.7362 - recall: 0.7538 - true_negatives: 1898.1471 - true_positives: 1526.9412\n",
      "Epoch 118/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7804 - auc: 0.8567 - false_negatives: 437.8788 - false_positives: 500.3030 - loss: 0.4813 - precision: 0.7482 - recall: 0.7707 - true_negatives: 1853.2727 - true_positives: 1496.5454\n",
      "Epoch 118: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7804 - auc: 0.8569 - false_negatives: 449.9706 - false_positives: 515.3823 - loss: 0.4811 - precision: 0.7481 - recall: 0.7710 - true_negatives: 1908.1471 - true_positives: 1540.1765\n",
      "Epoch 119/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7759 - auc: 0.8586 - false_negatives: 431.8060 - false_positives: 528.7313 - loss: 0.4776 - precision: 0.7379 - recall: 0.7790 - true_negatives: 1860.3433 - true_positives: 1530.8955\n",
      "Epoch 119: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7760 - auc: 0.8586 - false_negatives: 437.6471 - false_positives: 536.0000 - loss: 0.4775 - precision: 0.7380 - recall: 0.7791 - true_negatives: 1887.5294 - true_positives: 1552.5000\n",
      "Epoch 120/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7792 - auc: 0.8606 - false_negatives: 438.7121 - false_positives: 503.0000 - loss: 0.4740 - precision: 0.7476 - recall: 0.7676 - true_negatives: 1850.5758 - true_positives: 1495.7122\n",
      "Epoch 120: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7794 - auc: 0.8607 - false_negatives: 450.4559 - false_positives: 517.7941 - loss: 0.4739 - precision: 0.7476 - recall: 0.7680 - true_negatives: 1905.7354 - true_positives: 1539.6912\n",
      "Epoch 121/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7808 - auc: 0.8622 - false_negatives: 434.7910 - false_positives: 518.5224 - loss: 0.4720 - precision: 0.7482 - recall: 0.7710 - true_negatives: 1870.5522 - true_positives: 1527.9104\n",
      "Epoch 121: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7809 - auc: 0.8622 - false_negatives: 440.4559 - false_positives: 526.1177 - loss: 0.4720 - precision: 0.7481 - recall: 0.7713 - true_negatives: 1897.4117 - true_positives: 1549.6912\n",
      "Epoch 122/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7816 - auc: 0.8622 - false_negatives: 438.5522 - false_positives: 500.2686 - loss: 0.4718 - precision: 0.7491 - recall: 0.7730 - true_negatives: 1888.8060 - true_positives: 1524.1493\n",
      "Epoch 122: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7817 - auc: 0.8622 - false_negatives: 444.3088 - false_positives: 507.4559 - loss: 0.4718 - precision: 0.7491 - recall: 0.7732 - true_negatives: 1916.0735 - true_positives: 1545.8383\n",
      "Epoch 123/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7868 - auc: 0.8628 - false_negatives: 422.8955 - false_positives: 509.2836 - loss: 0.4711 - precision: 0.7499 - recall: 0.7887 - true_negatives: 1879.7910 - true_positives: 1539.8060\n",
      "Epoch 123: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7868 - auc: 0.8628 - false_negatives: 428.8235 - false_positives: 516.1912 - loss: 0.4711 - precision: 0.7499 - recall: 0.7887 - true_negatives: 1907.3383 - true_positives: 1561.3235\n",
      "Epoch 124/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7761 - auc: 0.8603 - false_negatives: 440.4627 - false_positives: 527.3134 - loss: 0.4747 - precision: 0.7407 - recall: 0.7703 - true_negatives: 1861.7612 - true_positives: 1522.2388\n",
      "Epoch 124: loss did not improve from 0.46595\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7761 - auc: 0.8604 - false_negatives: 446.2059 - false_positives: 534.7794 - loss: 0.4747 - precision: 0.7407 - recall: 0.7705 - true_negatives: 1888.7500 - true_positives: 1543.9412\n",
      "Epoch 125/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7846 - auc: 0.8663 - false_negatives: 442.7424 - false_positives: 487.6515 - loss: 0.4648 - precision: 0.7568 - recall: 0.7670 - true_negatives: 1865.9242 - true_positives: 1491.6818\n",
      "Epoch 125: loss improved from 0.46595 to 0.46487, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7847 - auc: 0.8663 - false_negatives: 454.6618 - false_positives: 502.3676 - loss: 0.4648 - precision: 0.7567 - recall: 0.7673 - true_negatives: 1921.1617 - true_positives: 1535.4854\n",
      "Epoch 126/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7845 - auc: 0.8642 - false_negatives: 416.6818 - false_positives: 506.0303 - loss: 0.4682 - precision: 0.7488 - recall: 0.7824 - true_negatives: 1847.5454 - true_positives: 1517.7424\n",
      "Epoch 126: loss did not improve from 0.46487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7846 - auc: 0.8642 - false_negatives: 428.7500 - false_positives: 520.6765 - loss: 0.4682 - precision: 0.7488 - recall: 0.7825 - true_negatives: 1902.8529 - true_positives: 1561.3971\n",
      "Epoch 127/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7897 - auc: 0.8690 - false_negatives: 402.0597 - false_positives: 509.9105 - loss: 0.4623 - precision: 0.7518 - recall: 0.7937 - true_negatives: 1879.1642 - true_positives: 1560.6418\n",
      "Epoch 127: loss improved from 0.46487 to 0.46262, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7897 - auc: 0.8690 - false_negatives: 407.5588 - false_positives: 517.2941 - loss: 0.4623 - precision: 0.7518 - recall: 0.7938 - true_negatives: 1906.2354 - true_positives: 1582.5883\n",
      "Epoch 128/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7858 - auc: 0.8683 - false_negatives: 429.6418 - false_positives: 492.4478 - loss: 0.4625 - precision: 0.7553 - recall: 0.7736 - true_negatives: 1896.6268 - true_positives: 1533.0597\n",
      "Epoch 128: loss improved from 0.46262 to 0.46054, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7859 - auc: 0.8683 - false_negatives: 435.4412 - false_positives: 499.7059 - loss: 0.4625 - precision: 0.7553 - recall: 0.7737 - true_negatives: 1923.8235 - true_positives: 1554.7059\n",
      "Epoch 129/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7823 - auc: 0.8640 - false_negatives: 407.2727 - false_positives: 521.2424 - loss: 0.4693 - precision: 0.7428 - recall: 0.7886 - true_negatives: 1832.3334 - true_positives: 1527.1515\n",
      "Epoch 129: loss did not improve from 0.46054\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7824 - auc: 0.8640 - false_negatives: 418.8529 - false_positives: 536.3823 - loss: 0.4692 - precision: 0.7428 - recall: 0.7886 - true_negatives: 1887.1471 - true_positives: 1571.2941\n",
      "Epoch 130/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7813 - auc: 0.8633 - false_negatives: 430.1791 - false_positives: 509.9105 - loss: 0.4703 - precision: 0.7514 - recall: 0.7658 - true_negatives: 1879.1642 - true_positives: 1532.5223\n",
      "Epoch 130: loss did not improve from 0.46054\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7814 - auc: 0.8633 - false_negatives: 435.6471 - false_positives: 517.2941 - loss: 0.4702 - precision: 0.7513 - recall: 0.7661 - true_negatives: 1906.2354 - true_positives: 1554.5000\n",
      "Epoch 131/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7879 - auc: 0.8674 - false_negatives: 429.9552 - false_positives: 489.8358 - loss: 0.4632 - precision: 0.7599 - recall: 0.7706 - true_negatives: 1899.2388 - true_positives: 1532.7462\n",
      "Epoch 131: loss improved from 0.46054 to 0.45942, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7879 - auc: 0.8674 - false_negatives: 435.6618 - false_positives: 497.0735 - loss: 0.4632 - precision: 0.7598 - recall: 0.7708 - true_negatives: 1926.4559 - true_positives: 1554.4854\n",
      "Epoch 132/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7831 - auc: 0.8693 - false_negatives: 418.0597 - false_positives: 515.6567 - loss: 0.4608 - precision: 0.7457 - recall: 0.7853 - true_negatives: 1873.4180 - true_positives: 1544.6418\n",
      "Epoch 132: loss improved from 0.45942 to 0.45931, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7832 - auc: 0.8693 - false_negatives: 423.5735 - false_positives: 522.9853 - loss: 0.4608 - precision: 0.7457 - recall: 0.7854 - true_negatives: 1900.5441 - true_positives: 1566.5735\n",
      "Epoch 133/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7923 - auc: 0.8718 - false_negatives: 412.7612 - false_positives: 492.1343 - loss: 0.4560 - precision: 0.7583 - recall: 0.7887 - true_negatives: 1896.9403 - true_positives: 1549.9403\n",
      "Epoch 133: loss improved from 0.45931 to 0.45380, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7923 - auc: 0.8718 - false_negatives: 418.3676 - false_positives: 499.1324 - loss: 0.4559 - precision: 0.7583 - recall: 0.7888 - true_negatives: 1924.3971 - true_positives: 1571.7794\n",
      "Epoch 134/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7861 - auc: 0.8632 - false_negatives: 394.7077 - false_positives: 493.5385 - loss: 0.4712 - precision: 0.7488 - recall: 0.7871 - true_negatives: 1824.6461 - true_positives: 1511.1077\n",
      "Epoch 134: loss did not improve from 0.45380\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7864 - auc: 0.8635 - false_negatives: 411.4118 - false_positives: 515.2500 - loss: 0.4707 - precision: 0.7491 - recall: 0.7876 - true_negatives: 1908.2794 - true_positives: 1578.7354\n",
      "Epoch 135/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7978 - auc: 0.8706 - false_negatives: 391.9846 - false_positives: 464.5538 - loss: 0.4593 - precision: 0.7701 - recall: 0.7836 - true_negatives: 1853.6307 - true_positives: 1513.8308\n",
      "Epoch 135: loss did not improve from 0.45380\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7978 - auc: 0.8707 - false_negatives: 408.1029 - false_positives: 486.7353 - loss: 0.4592 - precision: 0.7696 - recall: 0.7844 - true_negatives: 1936.7941 - true_positives: 1582.0441\n",
      "Epoch 136/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7814 - auc: 0.8636 - false_negatives: 396.9091 - false_positives: 530.8030 - loss: 0.4692 - precision: 0.7401 - recall: 0.7911 - true_negatives: 1822.7727 - true_positives: 1537.5151\n",
      "Epoch 136: loss did not improve from 0.45380\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7817 - auc: 0.8638 - false_negatives: 407.7353 - false_positives: 545.8088 - loss: 0.4689 - precision: 0.7403 - recall: 0.7914 - true_negatives: 1877.7206 - true_positives: 1582.4117\n",
      "Epoch 137/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7777 - auc: 0.8628 - false_negatives: 426.0454 - false_positives: 510.4091 - loss: 0.4710 - precision: 0.7428 - recall: 0.7717 - true_negatives: 1843.1666 - true_positives: 1508.3788\n",
      "Epoch 137: loss did not improve from 0.45380\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7780 - auc: 0.8630 - false_negatives: 437.3971 - false_positives: 525.2500 - loss: 0.4707 - precision: 0.7430 - recall: 0.7722 - true_negatives: 1898.2794 - true_positives: 1552.7500\n",
      "Epoch 138/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7931 - auc: 0.8746 - false_negatives: 417.0606 - false_positives: 475.1970 - loss: 0.4522 - precision: 0.7654 - recall: 0.7776 - true_negatives: 1878.3788 - true_positives: 1517.3636\n",
      "Epoch 138: loss improved from 0.45380 to 0.45268, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7932 - auc: 0.8746 - false_negatives: 428.4706 - false_positives: 489.2500 - loss: 0.4522 - precision: 0.7652 - recall: 0.7780 - true_negatives: 1934.2794 - true_positives: 1561.6765\n",
      "Epoch 139/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7854 - auc: 0.8657 - false_negatives: 424.4179 - false_positives: 501.5821 - loss: 0.4657 - precision: 0.7511 - recall: 0.7810 - true_negatives: 1887.4926 - true_positives: 1538.2836\n",
      "Epoch 139: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7855 - auc: 0.8658 - false_negatives: 430.0147 - false_positives: 509.1471 - loss: 0.4657 - precision: 0.7511 - recall: 0.7812 - true_negatives: 1914.3823 - true_positives: 1560.1323\n",
      "Epoch 140/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7861 - auc: 0.8722 - false_negatives: 399.3636 - false_positives: 517.1667 - loss: 0.4568 - precision: 0.7465 - recall: 0.7931 - true_negatives: 1836.4091 - true_positives: 1535.0605\n",
      "Epoch 140: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7862 - auc: 0.8722 - false_negatives: 410.6176 - false_positives: 532.0147 - loss: 0.4567 - precision: 0.7466 - recall: 0.7932 - true_negatives: 1891.5146 - true_positives: 1579.5294\n",
      "Epoch 141/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7857 - auc: 0.8687 - false_negatives: 400.6667 - false_positives: 517.9545 - loss: 0.4613 - precision: 0.7474 - recall: 0.7892 - true_negatives: 1835.6212 - true_positives: 1533.7576\n",
      "Epoch 141: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7859 - auc: 0.8688 - false_negatives: 411.5000 - false_positives: 532.5735 - loss: 0.4611 - precision: 0.7475 - recall: 0.7894 - true_negatives: 1890.9559 - true_positives: 1578.6471\n",
      "Epoch 142/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7929 - auc: 0.8724 - false_negatives: 408.5373 - false_positives: 496.9254 - loss: 0.4559 - precision: 0.7594 - recall: 0.7887 - true_negatives: 1892.1493 - true_positives: 1554.1642\n",
      "Epoch 142: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7930 - auc: 0.8724 - false_negatives: 413.9853 - false_positives: 503.9265 - loss: 0.4559 - precision: 0.7593 - recall: 0.7888 - true_negatives: 1919.6029 - true_positives: 1576.1617\n",
      "Epoch 143/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7931 - auc: 0.8743 - false_negatives: 406.2985 - false_positives: 500.1791 - loss: 0.4526 - precision: 0.7593 - recall: 0.7894 - true_negatives: 1888.8955 - true_positives: 1556.4030\n",
      "Epoch 143: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7931 - auc: 0.8742 - false_negatives: 411.7941 - false_positives: 507.3088 - loss: 0.4526 - precision: 0.7592 - recall: 0.7895 - true_negatives: 1916.2206 - true_positives: 1578.3529\n",
      "Epoch 144/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7827 - auc: 0.8643 - false_negatives: 423.9849 - false_positives: 496.9243 - loss: 0.4673 - precision: 0.7518 - recall: 0.7688 - true_negatives: 1856.6515 - true_positives: 1510.4395\n",
      "Epoch 144: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7829 - auc: 0.8646 - false_negatives: 435.1912 - false_positives: 511.3382 - loss: 0.4670 - precision: 0.7519 - recall: 0.7694 - true_negatives: 1912.1912 - true_positives: 1554.9559\n",
      "Epoch 145/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7902 - auc: 0.8714 - false_negatives: 404.2879 - false_positives: 492.2121 - loss: 0.4575 - precision: 0.7552 - recall: 0.7880 - true_negatives: 1861.3636 - true_positives: 1530.1364\n",
      "Epoch 145: loss did not improve from 0.45268\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7902 - auc: 0.8715 - false_negatives: 415.3676 - false_positives: 507.0588 - loss: 0.4574 - precision: 0.7552 - recall: 0.7883 - true_negatives: 1916.4706 - true_positives: 1574.7794\n",
      "Epoch 146/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8016 - auc: 0.8775 - false_negatives: 383.4328 - false_positives: 491.2836 - loss: 0.4470 - precision: 0.7661 - recall: 0.8035 - true_negatives: 1897.7910 - true_positives: 1579.2687\n",
      "Epoch 146: loss improved from 0.45268 to 0.45044, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8016 - auc: 0.8775 - false_negatives: 388.6029 - false_positives: 498.4853 - loss: 0.4470 - precision: 0.7660 - recall: 0.8036 - true_negatives: 1925.0441 - true_positives: 1601.5441\n",
      "Epoch 147/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8005 - auc: 0.8774 - false_negatives: 388.9394 - false_positives: 468.9697 - loss: 0.4483 - precision: 0.7689 - recall: 0.7943 - true_negatives: 1884.6061 - true_positives: 1545.4849\n",
      "Epoch 147: loss improved from 0.45044 to 0.44487, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8005 - auc: 0.8775 - false_negatives: 399.7353 - false_positives: 482.6471 - loss: 0.4482 - precision: 0.7688 - recall: 0.7945 - true_negatives: 1940.8823 - true_positives: 1590.4117\n",
      "Epoch 148/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7946 - auc: 0.8714 - false_negatives: 396.2985 - false_positives: 495.7314 - loss: 0.4574 - precision: 0.7600 - recall: 0.7915 - true_negatives: 1893.3433 - true_positives: 1566.4030\n",
      "Epoch 148: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7946 - auc: 0.8714 - false_negatives: 401.7500 - false_positives: 502.7794 - loss: 0.4573 - precision: 0.7600 - recall: 0.7916 - true_negatives: 1920.7500 - true_positives: 1588.3971\n",
      "Epoch 149/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7891 - auc: 0.8744 - false_negatives: 416.2836 - false_positives: 495.9105 - loss: 0.4519 - precision: 0.7554 - recall: 0.7838 - true_negatives: 1893.1642 - true_positives: 1546.4180\n",
      "Epoch 149: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7891 - auc: 0.8745 - false_negatives: 421.7647 - false_positives: 503.0882 - loss: 0.4519 - precision: 0.7554 - recall: 0.7839 - true_negatives: 1920.4412 - true_positives: 1568.3823\n",
      "Epoch 150/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7962 - auc: 0.8736 - false_negatives: 406.1493 - false_positives: 481.1791 - loss: 0.4540 - precision: 0.7630 - recall: 0.7922 - true_negatives: 1907.8955 - true_positives: 1556.5522\n",
      "Epoch 150: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7962 - auc: 0.8737 - false_negatives: 411.6176 - false_positives: 488.1176 - loss: 0.4539 - precision: 0.7629 - recall: 0.7923 - true_negatives: 1935.4117 - true_positives: 1578.5294\n",
      "Epoch 151/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7880 - auc: 0.8716 - false_negatives: 382.2576 - false_positives: 507.8030 - loss: 0.4576 - precision: 0.7456 - recall: 0.8019 - true_negatives: 1845.7727 - true_positives: 1552.1666\n",
      "Epoch 151: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7882 - auc: 0.8717 - false_negatives: 392.9853 - false_positives: 522.0441 - loss: 0.4574 - precision: 0.7459 - recall: 0.8020 - true_negatives: 1901.4854 - true_positives: 1597.1617\n",
      "Epoch 152/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7921 - auc: 0.8677 - false_negatives: 425.6667 - false_positives: 467.8788 - loss: 0.4647 - precision: 0.7700 - recall: 0.7659 - true_negatives: 1885.6970 - true_positives: 1508.7576\n",
      "Epoch 152: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7921 - auc: 0.8679 - false_negatives: 437.2941 - false_positives: 482.2353 - loss: 0.4644 - precision: 0.7697 - recall: 0.7664 - true_negatives: 1941.2941 - true_positives: 1552.8529\n",
      "Epoch 153/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7958 - auc: 0.8777 - false_negatives: 377.7761 - false_positives: 516.8657 - loss: 0.4473 - precision: 0.7538 - recall: 0.8100 - true_negatives: 1872.2090 - true_positives: 1584.9254\n",
      "Epoch 153: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7958 - auc: 0.8777 - false_negatives: 383.0882 - false_positives: 523.9853 - loss: 0.4473 - precision: 0.7538 - recall: 0.8100 - true_negatives: 1899.5441 - true_positives: 1607.0588\n",
      "Epoch 154/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7989 - auc: 0.8790 - false_negatives: 404.8806 - false_positives: 479.8955 - loss: 0.4451 - precision: 0.7700 - recall: 0.7884 - true_negatives: 1909.1791 - true_positives: 1557.8209\n",
      "Epoch 154: loss did not improve from 0.44487\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7989 - auc: 0.8790 - false_negatives: 410.4265 - false_positives: 486.7353 - loss: 0.4451 - precision: 0.7699 - recall: 0.7885 - true_negatives: 1936.7941 - true_positives: 1579.7206\n",
      "Epoch 155/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7963 - auc: 0.8809 - false_negatives: 394.2121 - false_positives: 480.6818 - loss: 0.4414 - precision: 0.7625 - recall: 0.7931 - true_negatives: 1872.8939 - true_positives: 1540.2122\n",
      "Epoch 155: loss improved from 0.44487 to 0.44172, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7963 - auc: 0.8809 - false_negatives: 405.3824 - false_positives: 494.7500 - loss: 0.4414 - precision: 0.7624 - recall: 0.7933 - true_negatives: 1928.7794 - true_positives: 1584.7646\n",
      "Epoch 156/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8015 - auc: 0.8782 - false_negatives: 375.7612 - false_positives: 496.8358 - loss: 0.4458 - precision: 0.7637 - recall: 0.8080 - true_negatives: 1892.2388 - true_positives: 1586.9403\n",
      "Epoch 156: loss did not improve from 0.44172\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8015 - auc: 0.8782 - false_negatives: 381.1029 - false_positives: 503.7794 - loss: 0.4458 - precision: 0.7637 - recall: 0.8080 - true_negatives: 1919.7500 - true_positives: 1609.0441\n",
      "Epoch 157/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7979 - auc: 0.8793 - false_negatives: 407.1060 - false_positives: 463.0757 - loss: 0.4456 - precision: 0.7714 - recall: 0.7812 - true_negatives: 1890.5000 - true_positives: 1527.3182\n",
      "Epoch 157: loss did not improve from 0.44172\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7979 - auc: 0.8792 - false_negatives: 418.2794 - false_positives: 477.2206 - loss: 0.4456 - precision: 0.7712 - recall: 0.7816 - true_negatives: 1946.3088 - true_positives: 1571.8677\n",
      "Epoch 158/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7995 - auc: 0.8810 - false_negatives: 383.4925 - false_positives: 496.7910 - loss: 0.4412 - precision: 0.7619 - recall: 0.8051 - true_negatives: 1892.2836 - true_positives: 1579.2090\n",
      "Epoch 158: loss did not improve from 0.44172\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7995 - auc: 0.8810 - false_negatives: 388.6912 - false_positives: 504.0147 - loss: 0.4412 - precision: 0.7618 - recall: 0.8051 - true_negatives: 1919.5146 - true_positives: 1601.4559\n",
      "Epoch 159/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8007 - auc: 0.8776 - false_negatives: 420.8657 - false_positives: 461.1940 - loss: 0.4476 - precision: 0.7753 - recall: 0.7835 - true_negatives: 1927.8806 - true_positives: 1541.8358\n",
      "Epoch 159: loss did not improve from 0.44172\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8007 - auc: 0.8776 - false_negatives: 426.5000 - false_positives: 468.1176 - loss: 0.4476 - precision: 0.7751 - recall: 0.7836 - true_negatives: 1955.4117 - true_positives: 1563.6471\n",
      "Epoch 160/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8056 - auc: 0.8836 - false_negatives: 385.0298 - false_positives: 466.9105 - loss: 0.4369 - precision: 0.7725 - recall: 0.8038 - true_negatives: 1922.1642 - true_positives: 1577.6716\n",
      "Epoch 160: loss improved from 0.44172 to 0.43807, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8056 - auc: 0.8836 - false_negatives: 390.2059 - false_positives: 473.6029 - loss: 0.4369 - precision: 0.7725 - recall: 0.8038 - true_negatives: 1949.9265 - true_positives: 1599.9412\n",
      "Epoch 161/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7992 - auc: 0.8812 - false_negatives: 393.4925 - false_positives: 476.6567 - loss: 0.4413 - precision: 0.7663 - recall: 0.7947 - true_negatives: 1912.4180 - true_positives: 1569.2090\n",
      "Epoch 161: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7992 - auc: 0.8812 - false_negatives: 398.8235 - false_positives: 483.4706 - loss: 0.4413 - precision: 0.7663 - recall: 0.7948 - true_negatives: 1940.0588 - true_positives: 1591.3235\n",
      "Epoch 162/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7907 - auc: 0.8698 - false_negatives: 394.5303 - false_positives: 490.5909 - loss: 0.4618 - precision: 0.7517 - recall: 0.8012 - true_negatives: 1862.9849 - true_positives: 1539.8939\n",
      "Epoch 162: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7909 - auc: 0.8700 - false_negatives: 405.5735 - false_positives: 504.2500 - loss: 0.4615 - precision: 0.7520 - recall: 0.8012 - true_negatives: 1919.2794 - true_positives: 1584.5735\n",
      "Epoch 163/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8014 - auc: 0.8773 - false_negatives: 394.0151 - false_positives: 459.7424 - loss: 0.4477 - precision: 0.7696 - recall: 0.7956 - true_negatives: 1893.8334 - true_positives: 1540.4091\n",
      "Epoch 163: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8015 - auc: 0.8774 - false_negatives: 404.8676 - false_positives: 473.1324 - loss: 0.4476 - precision: 0.7696 - recall: 0.7958 - true_negatives: 1950.3971 - true_positives: 1585.2794\n",
      "Epoch 164/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8038 - auc: 0.8810 - false_negatives: 384.8060 - false_positives: 470.1791 - loss: 0.4427 - precision: 0.7696 - recall: 0.8042 - true_negatives: 1918.8955 - true_positives: 1577.8955\n",
      "Epoch 164: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8038 - auc: 0.8810 - false_negatives: 390.2500 - false_positives: 476.9706 - loss: 0.4427 - precision: 0.7695 - recall: 0.8041 - true_negatives: 1946.5588 - true_positives: 1599.8971\n",
      "Epoch 165/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7912 - auc: 0.8771 - false_negatives: 381.7879 - false_positives: 506.5000 - loss: 0.4491 - precision: 0.7491 - recall: 0.8051 - true_negatives: 1847.0758 - true_positives: 1552.6364\n",
      "Epoch 165: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7914 - auc: 0.8772 - false_negatives: 392.8529 - false_positives: 520.6912 - loss: 0.4490 - precision: 0.7493 - recall: 0.8050 - true_negatives: 1902.8383 - true_positives: 1597.2941\n",
      "Epoch 166/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8081 - auc: 0.8833 - false_negatives: 381.8636 - false_positives: 456.5454 - loss: 0.4377 - precision: 0.7773 - recall: 0.8029 - true_negatives: 1897.0303 - true_positives: 1552.5605\n",
      "Epoch 166: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8080 - auc: 0.8833 - false_negatives: 392.3088 - false_positives: 470.5294 - loss: 0.4377 - precision: 0.7770 - recall: 0.8031 - true_negatives: 1953.0000 - true_positives: 1597.8383\n",
      "Epoch 167/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8058 - auc: 0.8794 - false_negatives: 411.5821 - false_positives: 446.9403 - loss: 0.4459 - precision: 0.7847 - recall: 0.7839 - true_negatives: 1942.1343 - true_positives: 1551.1194\n",
      "Epoch 167: loss did not improve from 0.43807\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8058 - auc: 0.8794 - false_negatives: 416.8971 - false_positives: 453.6471 - loss: 0.4458 - precision: 0.7845 - recall: 0.7841 - true_negatives: 1969.8823 - true_positives: 1573.2500\n",
      "Epoch 168/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8035 - auc: 0.8861 - false_negatives: 366.9849 - false_positives: 471.1364 - loss: 0.4329 - precision: 0.7660 - recall: 0.8097 - true_negatives: 1882.4395 - true_positives: 1567.4395\n",
      "Epoch 168: loss improved from 0.43807 to 0.43244, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8037 - auc: 0.8861 - false_negatives: 377.0441 - false_positives: 484.5735 - loss: 0.4329 - precision: 0.7662 - recall: 0.8098 - true_negatives: 1938.9559 - true_positives: 1613.1029\n",
      "Epoch 169/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8037 - auc: 0.8794 - false_negatives: 392.0454 - false_positives: 463.5757 - loss: 0.4449 - precision: 0.7775 - recall: 0.7908 - true_negatives: 1890.0000 - true_positives: 1542.3788\n",
      "Epoch 169: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8036 - auc: 0.8794 - false_negatives: 402.7206 - false_positives: 477.8529 - loss: 0.4449 - precision: 0.7771 - recall: 0.7912 - true_negatives: 1945.6765 - true_positives: 1587.4265\n",
      "Epoch 170/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7979 - auc: 0.8813 - false_negatives: 386.6364 - false_positives: 472.6667 - loss: 0.4410 - precision: 0.7626 - recall: 0.7988 - true_negatives: 1880.9091 - true_positives: 1547.7878\n",
      "Epoch 170: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7980 - auc: 0.8813 - false_negatives: 397.6176 - false_positives: 486.1765 - loss: 0.4411 - precision: 0.7627 - recall: 0.7988 - true_negatives: 1937.3529 - true_positives: 1592.5294\n",
      "Epoch 171/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8100 - auc: 0.8835 - false_negatives: 373.6866 - false_positives: 460.3881 - loss: 0.4373 - precision: 0.7762 - recall: 0.8101 - true_negatives: 1928.6865 - true_positives: 1589.0149\n",
      "Epoch 171: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8100 - auc: 0.8835 - false_negatives: 378.7059 - false_positives: 466.9559 - loss: 0.4373 - precision: 0.7761 - recall: 0.8101 - true_negatives: 1956.5735 - true_positives: 1611.4412\n",
      "Epoch 172/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8074 - auc: 0.8847 - false_negatives: 368.0597 - false_positives: 472.3881 - loss: 0.4354 - precision: 0.7707 - recall: 0.8125 - true_negatives: 1916.6865 - true_positives: 1594.6418\n",
      "Epoch 172: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8074 - auc: 0.8847 - false_negatives: 373.2206 - false_positives: 479.0294 - loss: 0.4354 - precision: 0.7707 - recall: 0.8125 - true_negatives: 1944.5000 - true_positives: 1616.9265\n",
      "Epoch 173/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8024 - auc: 0.8780 - false_negatives: 391.7761 - false_positives: 467.6716 - loss: 0.4476 - precision: 0.7753 - recall: 0.7899 - true_negatives: 1921.4030 - true_positives: 1570.9254\n",
      "Epoch 173: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8025 - auc: 0.8781 - false_negatives: 396.9706 - false_positives: 474.3676 - loss: 0.4474 - precision: 0.7752 - recall: 0.7901 - true_negatives: 1949.1617 - true_positives: 1593.1765\n",
      "Epoch 174/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8052 - auc: 0.8815 - false_negatives: 391.9552 - false_positives: 448.9851 - loss: 0.4414 - precision: 0.7779 - recall: 0.7915 - true_negatives: 1940.0896 - true_positives: 1570.7462\n",
      "Epoch 174: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8053 - auc: 0.8816 - false_negatives: 397.2500 - false_positives: 455.4412 - loss: 0.4414 - precision: 0.7779 - recall: 0.7917 - true_negatives: 1968.0883 - true_positives: 1592.8971\n",
      "Epoch 175/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7971 - auc: 0.8797 - false_negatives: 384.9254 - false_positives: 498.7761 - loss: 0.4441 - precision: 0.7606 - recall: 0.8000 - true_negatives: 1890.2985 - true_positives: 1577.7761\n",
      "Epoch 175: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7971 - auc: 0.8797 - false_negatives: 390.1176 - false_positives: 505.8529 - loss: 0.4441 - precision: 0.7606 - recall: 0.8001 - true_negatives: 1917.6765 - true_positives: 1600.0294\n",
      "Epoch 176/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8093 - auc: 0.8844 - false_negatives: 389.2836 - false_positives: 446.2537 - loss: 0.4362 - precision: 0.7834 - recall: 0.7955 - true_negatives: 1942.8209 - true_positives: 1573.4180\n",
      "Epoch 176: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8094 - auc: 0.8844 - false_negatives: 394.3382 - false_positives: 452.7206 - loss: 0.4362 - precision: 0.7833 - recall: 0.7957 - true_negatives: 1970.8088 - true_positives: 1595.8088\n",
      "Epoch 177/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8058 - auc: 0.8833 - false_negatives: 367.7273 - false_positives: 465.0151 - loss: 0.4373 - precision: 0.7719 - recall: 0.8053 - true_negatives: 1888.5605 - true_positives: 1566.6970\n",
      "Epoch 177: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8058 - auc: 0.8834 - false_negatives: 378.2353 - false_positives: 478.9265 - loss: 0.4373 - precision: 0.7718 - recall: 0.8055 - true_negatives: 1944.6029 - true_positives: 1611.9117\n",
      "Epoch 178/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8011 - auc: 0.8821 - false_negatives: 371.0298 - false_positives: 490.0746 - loss: 0.4397 - precision: 0.7617 - recall: 0.8099 - true_negatives: 1899.0000 - true_positives: 1591.6716\n",
      "Epoch 178: loss did not improve from 0.43244\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8011 - auc: 0.8822 - false_negatives: 376.1176 - false_positives: 496.7500 - loss: 0.4396 - precision: 0.7618 - recall: 0.8099 - true_negatives: 1926.7794 - true_positives: 1614.0294\n",
      "Epoch 179/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8074 - auc: 0.8847 - false_negatives: 379.1045 - false_positives: 462.5224 - loss: 0.4354 - precision: 0.7783 - recall: 0.7988 - true_negatives: 1926.5522 - true_positives: 1583.5970\n",
      "Epoch 179: loss improved from 0.43244 to 0.43189, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8074 - auc: 0.8848 - false_negatives: 384.1176 - false_positives: 469.3824 - loss: 0.4354 - precision: 0.7782 - recall: 0.7990 - true_negatives: 1954.1471 - true_positives: 1606.0294\n",
      "Epoch 180/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8043 - auc: 0.8780 - false_negatives: 386.2537 - false_positives: 467.3433 - loss: 0.4489 - precision: 0.7790 - recall: 0.7889 - true_negatives: 1921.7313 - true_positives: 1576.4478\n",
      "Epoch 180: loss did not improve from 0.43189\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8043 - auc: 0.8780 - false_negatives: 391.3676 - false_positives: 474.2941 - loss: 0.4488 - precision: 0.7788 - recall: 0.7892 - true_negatives: 1949.2354 - true_positives: 1598.7794\n",
      "Epoch 181/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8004 - auc: 0.8825 - false_negatives: 396.2686 - false_positives: 473.2985 - loss: 0.4395 - precision: 0.7673 - recall: 0.7977 - true_negatives: 1915.7761 - true_positives: 1566.4329\n",
      "Epoch 181: loss did not improve from 0.43189\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8005 - auc: 0.8825 - false_negatives: 401.7059 - false_positives: 479.9118 - loss: 0.4394 - precision: 0.7673 - recall: 0.7978 - true_negatives: 1943.6177 - true_positives: 1588.4412\n",
      "Epoch 182/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8024 - auc: 0.8805 - false_negatives: 371.4849 - false_positives: 463.9091 - loss: 0.4425 - precision: 0.7686 - recall: 0.8006 - true_negatives: 1889.6666 - true_positives: 1562.9395\n",
      "Epoch 182: loss did not improve from 0.43189\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8026 - auc: 0.8806 - false_negatives: 381.5882 - false_positives: 477.1471 - loss: 0.4422 - precision: 0.7687 - recall: 0.8010 - true_negatives: 1946.3823 - true_positives: 1608.5588\n",
      "Epoch 183/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8062 - auc: 0.8873 - false_negatives: 357.9105 - false_positives: 487.3731 - loss: 0.4315 - precision: 0.7639 - recall: 0.8225 - true_negatives: 1901.7015 - true_positives: 1604.7910\n",
      "Epoch 183: loss improved from 0.43189 to 0.42906, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8062 - auc: 0.8873 - false_negatives: 363.0588 - false_positives: 494.1176 - loss: 0.4315 - precision: 0.7640 - recall: 0.8224 - true_negatives: 1929.4117 - true_positives: 1627.0883\n",
      "Epoch 184/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8063 - auc: 0.8800 - false_negatives: 395.6269 - false_positives: 459.8209 - loss: 0.4444 - precision: 0.7830 - recall: 0.7891 - true_negatives: 1929.2538 - true_positives: 1567.0746\n",
      "Epoch 184: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8063 - auc: 0.8800 - false_negatives: 400.8088 - false_positives: 466.5735 - loss: 0.4443 - precision: 0.7828 - recall: 0.7893 - true_negatives: 1956.9559 - true_positives: 1589.3383\n",
      "Epoch 185/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8071 - auc: 0.8849 - false_negatives: 375.6866 - false_positives: 474.3731 - loss: 0.4349 - precision: 0.7748 - recall: 0.8043 - true_negatives: 1914.7015 - true_positives: 1587.0149\n",
      "Epoch 185: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8070 - auc: 0.8849 - false_negatives: 380.9118 - false_positives: 481.1618 - loss: 0.4349 - precision: 0.7747 - recall: 0.8044 - true_negatives: 1942.3677 - true_positives: 1609.2354\n",
      "Epoch 186/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8093 - auc: 0.8814 - false_negatives: 389.3582 - false_positives: 448.2388 - loss: 0.4421 - precision: 0.7872 - recall: 0.7898 - true_negatives: 1940.8358 - true_positives: 1573.3433\n",
      "Epoch 186: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8093 - auc: 0.8814 - false_negatives: 394.4412 - false_positives: 454.9265 - loss: 0.4420 - precision: 0.7871 - recall: 0.7901 - true_negatives: 1968.6029 - true_positives: 1595.7059\n",
      "Epoch 187/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8116 - auc: 0.8880 - false_negatives: 361.6119 - false_positives: 471.7463 - loss: 0.4293 - precision: 0.7751 - recall: 0.8175 - true_negatives: 1917.3284 - true_positives: 1601.0896\n",
      "Epoch 187: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8115 - auc: 0.8880 - false_negatives: 366.9853 - false_positives: 478.4118 - loss: 0.4293 - precision: 0.7750 - recall: 0.8174 - true_negatives: 1945.1177 - true_positives: 1623.1617\n",
      "Epoch 188/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8071 - auc: 0.8863 - false_negatives: 385.9552 - false_positives: 465.2836 - loss: 0.4320 - precision: 0.7795 - recall: 0.7958 - true_negatives: 1923.7910 - true_positives: 1576.7462\n",
      "Epoch 188: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8070 - auc: 0.8862 - false_negatives: 391.3529 - false_positives: 472.3529 - loss: 0.4321 - precision: 0.7792 - recall: 0.7959 - true_negatives: 1951.1765 - true_positives: 1598.7941\n",
      "Epoch 189/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7966 - auc: 0.8802 - false_negatives: 393.0448 - false_positives: 489.4478 - loss: 0.4438 - precision: 0.7606 - recall: 0.7990 - true_negatives: 1899.6268 - true_positives: 1569.6567\n",
      "Epoch 189: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7966 - auc: 0.8801 - false_negatives: 398.7500 - false_positives: 496.3088 - loss: 0.4439 - precision: 0.7606 - recall: 0.7989 - true_negatives: 1927.2206 - true_positives: 1591.3971\n",
      "Epoch 190/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7961 - auc: 0.8771 - false_negatives: 372.4627 - false_positives: 500.2537 - loss: 0.4474 - precision: 0.7562 - recall: 0.8048 - true_negatives: 1888.8209 - true_positives: 1590.2388\n",
      "Epoch 190: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7962 - auc: 0.8772 - false_negatives: 377.5147 - false_positives: 507.0000 - loss: 0.4472 - precision: 0.7563 - recall: 0.8049 - true_negatives: 1916.5294 - true_positives: 1612.6323\n",
      "Epoch 191/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8074 - auc: 0.8839 - false_negatives: 390.9552 - false_positives: 456.4776 - loss: 0.4391 - precision: 0.7843 - recall: 0.7894 - true_negatives: 1932.5970 - true_positives: 1571.7462\n",
      "Epoch 191: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8074 - auc: 0.8839 - false_negatives: 396.1765 - false_positives: 463.1912 - loss: 0.4390 - precision: 0.7841 - recall: 0.7896 - true_negatives: 1960.3383 - true_positives: 1593.9706\n",
      "Epoch 192/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8070 - auc: 0.8843 - false_negatives: 362.0909 - false_positives: 471.3030 - loss: 0.4352 - precision: 0.7711 - recall: 0.8107 - true_negatives: 1882.2727 - true_positives: 1572.3334\n",
      "Epoch 192: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8069 - auc: 0.8843 - false_negatives: 372.9412 - false_positives: 484.7941 - loss: 0.4352 - precision: 0.7711 - recall: 0.8106 - true_negatives: 1938.7354 - true_positives: 1617.2059\n",
      "Epoch 193/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8140 - auc: 0.8866 - false_negatives: 361.4849 - false_positives: 447.5909 - loss: 0.4313 - precision: 0.7849 - recall: 0.8075 - true_negatives: 1905.9849 - true_positives: 1572.9395\n",
      "Epoch 193: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8138 - auc: 0.8866 - false_negatives: 372.1765 - false_positives: 461.0735 - loss: 0.4314 - precision: 0.7845 - recall: 0.8076 - true_negatives: 1962.4559 - true_positives: 1617.9706\n",
      "Epoch 194/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8081 - auc: 0.8863 - false_negatives: 390.6119 - false_positives: 453.5821 - loss: 0.4333 - precision: 0.7855 - recall: 0.7898 - true_negatives: 1935.4926 - true_positives: 1572.0896\n",
      "Epoch 194: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8081 - auc: 0.8863 - false_negatives: 395.9118 - false_positives: 460.1765 - loss: 0.4333 - precision: 0.7853 - recall: 0.7900 - true_negatives: 1963.3529 - true_positives: 1594.2354\n",
      "Epoch 195/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8088 - auc: 0.8839 - false_negatives: 373.0746 - false_positives: 474.0746 - loss: 0.4364 - precision: 0.7781 - recall: 0.8038 - true_negatives: 1915.0000 - true_positives: 1589.6268\n",
      "Epoch 195: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8087 - auc: 0.8839 - false_negatives: 378.3235 - false_positives: 480.8824 - loss: 0.4364 - precision: 0.7780 - recall: 0.8039 - true_negatives: 1942.6471 - true_positives: 1611.8235\n",
      "Epoch 196/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8072 - auc: 0.8862 - false_negatives: 365.7424 - false_positives: 463.2121 - loss: 0.4327 - precision: 0.7740 - recall: 0.8060 - true_negatives: 1890.3636 - true_positives: 1568.6818\n",
      "Epoch 196: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8072 - auc: 0.8862 - false_negatives: 376.3382 - false_positives: 476.7941 - loss: 0.4328 - precision: 0.7739 - recall: 0.8061 - true_negatives: 1946.7354 - true_positives: 1613.8088\n",
      "Epoch 197/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8119 - auc: 0.8879 - false_negatives: 363.8030 - false_positives: 449.6667 - loss: 0.4298 - precision: 0.7777 - recall: 0.8142 - true_negatives: 1903.9091 - true_positives: 1570.6212\n",
      "Epoch 197: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8117 - auc: 0.8878 - false_negatives: 374.6618 - false_positives: 463.1471 - loss: 0.4298 - precision: 0.7776 - recall: 0.8140 - true_negatives: 1960.3823 - true_positives: 1615.4854\n",
      "Epoch 198/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8048 - auc: 0.8866 - false_negatives: 381.3582 - false_positives: 465.7761 - loss: 0.4321 - precision: 0.7749 - recall: 0.7961 - true_negatives: 1923.2985 - true_positives: 1581.3433\n",
      "Epoch 198: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8049 - auc: 0.8866 - false_negatives: 386.6029 - false_positives: 472.4706 - loss: 0.4321 - precision: 0.7748 - recall: 0.7963 - true_negatives: 1951.0588 - true_positives: 1603.5441\n",
      "Epoch 199/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7974 - auc: 0.8828 - false_negatives: 371.0149 - false_positives: 490.8358 - loss: 0.4401 - precision: 0.7560 - recall: 0.8139 - true_negatives: 1898.2388 - true_positives: 1591.6865\n",
      "Epoch 199: loss did not improve from 0.42906\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7975 - auc: 0.8828 - false_negatives: 376.2353 - false_positives: 497.4412 - loss: 0.4400 - precision: 0.7561 - recall: 0.8138 - true_negatives: 1926.0883 - true_positives: 1613.9117\n",
      "Epoch 200/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8105 - auc: 0.8876 - false_negatives: 366.6667 - false_positives: 446.5303 - loss: 0.4300 - precision: 0.7773 - recall: 0.8110 - true_negatives: 1907.0454 - true_positives: 1567.7576\n",
      "Epoch 200: loss improved from 0.42906 to 0.42677, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8105 - auc: 0.8876 - false_negatives: 376.8529 - false_positives: 459.8971 - loss: 0.4299 - precision: 0.7772 - recall: 0.8110 - true_negatives: 1963.6323 - true_positives: 1613.2941\n",
      "Epoch 201/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8090 - auc: 0.8844 - false_negatives: 370.7314 - false_positives: 458.1045 - loss: 0.4361 - precision: 0.7739 - recall: 0.8131 - true_negatives: 1930.9701 - true_positives: 1591.9701\n",
      "Epoch 201: loss did not improve from 0.42677\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8091 - auc: 0.8845 - false_negatives: 375.8382 - false_positives: 464.6029 - loss: 0.4360 - precision: 0.7739 - recall: 0.8130 - true_negatives: 1958.9265 - true_positives: 1614.3088\n",
      "Epoch 202/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8011 - auc: 0.8839 - false_negatives: 374.8636 - false_positives: 459.6970 - loss: 0.4357 - precision: 0.7675 - recall: 0.7980 - true_negatives: 1893.8788 - true_positives: 1559.5605\n",
      "Epoch 202: loss did not improve from 0.42677\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8012 - auc: 0.8840 - false_negatives: 385.6912 - false_positives: 473.0000 - loss: 0.4356 - precision: 0.7677 - recall: 0.7982 - true_negatives: 1950.5294 - true_positives: 1604.4559\n",
      "Epoch 203/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8014 - auc: 0.8847 - false_negatives: 384.3182 - false_positives: 459.4091 - loss: 0.4350 - precision: 0.7688 - recall: 0.7985 - true_negatives: 1894.1666 - true_positives: 1550.1061\n",
      "Epoch 203: loss did not improve from 0.42677\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8015 - auc: 0.8847 - false_negatives: 395.4853 - false_positives: 472.8676 - loss: 0.4350 - precision: 0.7688 - recall: 0.7986 - true_negatives: 1950.6617 - true_positives: 1594.6617\n",
      "Epoch 204/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8078 - auc: 0.8853 - false_negatives: 360.0909 - false_positives: 466.0151 - loss: 0.4342 - precision: 0.7721 - recall: 0.8111 - true_negatives: 1887.5605 - true_positives: 1574.3334\n",
      "Epoch 204: loss did not improve from 0.42677\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8078 - auc: 0.8854 - false_negatives: 370.4118 - false_positives: 479.9265 - loss: 0.4342 - precision: 0.7720 - recall: 0.8112 - true_negatives: 1943.6029 - true_positives: 1619.7354\n",
      "Epoch 205/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8129 - auc: 0.8903 - false_negatives: 378.7121 - false_positives: 428.8788 - loss: 0.4260 - precision: 0.7882 - recall: 0.7980 - true_negatives: 1924.6970 - true_positives: 1555.7122\n",
      "Epoch 205: loss improved from 0.42677 to 0.42477, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8129 - auc: 0.8903 - false_negatives: 388.8676 - false_positives: 442.5588 - loss: 0.4260 - precision: 0.7878 - recall: 0.7983 - true_negatives: 1980.9706 - true_positives: 1601.2794\n",
      "Epoch 206/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8005 - auc: 0.8852 - false_negatives: 381.9243 - false_positives: 466.2879 - loss: 0.4359 - precision: 0.7633 - recall: 0.8089 - true_negatives: 1887.2878 - true_positives: 1552.5000\n",
      "Epoch 206: loss did not improve from 0.42477\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8005 - auc: 0.8852 - false_negatives: 393.1618 - false_positives: 479.8676 - loss: 0.4358 - precision: 0.7634 - recall: 0.8086 - true_negatives: 1943.6617 - true_positives: 1596.9854\n",
      "Epoch 207/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8077 - auc: 0.8872 - false_negatives: 358.0298 - false_positives: 469.1940 - loss: 0.4317 - precision: 0.7690 - recall: 0.8185 - true_negatives: 1919.8806 - true_positives: 1604.6716\n",
      "Epoch 207: loss did not improve from 0.42477\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8077 - auc: 0.8872 - false_negatives: 362.9706 - false_positives: 475.7500 - loss: 0.4316 - precision: 0.7691 - recall: 0.8185 - true_negatives: 1947.7794 - true_positives: 1627.1765\n",
      "Epoch 208/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8193 - auc: 0.8911 - false_negatives: 373.2090 - false_positives: 421.8657 - loss: 0.4242 - precision: 0.7930 - recall: 0.8092 - true_negatives: 1967.2090 - true_positives: 1589.4926\n",
      "Epoch 208: loss did not improve from 0.42477\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8193 - auc: 0.8911 - false_negatives: 378.3088 - false_positives: 428.0882 - loss: 0.4242 - precision: 0.7929 - recall: 0.8093 - true_negatives: 1995.4412 - true_positives: 1611.8383\n",
      "Epoch 209/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8092 - auc: 0.8931 - false_negatives: 344.7727 - false_positives: 477.5909 - loss: 0.4215 - precision: 0.7660 - recall: 0.8306 - true_negatives: 1875.9849 - true_positives: 1589.6515\n",
      "Epoch 209: loss improved from 0.42477 to 0.42438, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8091 - auc: 0.8931 - false_negatives: 355.2206 - false_positives: 491.6324 - loss: 0.4216 - precision: 0.7660 - recall: 0.8302 - true_negatives: 1931.8971 - true_positives: 1634.9265\n",
      "Epoch 210/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8153 - auc: 0.8933 - false_negatives: 371.9546 - false_positives: 414.9546 - loss: 0.4209 - precision: 0.7926 - recall: 0.7968 - true_negatives: 1938.6212 - true_positives: 1562.4697\n",
      "Epoch 210: loss improved from 0.42438 to 0.41587, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8154 - auc: 0.8934 - false_negatives: 381.9265 - false_positives: 427.7206 - loss: 0.4208 - precision: 0.7924 - recall: 0.7973 - true_negatives: 1995.8088 - true_positives: 1608.2206\n",
      "Epoch 211/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8142 - auc: 0.8920 - false_negatives: 364.5075 - false_positives: 444.4627 - loss: 0.4222 - precision: 0.7818 - recall: 0.8145 - true_negatives: 1944.6119 - true_positives: 1598.1940\n",
      "Epoch 211: loss did not improve from 0.41587\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8142 - auc: 0.8920 - false_negatives: 369.6324 - false_positives: 450.9853 - loss: 0.4222 - precision: 0.7817 - recall: 0.8145 - true_negatives: 1972.5441 - true_positives: 1620.5146\n",
      "Epoch 212/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8100 - auc: 0.8932 - false_negatives: 346.7314 - false_positives: 479.9851 - loss: 0.4195 - precision: 0.7696 - recall: 0.8228 - true_negatives: 1909.0896 - true_positives: 1615.9701\n",
      "Epoch 212: loss did not improve from 0.41587\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8100 - auc: 0.8931 - false_negatives: 351.7794 - false_positives: 486.8529 - loss: 0.4196 - precision: 0.7696 - recall: 0.8228 - true_negatives: 1936.6765 - true_positives: 1638.3677\n",
      "Epoch 213/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8052 - auc: 0.8858 - false_negatives: 363.6119 - false_positives: 469.9403 - loss: 0.4327 - precision: 0.7675 - recall: 0.8128 - true_negatives: 1919.1343 - true_positives: 1599.0896\n",
      "Epoch 213: loss did not improve from 0.41587\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8053 - auc: 0.8859 - false_negatives: 368.5147 - false_positives: 476.4706 - loss: 0.4325 - precision: 0.7676 - recall: 0.8129 - true_negatives: 1947.0588 - true_positives: 1621.6323\n",
      "Epoch 214/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8158 - auc: 0.8953 - false_negatives: 358.2985 - false_positives: 442.4030 - loss: 0.4163 - precision: 0.7822 - recall: 0.8183 - true_negatives: 1946.6716 - true_positives: 1604.4030\n",
      "Epoch 214: loss did not improve from 0.41587\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8158 - auc: 0.8953 - false_negatives: 363.2941 - false_positives: 449.0882 - loss: 0.4164 - precision: 0.7821 - recall: 0.8183 - true_negatives: 1974.4412 - true_positives: 1626.8529\n",
      "Epoch 215/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8138 - auc: 0.8930 - false_negatives: 345.0303 - false_positives: 443.0606 - loss: 0.4192 - precision: 0.7779 - recall: 0.8195 - true_negatives: 1910.5151 - true_positives: 1589.3939\n",
      "Epoch 215: loss improved from 0.41587 to 0.41578, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8139 - auc: 0.8931 - false_negatives: 354.5588 - false_positives: 456.2941 - loss: 0.4191 - precision: 0.7780 - recall: 0.8196 - true_negatives: 1967.2354 - true_positives: 1635.5883\n",
      "Epoch 216/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8175 - auc: 0.8921 - false_negatives: 366.3940 - false_positives: 426.6364 - loss: 0.4225 - precision: 0.7919 - recall: 0.8056 - true_negatives: 1926.9395 - true_positives: 1568.0303\n",
      "Epoch 216: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8174 - auc: 0.8921 - false_negatives: 376.5294 - false_positives: 440.0000 - loss: 0.4226 - precision: 0.7916 - recall: 0.8058 - true_negatives: 1983.5294 - true_positives: 1613.6177\n",
      "Epoch 217/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8174 - auc: 0.8960 - false_negatives: 352.5522 - false_positives: 442.6269 - loss: 0.4164 - precision: 0.7813 - recall: 0.8250 - true_negatives: 1946.4478 - true_positives: 1610.1493\n",
      "Epoch 217: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8174 - auc: 0.8960 - false_negatives: 357.4559 - false_positives: 449.1765 - loss: 0.4164 - precision: 0.7813 - recall: 0.8249 - true_negatives: 1974.3529 - true_positives: 1632.6912\n",
      "Epoch 218/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8138 - auc: 0.8930 - false_negatives: 378.9702 - false_positives: 433.6716 - loss: 0.4204 - precision: 0.7904 - recall: 0.7959 - true_negatives: 1955.4030 - true_positives: 1583.7313\n",
      "Epoch 218: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8138 - auc: 0.8930 - false_negatives: 383.9118 - false_positives: 440.1765 - loss: 0.4204 - precision: 0.7903 - recall: 0.7962 - true_negatives: 1983.3529 - true_positives: 1606.2354\n",
      "Epoch 219/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8042 - auc: 0.8902 - false_negatives: 354.4546 - false_positives: 465.9849 - loss: 0.4262 - precision: 0.7641 - recall: 0.8189 - true_negatives: 1887.5909 - true_positives: 1579.9697\n",
      "Epoch 219: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8043 - auc: 0.8902 - false_negatives: 364.5294 - false_positives: 480.0147 - loss: 0.4262 - precision: 0.7642 - recall: 0.8188 - true_negatives: 1943.5146 - true_positives: 1625.6177\n",
      "Epoch 220/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7908 - auc: 0.8777 - false_negatives: 385.1667 - false_positives: 480.8788 - loss: 0.4516 - precision: 0.7507 - recall: 0.8072 - true_negatives: 1872.6970 - true_positives: 1549.2576\n",
      "Epoch 220: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7912 - auc: 0.8778 - false_negatives: 395.6029 - false_positives: 494.2059 - loss: 0.4513 - precision: 0.7512 - recall: 0.8072 - true_negatives: 1929.3235 - true_positives: 1594.5441\n",
      "Epoch 221/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8053 - auc: 0.8883 - false_negatives: 354.3485 - false_positives: 474.2424 - loss: 0.4302 - precision: 0.7631 - recall: 0.8245 - true_negatives: 1879.3334 - true_positives: 1580.0758\n",
      "Epoch 221: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8053 - auc: 0.8883 - false_negatives: 364.4265 - false_positives: 488.0588 - loss: 0.4302 - precision: 0.7632 - recall: 0.8243 - true_negatives: 1935.4706 - true_positives: 1625.7206\n",
      "Epoch 222/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8165 - auc: 0.8926 - false_negatives: 351.7612 - false_positives: 443.8507 - loss: 0.4214 - precision: 0.7841 - recall: 0.8153 - true_negatives: 1945.2239 - true_positives: 1610.9403\n",
      "Epoch 222: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8165 - auc: 0.8926 - false_negatives: 356.6324 - false_positives: 450.3382 - loss: 0.4214 - precision: 0.7841 - recall: 0.8154 - true_negatives: 1973.1912 - true_positives: 1633.5146\n",
      "Epoch 223/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8130 - auc: 0.8921 - false_negatives: 342.2836 - false_positives: 461.6716 - loss: 0.4219 - precision: 0.7746 - recall: 0.8226 - true_negatives: 1927.4030 - true_positives: 1620.4180\n",
      "Epoch 223: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8130 - auc: 0.8921 - false_negatives: 346.9706 - false_positives: 468.2647 - loss: 0.4219 - precision: 0.7746 - recall: 0.8227 - true_negatives: 1955.2646 - true_positives: 1643.1765\n",
      "Epoch 224/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8110 - auc: 0.8946 - false_negatives: 360.8657 - false_positives: 450.5075 - loss: 0.4167 - precision: 0.7772 - recall: 0.8111 - true_negatives: 1938.5671 - true_positives: 1601.8358\n",
      "Epoch 224: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8110 - auc: 0.8946 - false_negatives: 365.7500 - false_positives: 457.1029 - loss: 0.4167 - precision: 0.7772 - recall: 0.8113 - true_negatives: 1966.4265 - true_positives: 1624.3971\n",
      "Epoch 225/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8197 - auc: 0.8934 - false_negatives: 348.9394 - false_positives: 426.3636 - loss: 0.4198 - precision: 0.7886 - recall: 0.8171 - true_negatives: 1927.2122 - true_positives: 1585.4849\n",
      "Epoch 225: loss did not improve from 0.41578\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8197 - auc: 0.8935 - false_negatives: 358.8824 - false_positives: 439.0588 - loss: 0.4197 - precision: 0.7885 - recall: 0.8172 - true_negatives: 1984.4706 - true_positives: 1631.2646\n",
      "Epoch 226/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8210 - auc: 0.8964 - false_negatives: 340.8788 - false_positives: 429.1667 - loss: 0.4139 - precision: 0.7871 - recall: 0.8245 - true_negatives: 1924.4091 - true_positives: 1593.5454\n",
      "Epoch 226: loss improved from 0.41578 to 0.41543, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8209 - auc: 0.8963 - false_negatives: 350.7647 - false_positives: 442.4853 - loss: 0.4140 - precision: 0.7869 - recall: 0.8244 - true_negatives: 1981.0441 - true_positives: 1639.3823\n",
      "Epoch 227/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8188 - auc: 0.8973 - false_negatives: 350.5909 - false_positives: 422.0000 - loss: 0.4117 - precision: 0.7882 - recall: 0.8156 - true_negatives: 1931.5758 - true_positives: 1583.8334\n",
      "Epoch 227: loss improved from 0.41543 to 0.41024, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8189 - auc: 0.8973 - false_negatives: 360.1618 - false_positives: 434.5000 - loss: 0.4117 - precision: 0.7882 - recall: 0.8158 - true_negatives: 1989.0294 - true_positives: 1629.9854\n",
      "Epoch 228/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8114 - auc: 0.8951 - false_negatives: 341.5454 - false_positives: 462.7273 - loss: 0.4177 - precision: 0.7697 - recall: 0.8289 - true_negatives: 1890.8485 - true_positives: 1592.8788\n",
      "Epoch 228: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8114 - auc: 0.8952 - false_negatives: 351.5294 - false_positives: 476.0882 - loss: 0.4177 - precision: 0.7699 - recall: 0.8287 - true_negatives: 1947.4412 - true_positives: 1638.6177\n",
      "Epoch 229/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8120 - auc: 0.8963 - false_negatives: 348.4925 - false_positives: 460.5075 - loss: 0.4136 - precision: 0.7760 - recall: 0.8160 - true_negatives: 1928.5671 - true_positives: 1614.2090\n",
      "Epoch 229: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8120 - auc: 0.8963 - false_negatives: 353.1471 - false_positives: 467.2059 - loss: 0.4136 - precision: 0.7760 - recall: 0.8162 - true_negatives: 1956.3235 - true_positives: 1637.0000\n",
      "Epoch 230/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8177 - auc: 0.8939 - false_negatives: 360.8955 - false_positives: 431.7463 - loss: 0.4186 - precision: 0.7884 - recall: 0.8126 - true_negatives: 1957.3284 - true_positives: 1601.8060\n",
      "Epoch 230: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8178 - auc: 0.8939 - false_negatives: 365.6912 - false_positives: 438.0735 - loss: 0.4185 - precision: 0.7883 - recall: 0.8127 - true_negatives: 1985.4559 - true_positives: 1624.4559\n",
      "Epoch 231/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8039 - auc: 0.8892 - false_negatives: 353.8788 - false_positives: 463.9546 - loss: 0.4313 - precision: 0.7624 - recall: 0.8240 - true_negatives: 1889.6212 - true_positives: 1580.5454\n",
      "Epoch 231: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8042 - auc: 0.8893 - false_negatives: 363.8824 - false_positives: 477.2794 - loss: 0.4309 - precision: 0.7627 - recall: 0.8239 - true_negatives: 1946.2500 - true_positives: 1626.2646\n",
      "Epoch 232/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8159 - auc: 0.8940 - false_negatives: 337.0000 - false_positives: 430.2462 - loss: 0.4196 - precision: 0.7781 - recall: 0.8270 - true_negatives: 1887.9385 - true_positives: 1568.8154\n",
      "Epoch 232: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8160 - auc: 0.8940 - false_negatives: 351.6176 - false_positives: 449.8382 - loss: 0.4195 - precision: 0.7783 - recall: 0.8269 - true_negatives: 1973.6912 - true_positives: 1638.5294\n",
      "Epoch 233/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8075 - auc: 0.8926 - false_negatives: 367.0000 - false_positives: 445.0454 - loss: 0.4206 - precision: 0.7770 - recall: 0.8004 - true_negatives: 1908.5303 - true_positives: 1567.4242\n",
      "Epoch 233: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8077 - auc: 0.8926 - false_negatives: 376.7647 - false_positives: 458.4559 - loss: 0.4205 - precision: 0.7770 - recall: 0.8009 - true_negatives: 1965.0735 - true_positives: 1613.3823\n",
      "Epoch 234/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8259 - auc: 0.8979 - false_negatives: 327.1364 - false_positives: 423.5909 - loss: 0.4117 - precision: 0.7901 - recall: 0.8339 - true_negatives: 1929.9849 - true_positives: 1607.2878\n",
      "Epoch 234: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8258 - auc: 0.8979 - false_negatives: 337.1912 - false_positives: 436.6324 - loss: 0.4117 - precision: 0.7900 - recall: 0.8337 - true_negatives: 1986.8971 - true_positives: 1652.9559\n",
      "Epoch 235/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8118 - auc: 0.8969 - false_negatives: 346.1940 - false_positives: 466.7164 - loss: 0.4138 - precision: 0.7710 - recall: 0.8280 - true_negatives: 1922.3582 - true_positives: 1616.5074\n",
      "Epoch 235: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8119 - auc: 0.8968 - false_negatives: 351.0147 - false_positives: 473.3088 - loss: 0.4139 - precision: 0.7711 - recall: 0.8280 - true_negatives: 1950.2206 - true_positives: 1639.1323\n",
      "Epoch 236/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8186 - auc: 0.8981 - false_negatives: 347.2388 - false_positives: 448.3284 - loss: 0.4111 - precision: 0.7857 - recall: 0.8194 - true_negatives: 1940.7462 - true_positives: 1615.4626\n",
      "Epoch 236: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8186 - auc: 0.8981 - false_negatives: 351.9559 - false_positives: 454.8088 - loss: 0.4111 - precision: 0.7856 - recall: 0.8195 - true_negatives: 1968.7206 - true_positives: 1638.1912\n",
      "Epoch 237/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8198 - auc: 0.8980 - false_negatives: 346.6418 - false_positives: 444.6269 - loss: 0.4121 - precision: 0.7841 - recall: 0.8268 - true_negatives: 1944.4478 - true_positives: 1616.0597\n",
      "Epoch 237: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8198 - auc: 0.8980 - false_negatives: 351.5735 - false_positives: 451.1618 - loss: 0.4121 - precision: 0.7840 - recall: 0.8267 - true_negatives: 1972.3677 - true_positives: 1638.5735\n",
      "Epoch 238/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8161 - auc: 0.8963 - false_negatives: 336.1212 - false_positives: 439.8940 - loss: 0.4143 - precision: 0.7777 - recall: 0.8273 - true_negatives: 1913.6818 - true_positives: 1598.3030\n",
      "Epoch 238: loss did not improve from 0.41024\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8162 - auc: 0.8963 - false_negatives: 345.7647 - false_positives: 452.9559 - loss: 0.4142 - precision: 0.7778 - recall: 0.8273 - true_negatives: 1970.5735 - true_positives: 1644.3823\n",
      "Epoch 239/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8221 - auc: 0.9014 - false_negatives: 354.0000 - false_positives: 422.9552 - loss: 0.4043 - precision: 0.7921 - recall: 0.8182 - true_negatives: 1966.1194 - true_positives: 1608.7015\n",
      "Epoch 239: loss improved from 0.41024 to 0.40976, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8220 - auc: 0.9014 - false_negatives: 358.8824 - false_positives: 429.5147 - loss: 0.4044 - precision: 0.7920 - recall: 0.8183 - true_negatives: 1994.0146 - true_positives: 1631.2646\n",
      "Epoch 240/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8162 - auc: 0.8942 - false_negatives: 348.7164 - false_positives: 445.1642 - loss: 0.4191 - precision: 0.7808 - recall: 0.8219 - true_negatives: 1943.9104 - true_positives: 1613.9851\n",
      "Epoch 240: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8162 - auc: 0.8942 - false_negatives: 353.4118 - false_positives: 451.7353 - loss: 0.4190 - precision: 0.7807 - recall: 0.8220 - true_negatives: 1971.7941 - true_positives: 1636.7354\n",
      "Epoch 241/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8180 - auc: 0.8950 - false_negatives: 355.8209 - false_positives: 447.4328 - loss: 0.4164 - precision: 0.7852 - recall: 0.8190 - true_negatives: 1941.6418 - true_positives: 1606.8806\n",
      "Epoch 241: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8179 - auc: 0.8949 - false_negatives: 360.6912 - false_positives: 454.3529 - loss: 0.4166 - precision: 0.7851 - recall: 0.8191 - true_negatives: 1969.1765 - true_positives: 1629.4559\n",
      "Epoch 242/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8113 - auc: 0.8887 - false_negatives: 373.2985 - false_positives: 454.7015 - loss: 0.4273 - precision: 0.7786 - recall: 0.8112 - true_negatives: 1934.3732 - true_positives: 1589.4030\n",
      "Epoch 242: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8113 - auc: 0.8886 - false_negatives: 378.5294 - false_positives: 461.6471 - loss: 0.4274 - precision: 0.7785 - recall: 0.8112 - true_negatives: 1961.8823 - true_positives: 1611.6177\n",
      "Epoch 243/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8065 - auc: 0.8900 - false_negatives: 356.2836 - false_positives: 463.1493 - loss: 0.4276 - precision: 0.7654 - recall: 0.8246 - true_negatives: 1925.9254 - true_positives: 1606.4180\n",
      "Epoch 243: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8066 - auc: 0.8900 - false_negatives: 361.3088 - false_positives: 469.5294 - loss: 0.4275 - precision: 0.7656 - recall: 0.8245 - true_negatives: 1954.0000 - true_positives: 1628.8383\n",
      "Epoch 244/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8088 - auc: 0.8917 - false_negatives: 371.9394 - false_positives: 440.8030 - loss: 0.4222 - precision: 0.7792 - recall: 0.8001 - true_negatives: 1912.7727 - true_positives: 1562.4849\n",
      "Epoch 244: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8088 - auc: 0.8918 - false_negatives: 382.3235 - false_positives: 454.3382 - loss: 0.4221 - precision: 0.7791 - recall: 0.8004 - true_negatives: 1969.1912 - true_positives: 1607.8235\n",
      "Epoch 245/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8150 - auc: 0.8953 - false_negatives: 353.2273 - false_positives: 432.0909 - loss: 0.4156 - precision: 0.7815 - recall: 0.8165 - true_negatives: 1921.4849 - true_positives: 1581.1970\n",
      "Epoch 245: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8151 - auc: 0.8953 - false_negatives: 363.3088 - false_positives: 445.0294 - loss: 0.4155 - precision: 0.7815 - recall: 0.8166 - true_negatives: 1978.5000 - true_positives: 1626.8383\n",
      "Epoch 246/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8156 - auc: 0.8951 - false_negatives: 365.5970 - false_positives: 436.6716 - loss: 0.4158 - precision: 0.7832 - recall: 0.8156 - true_negatives: 1952.4030 - true_positives: 1597.1045\n",
      "Epoch 246: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8156 - auc: 0.8951 - false_negatives: 370.7059 - false_positives: 443.1912 - loss: 0.4158 - precision: 0.7831 - recall: 0.8156 - true_negatives: 1980.3383 - true_positives: 1619.4412\n",
      "Epoch 247/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8024 - auc: 0.8910 - false_negatives: 375.2985 - false_positives: 458.3433 - loss: 0.4236 - precision: 0.7671 - recall: 0.8036 - true_negatives: 1930.7313 - true_positives: 1587.4030\n",
      "Epoch 247: loss did not improve from 0.40976\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8025 - auc: 0.8910 - false_negatives: 380.2206 - false_positives: 464.8235 - loss: 0.4235 - precision: 0.7672 - recall: 0.8037 - true_negatives: 1958.7059 - true_positives: 1609.9265\n",
      "Epoch 248/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8234 - auc: 0.8988 - false_negatives: 338.2388 - false_positives: 423.1493 - loss: 0.4097 - precision: 0.7916 - recall: 0.8230 - true_negatives: 1965.9254 - true_positives: 1624.4626\n",
      "Epoch 248: loss improved from 0.40976 to 0.40851, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8235 - auc: 0.8988 - false_negatives: 342.6471 - false_positives: 429.4853 - loss: 0.4096 - precision: 0.7916 - recall: 0.8231 - true_negatives: 1994.0441 - true_positives: 1647.5000\n",
      "Epoch 249/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8221 - auc: 0.8976 - false_negatives: 342.7273 - false_positives: 419.6818 - loss: 0.4122 - precision: 0.7946 - recall: 0.8139 - true_negatives: 1933.8939 - true_positives: 1591.6970\n",
      "Epoch 249: loss improved from 0.40851 to 0.40816, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8221 - auc: 0.8976 - false_negatives: 352.1176 - false_positives: 432.6912 - loss: 0.4120 - precision: 0.7943 - recall: 0.8143 - true_negatives: 1990.8383 - true_positives: 1638.0294\n",
      "Epoch 250/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8232 - auc: 0.8983 - false_negatives: 332.1364 - false_positives: 430.1667 - loss: 0.4108 - precision: 0.7874 - recall: 0.8310 - true_negatives: 1923.4091 - true_positives: 1602.2878\n",
      "Epoch 250: loss did not improve from 0.40816\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8232 - auc: 0.8983 - false_negatives: 341.7206 - false_positives: 443.4265 - loss: 0.4108 - precision: 0.7873 - recall: 0.8309 - true_negatives: 1980.1029 - true_positives: 1648.4265\n",
      "Epoch 251/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8256 - auc: 0.9002 - false_negatives: 342.3182 - false_positives: 413.9243 - loss: 0.4068 - precision: 0.7960 - recall: 0.8225 - true_negatives: 1939.6515 - true_positives: 1592.1061\n",
      "Epoch 251: loss improved from 0.40816 to 0.40462, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8255 - auc: 0.9002 - false_negatives: 351.7794 - false_positives: 427.0147 - loss: 0.4067 - precision: 0.7957 - recall: 0.8226 - true_negatives: 1996.5146 - true_positives: 1638.3677\n",
      "Epoch 252/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8242 - auc: 0.9029 - false_negatives: 338.1818 - false_positives: 416.0757 - loss: 0.4007 - precision: 0.7923 - recall: 0.8243 - true_negatives: 1937.5000 - true_positives: 1596.2424\n",
      "Epoch 252: loss improved from 0.40462 to 0.40425, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8241 - auc: 0.9028 - false_negatives: 347.5000 - false_positives: 429.1029 - loss: 0.4008 - precision: 0.7921 - recall: 0.8244 - true_negatives: 1994.4265 - true_positives: 1642.6471\n",
      "Epoch 253/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8192 - auc: 0.8977 - false_negatives: 340.2576 - false_positives: 423.9849 - loss: 0.4118 - precision: 0.7862 - recall: 0.8205 - true_negatives: 1929.5909 - true_positives: 1594.1666\n",
      "Epoch 253: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8193 - auc: 0.8978 - false_negatives: 349.6324 - false_positives: 436.8088 - loss: 0.4117 - precision: 0.7862 - recall: 0.8207 - true_negatives: 1986.7206 - true_positives: 1640.5146\n",
      "Epoch 254/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8047 - auc: 0.8932 - false_negatives: 360.2836 - false_positives: 464.9552 - loss: 0.4211 - precision: 0.7644 - recall: 0.8198 - true_negatives: 1924.1194 - true_positives: 1602.4180\n",
      "Epoch 254: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8049 - auc: 0.8933 - false_negatives: 365.1176 - false_positives: 471.4706 - loss: 0.4209 - precision: 0.7646 - recall: 0.8199 - true_negatives: 1952.0588 - true_positives: 1625.0294\n",
      "Epoch 255/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8172 - auc: 0.8955 - false_negatives: 352.0909 - false_positives: 420.9849 - loss: 0.4153 - precision: 0.7888 - recall: 0.8086 - true_negatives: 1932.5909 - true_positives: 1582.3334\n",
      "Epoch 255: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8173 - auc: 0.8956 - false_negatives: 361.4706 - false_positives: 434.3382 - loss: 0.4152 - precision: 0.7886 - recall: 0.8090 - true_negatives: 1989.1912 - true_positives: 1628.6765\n",
      "Epoch 256/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8158 - auc: 0.8971 - false_negatives: 354.6418 - false_positives: 450.3134 - loss: 0.4127 - precision: 0.7795 - recall: 0.8221 - true_negatives: 1938.7612 - true_positives: 1608.0597\n",
      "Epoch 256: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8157 - auc: 0.8970 - false_negatives: 359.5294 - false_positives: 457.1324 - loss: 0.4128 - precision: 0.7794 - recall: 0.8221 - true_negatives: 1966.3971 - true_positives: 1630.6177\n",
      "Epoch 257/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8162 - auc: 0.8990 - false_negatives: 344.3182 - false_positives: 439.5000 - loss: 0.4093 - precision: 0.7796 - recall: 0.8237 - true_negatives: 1914.0758 - true_positives: 1590.1061\n",
      "Epoch 257: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8162 - auc: 0.8990 - false_negatives: 353.8676 - false_positives: 453.0147 - loss: 0.4094 - precision: 0.7796 - recall: 0.8237 - true_negatives: 1970.5146 - true_positives: 1636.2794\n",
      "Epoch 258/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8143 - auc: 0.8979 - false_negatives: 351.6667 - false_positives: 440.4697 - loss: 0.4106 - precision: 0.7838 - recall: 0.8092 - true_negatives: 1913.1061 - true_positives: 1582.7576\n",
      "Epoch 258: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8144 - auc: 0.8979 - false_negatives: 361.1176 - false_positives: 454.1912 - loss: 0.4106 - precision: 0.7836 - recall: 0.8096 - true_negatives: 1969.3383 - true_positives: 1629.0294\n",
      "Epoch 259/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8066 - auc: 0.8913 - false_negatives: 357.8182 - false_positives: 448.0000 - loss: 0.4224 - precision: 0.7704 - recall: 0.8106 - true_negatives: 1905.5758 - true_positives: 1576.6061\n",
      "Epoch 259: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8069 - auc: 0.8914 - false_negatives: 367.6176 - false_positives: 461.2059 - loss: 0.4222 - precision: 0.7706 - recall: 0.8109 - true_negatives: 1962.3235 - true_positives: 1622.5294\n",
      "Epoch 260/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8142 - auc: 0.8950 - false_negatives: 337.2239 - false_positives: 456.5075 - loss: 0.4167 - precision: 0.7755 - recall: 0.8249 - true_negatives: 1932.5671 - true_positives: 1625.4777\n",
      "Epoch 260: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8143 - auc: 0.8951 - false_negatives: 341.7941 - false_positives: 463.0294 - loss: 0.4166 - precision: 0.7756 - recall: 0.8250 - true_negatives: 1960.5000 - true_positives: 1648.3529\n",
      "Epoch 261/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8048 - auc: 0.8952 - false_negatives: 361.5821 - false_positives: 469.6866 - loss: 0.4155 - precision: 0.7655 - recall: 0.8157 - true_negatives: 1919.3881 - true_positives: 1601.1194\n",
      "Epoch 261: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8049 - auc: 0.8952 - false_negatives: 366.6176 - false_positives: 476.2794 - loss: 0.4155 - precision: 0.7656 - recall: 0.8157 - true_negatives: 1947.2500 - true_positives: 1623.5294\n",
      "Epoch 262/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8147 - auc: 0.8938 - false_negatives: 356.6364 - false_positives: 444.5757 - loss: 0.4188 - precision: 0.7806 - recall: 0.8166 - true_negatives: 1909.0000 - true_positives: 1577.7878\n",
      "Epoch 262: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8147 - auc: 0.8938 - false_negatives: 366.7941 - false_positives: 457.7941 - loss: 0.4188 - precision: 0.7806 - recall: 0.8166 - true_negatives: 1965.7354 - true_positives: 1623.3529\n",
      "Epoch 263/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8048 - auc: 0.8903 - false_negatives: 337.9552 - false_positives: 501.3284 - loss: 0.4242 - precision: 0.7587 - recall: 0.8288 - true_negatives: 1887.7462 - true_positives: 1624.7462\n",
      "Epoch 263: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8049 - auc: 0.8903 - false_negatives: 342.7206 - false_positives: 508.2647 - loss: 0.4241 - precision: 0.7588 - recall: 0.8288 - true_negatives: 1915.2646 - true_positives: 1647.4265\n",
      "Epoch 264/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8062 - auc: 0.8897 - false_negatives: 384.1045 - false_positives: 452.2537 - loss: 0.4296 - precision: 0.7878 - recall: 0.7813 - true_negatives: 1936.8209 - true_positives: 1578.5970\n",
      "Epoch 264: loss did not improve from 0.40425\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8063 - auc: 0.8897 - false_negatives: 388.7794 - false_positives: 458.8971 - loss: 0.4295 - precision: 0.7876 - recall: 0.7818 - true_negatives: 1964.6323 - true_positives: 1601.3677\n",
      "Epoch 265/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8214 - auc: 0.9015 - false_negatives: 331.4478 - false_positives: 441.8955 - loss: 0.4042 - precision: 0.7883 - recall: 0.8227 - true_negatives: 1947.1791 - true_positives: 1631.2538\n",
      "Epoch 265: loss improved from 0.40425 to 0.40264, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8214 - auc: 0.9015 - false_negatives: 335.9412 - false_positives: 448.3088 - loss: 0.4041 - precision: 0.7882 - recall: 0.8229 - true_negatives: 1975.2206 - true_positives: 1654.2059\n",
      "Epoch 266/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8198 - auc: 0.8978 - false_negatives: 352.8806 - false_positives: 433.7612 - loss: 0.4131 - precision: 0.7948 - recall: 0.8081 - true_negatives: 1955.3135 - true_positives: 1609.8209\n",
      "Epoch 266: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8198 - auc: 0.8978 - false_negatives: 357.4265 - false_positives: 440.3676 - loss: 0.4131 - precision: 0.7946 - recall: 0.8083 - true_negatives: 1983.1617 - true_positives: 1632.7206\n",
      "Epoch 267/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8193 - auc: 0.9021 - false_negatives: 348.4776 - false_positives: 437.6418 - loss: 0.4026 - precision: 0.7899 - recall: 0.8137 - true_negatives: 1951.4329 - true_positives: 1614.2239\n",
      "Epoch 267: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8193 - auc: 0.9021 - false_negatives: 353.4265 - false_positives: 444.0735 - loss: 0.4026 - precision: 0.7898 - recall: 0.8139 - true_negatives: 1979.4559 - true_positives: 1636.7206\n",
      "Epoch 268/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8196 - auc: 0.9026 - false_negatives: 330.6212 - false_positives: 440.2424 - loss: 0.4021 - precision: 0.7857 - recall: 0.8222 - true_negatives: 1913.3334 - true_positives: 1603.8030\n",
      "Epoch 268: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8197 - auc: 0.9026 - false_negatives: 339.4559 - false_positives: 453.4412 - loss: 0.4021 - precision: 0.7856 - recall: 0.8226 - true_negatives: 1970.0883 - true_positives: 1650.6912\n",
      "Epoch 269/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8085 - auc: 0.8926 - false_negatives: 382.9394 - false_positives: 435.6667 - loss: 0.4264 - precision: 0.7902 - recall: 0.7827 - true_negatives: 1917.9091 - true_positives: 1551.4849\n",
      "Epoch 269: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8086 - auc: 0.8926 - false_negatives: 393.0588 - false_positives: 449.3824 - loss: 0.4264 - precision: 0.7897 - recall: 0.7835 - true_negatives: 1974.1471 - true_positives: 1597.0883\n",
      "Epoch 270/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8111 - auc: 0.8948 - false_negatives: 346.7727 - false_positives: 454.1970 - loss: 0.4170 - precision: 0.7720 - recall: 0.8232 - true_negatives: 1899.3788 - true_positives: 1587.6515\n",
      "Epoch 270: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8111 - auc: 0.8947 - false_negatives: 356.6912 - false_positives: 467.6912 - loss: 0.4171 - precision: 0.7721 - recall: 0.8231 - true_negatives: 1955.8383 - true_positives: 1633.4559\n",
      "Epoch 271/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8163 - auc: 0.8993 - false_negatives: 368.3284 - false_positives: 437.4478 - loss: 0.4094 - precision: 0.7939 - recall: 0.7992 - true_negatives: 1951.6268 - true_positives: 1594.3732\n",
      "Epoch 271: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8163 - auc: 0.8993 - false_negatives: 373.2500 - false_positives: 444.2059 - loss: 0.4094 - precision: 0.7937 - recall: 0.7994 - true_negatives: 1979.3235 - true_positives: 1616.8971\n",
      "Epoch 272/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8232 - auc: 0.9014 - false_negatives: 343.2388 - false_positives: 432.3134 - loss: 0.4043 - precision: 0.7939 - recall: 0.8188 - true_negatives: 1956.7612 - true_positives: 1619.4626\n",
      "Epoch 272: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8231 - auc: 0.9014 - false_negatives: 347.9559 - false_positives: 438.9118 - loss: 0.4043 - precision: 0.7937 - recall: 0.8189 - true_negatives: 1984.6177 - true_positives: 1642.1912\n",
      "Epoch 273/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8244 - auc: 0.9010 - false_negatives: 335.1077 - false_positives: 406.1077 - loss: 0.4065 - precision: 0.7994 - recall: 0.8127 - true_negatives: 1912.0769 - true_positives: 1570.7076\n",
      "Epoch 273: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8244 - auc: 0.9011 - false_negatives: 348.9118 - false_positives: 425.9265 - loss: 0.4064 - precision: 0.7988 - recall: 0.8135 - true_negatives: 1997.6029 - true_positives: 1641.2354\n",
      "Epoch 274/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8309 - auc: 0.9053 - false_negatives: 323.8485 - false_positives: 413.3182 - loss: 0.3972 - precision: 0.8019 - recall: 0.8282 - true_negatives: 1940.2576 - true_positives: 1610.5758\n",
      "Epoch 274: loss did not improve from 0.40264\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8307 - auc: 0.9052 - false_negatives: 333.0294 - false_positives: 426.5735 - loss: 0.3974 - precision: 0.8014 - recall: 0.8284 - true_negatives: 1996.9559 - true_positives: 1657.1177\n",
      "Epoch 275/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8280 - auc: 0.9075 - false_negatives: 328.5000 - false_positives: 410.6970 - loss: 0.3922 - precision: 0.7972 - recall: 0.8276 - true_negatives: 1942.8788 - true_positives: 1605.9242\n",
      "Epoch 275: loss improved from 0.40264 to 0.39571, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8279 - auc: 0.9074 - false_negatives: 337.5441 - false_positives: 423.8235 - loss: 0.3923 - precision: 0.7969 - recall: 0.8278 - true_negatives: 1999.7059 - true_positives: 1652.6029\n",
      "Epoch 276/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8299 - auc: 0.9046 - false_negatives: 329.1364 - false_positives: 413.6060 - loss: 0.3988 - precision: 0.7992 - recall: 0.8295 - true_negatives: 1939.9697 - true_positives: 1605.2878\n",
      "Epoch 276: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8297 - auc: 0.9045 - false_negatives: 338.8676 - false_positives: 426.8529 - loss: 0.3989 - precision: 0.7988 - recall: 0.8295 - true_negatives: 1996.6765 - true_positives: 1651.2794\n",
      "Epoch 277/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8109 - auc: 0.8984 - false_negatives: 345.9243 - false_positives: 452.4243 - loss: 0.4098 - precision: 0.7739 - recall: 0.8180 - true_negatives: 1901.1515 - true_positives: 1588.5000\n",
      "Epoch 277: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8109 - auc: 0.8983 - false_negatives: 355.3382 - false_positives: 466.6471 - loss: 0.4100 - precision: 0.7739 - recall: 0.8183 - true_negatives: 1956.8823 - true_positives: 1634.8088\n",
      "Epoch 278/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8295 - auc: 0.9043 - false_negatives: 335.7879 - false_positives: 411.1364 - loss: 0.3985 - precision: 0.7994 - recall: 0.8281 - true_negatives: 1942.4395 - true_positives: 1598.6364\n",
      "Epoch 278: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8293 - auc: 0.9043 - false_negatives: 345.2941 - false_positives: 424.1912 - loss: 0.3987 - precision: 0.7990 - recall: 0.8281 - true_negatives: 1999.3383 - true_positives: 1644.8529\n",
      "Epoch 279/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8309 - auc: 0.9083 - false_negatives: 317.6418 - false_positives: 432.1343 - loss: 0.3901 - precision: 0.7950 - recall: 0.8400 - true_negatives: 1956.9403 - true_positives: 1645.0597\n",
      "Epoch 279: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8308 - auc: 0.9083 - false_negatives: 322.1029 - false_positives: 438.9412 - loss: 0.3902 - precision: 0.7948 - recall: 0.8400 - true_negatives: 1984.5883 - true_positives: 1668.0441\n",
      "Epoch 280/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8302 - auc: 0.9087 - false_negatives: 334.0298 - false_positives: 410.7164 - loss: 0.3901 - precision: 0.8023 - recall: 0.8250 - true_negatives: 1978.3582 - true_positives: 1628.6716\n",
      "Epoch 280: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8301 - auc: 0.9087 - false_negatives: 338.4559 - false_positives: 417.1765 - loss: 0.3902 - precision: 0.8021 - recall: 0.8252 - true_negatives: 2006.3529 - true_positives: 1651.6912\n",
      "Epoch 281/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8266 - auc: 0.9075 - false_negatives: 345.1791 - false_positives: 408.1493 - loss: 0.3924 - precision: 0.8028 - recall: 0.8140 - true_negatives: 1980.9254 - true_positives: 1617.5223\n",
      "Epoch 281: loss did not improve from 0.39571\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8266 - auc: 0.9074 - false_negatives: 349.7059 - false_positives: 414.4853 - loss: 0.3924 - precision: 0.8026 - recall: 0.8142 - true_negatives: 2009.0441 - true_positives: 1640.4412\n",
      "Epoch 282/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8291 - auc: 0.9110 - false_negatives: 315.1060 - false_positives: 418.9849 - loss: 0.3851 - precision: 0.7939 - recall: 0.8365 - true_negatives: 1934.5909 - true_positives: 1619.3182\n",
      "Epoch 282: loss improved from 0.39571 to 0.39569, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8289 - auc: 0.9108 - false_negatives: 324.3382 - false_positives: 432.6618 - loss: 0.3854 - precision: 0.7936 - recall: 0.8365 - true_negatives: 1990.8677 - true_positives: 1665.8088\n",
      "Epoch 283/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8279 - auc: 0.9073 - false_negatives: 336.9403 - false_positives: 413.0746 - loss: 0.3926 - precision: 0.7990 - recall: 0.8235 - true_negatives: 1976.0000 - true_positives: 1625.7612\n",
      "Epoch 283: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8279 - auc: 0.9072 - false_negatives: 341.6618 - false_positives: 419.4118 - loss: 0.3927 - precision: 0.7989 - recall: 0.8235 - true_negatives: 2004.1177 - true_positives: 1648.4854\n",
      "Epoch 284/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8195 - auc: 0.9037 - false_negatives: 336.1045 - false_positives: 442.2537 - loss: 0.4011 - precision: 0.7818 - recall: 0.8308 - true_negatives: 1946.8209 - true_positives: 1626.5970\n",
      "Epoch 284: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8195 - auc: 0.9036 - false_negatives: 340.8971 - false_positives: 449.2794 - loss: 0.4012 - precision: 0.7817 - recall: 0.8307 - true_negatives: 1974.2500 - true_positives: 1649.2500\n",
      "Epoch 285/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8282 - auc: 0.9052 - false_negatives: 352.6716 - false_positives: 400.5224 - loss: 0.3969 - precision: 0.8000 - recall: 0.8232 - true_negatives: 1988.5522 - true_positives: 1610.0299\n",
      "Epoch 285: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8281 - auc: 0.9051 - false_negatives: 357.9118 - false_positives: 406.8529 - loss: 0.3971 - precision: 0.7998 - recall: 0.8230 - true_negatives: 2016.6765 - true_positives: 1632.2354\n",
      "Epoch 286/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8221 - auc: 0.9028 - false_negatives: 324.7164 - false_positives: 449.6567 - loss: 0.4028 - precision: 0.7798 - recall: 0.8421 - true_negatives: 1939.4180 - true_positives: 1637.9851\n",
      "Epoch 286: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8221 - auc: 0.9028 - false_negatives: 329.2059 - false_positives: 456.3088 - loss: 0.4029 - precision: 0.7799 - recall: 0.8420 - true_negatives: 1967.2206 - true_positives: 1660.9412\n",
      "Epoch 287/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8254 - auc: 0.9076 - false_negatives: 340.0000 - false_positives: 417.4925 - loss: 0.3925 - precision: 0.7930 - recall: 0.8273 - true_negatives: 1971.5820 - true_positives: 1622.7015\n",
      "Epoch 287: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8253 - auc: 0.9075 - false_negatives: 344.7500 - false_positives: 424.1324 - loss: 0.3927 - precision: 0.7929 - recall: 0.8273 - true_negatives: 1999.3971 - true_positives: 1645.3971\n",
      "Epoch 288/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8241 - auc: 0.9075 - false_negatives: 313.8485 - false_positives: 431.4546 - loss: 0.3927 - precision: 0.7855 - recall: 0.8369 - true_negatives: 1922.1212 - true_positives: 1620.5758\n",
      "Epoch 288: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8240 - auc: 0.9074 - false_negatives: 323.0294 - false_positives: 445.2059 - loss: 0.3929 - precision: 0.7854 - recall: 0.8369 - true_negatives: 1978.3235 - true_positives: 1667.1177\n",
      "Epoch 289/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8316 - auc: 0.9063 - false_negatives: 326.8940 - false_positives: 406.0454 - loss: 0.3950 - precision: 0.8056 - recall: 0.8241 - true_negatives: 1947.5303 - true_positives: 1607.5303\n",
      "Epoch 289: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8313 - auc: 0.9062 - false_negatives: 336.0735 - false_positives: 419.9265 - loss: 0.3952 - precision: 0.8050 - recall: 0.8243 - true_negatives: 2003.6029 - true_positives: 1654.0735\n",
      "Epoch 290/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8267 - auc: 0.9052 - false_negatives: 334.7314 - false_positives: 419.3881 - loss: 0.3965 - precision: 0.7952 - recall: 0.8264 - true_negatives: 1969.6865 - true_positives: 1627.9701\n",
      "Epoch 290: loss did not improve from 0.39569\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8266 - auc: 0.9052 - false_negatives: 339.2059 - false_positives: 426.0000 - loss: 0.3966 - precision: 0.7951 - recall: 0.8265 - true_negatives: 1997.5294 - true_positives: 1650.9412\n",
      "Epoch 291/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8264 - auc: 0.9113 - false_negatives: 319.5672 - false_positives: 421.6269 - loss: 0.3855 - precision: 0.7886 - recall: 0.8392 - true_negatives: 1967.4478 - true_positives: 1643.1343\n",
      "Epoch 291: loss improved from 0.39569 to 0.38792, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8264 - auc: 0.9113 - false_negatives: 324.0294 - false_positives: 427.8824 - loss: 0.3855 - precision: 0.7887 - recall: 0.8392 - true_negatives: 1995.6471 - true_positives: 1666.1177\n",
      "Epoch 292/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8292 - auc: 0.9074 - false_negatives: 319.1212 - false_positives: 414.1364 - loss: 0.3930 - precision: 0.7967 - recall: 0.8312 - true_negatives: 1939.4395 - true_positives: 1615.3030\n",
      "Epoch 292: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8292 - auc: 0.9074 - false_negatives: 328.2059 - false_positives: 426.9265 - loss: 0.3930 - precision: 0.7966 - recall: 0.8314 - true_negatives: 1996.6029 - true_positives: 1661.9412\n",
      "Epoch 293/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8335 - auc: 0.9138 - false_negatives: 329.6866 - false_positives: 402.4627 - loss: 0.3788 - precision: 0.8047 - recall: 0.8304 - true_negatives: 1986.6119 - true_positives: 1633.0149\n",
      "Epoch 293: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8334 - auc: 0.9138 - false_negatives: 334.2500 - false_positives: 409.0147 - loss: 0.3790 - precision: 0.8045 - recall: 0.8305 - true_negatives: 2014.5146 - true_positives: 1655.8971\n",
      "Epoch 294/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8333 - auc: 0.9105 - false_negatives: 321.9849 - false_positives: 407.1060 - loss: 0.3858 - precision: 0.8031 - recall: 0.8331 - true_negatives: 1946.4697 - true_positives: 1612.4395\n",
      "Epoch 294: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8331 - auc: 0.9104 - false_negatives: 331.0735 - false_positives: 420.6029 - loss: 0.3860 - precision: 0.8026 - recall: 0.8332 - true_negatives: 2002.9265 - true_positives: 1659.0735\n",
      "Epoch 295/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8359 - auc: 0.9113 - false_negatives: 313.6418 - false_positives: 404.1194 - loss: 0.3846 - precision: 0.8027 - recall: 0.8416 - true_negatives: 1984.9552 - true_positives: 1649.0597\n",
      "Epoch 295: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8358 - auc: 0.9112 - false_negatives: 318.2206 - false_positives: 410.5882 - loss: 0.3847 - precision: 0.8025 - recall: 0.8415 - true_negatives: 2012.9412 - true_positives: 1671.9265\n",
      "Epoch 296/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8347 - auc: 0.9127 - false_negatives: 303.2537 - false_positives: 418.0895 - loss: 0.3817 - precision: 0.7977 - recall: 0.8468 - true_negatives: 1970.9851 - true_positives: 1659.4478\n",
      "Epoch 296: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8347 - auc: 0.9126 - false_negatives: 307.4118 - false_positives: 424.5588 - loss: 0.3818 - precision: 0.7976 - recall: 0.8468 - true_negatives: 1998.9706 - true_positives: 1682.7354\n",
      "Epoch 297/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8222 - auc: 0.9040 - false_negatives: 342.9403 - false_positives: 426.1791 - loss: 0.4011 - precision: 0.7883 - recall: 0.8271 - true_negatives: 1962.8955 - true_positives: 1619.7612\n",
      "Epoch 297: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8222 - auc: 0.9040 - false_negatives: 347.4265 - false_positives: 432.6765 - loss: 0.4011 - precision: 0.7883 - recall: 0.8271 - true_negatives: 1990.8529 - true_positives: 1642.7206\n",
      "Epoch 298/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8270 - auc: 0.9089 - false_negatives: 325.8940 - false_positives: 408.3485 - loss: 0.3895 - precision: 0.7930 - recall: 0.8322 - true_negatives: 1945.2273 - true_positives: 1608.5303\n",
      "Epoch 298: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8270 - auc: 0.9088 - false_negatives: 335.2500 - false_positives: 420.9853 - loss: 0.3897 - precision: 0.7930 - recall: 0.8322 - true_negatives: 2002.5441 - true_positives: 1654.8971\n",
      "Epoch 299/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8281 - auc: 0.9078 - false_negatives: 311.9702 - false_positives: 426.3134 - loss: 0.3914 - precision: 0.7901 - recall: 0.8401 - true_negatives: 1962.7612 - true_positives: 1650.7313\n",
      "Epoch 299: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8282 - auc: 0.9078 - false_negatives: 316.2647 - false_positives: 432.6324 - loss: 0.3914 - precision: 0.7901 - recall: 0.8402 - true_negatives: 1990.8971 - true_positives: 1673.8823\n",
      "Epoch 300/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8362 - auc: 0.9104 - false_negatives: 303.3433 - false_positives: 408.3433 - loss: 0.3866 - precision: 0.8007 - recall: 0.8453 - true_negatives: 1980.7313 - true_positives: 1659.3582\n",
      "Epoch 300: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8361 - auc: 0.9103 - false_negatives: 307.7647 - false_positives: 414.4559 - loss: 0.3866 - precision: 0.8007 - recall: 0.8453 - true_negatives: 2009.0735 - true_positives: 1682.3823\n",
      "Epoch 301/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8262 - auc: 0.9096 - false_negatives: 307.5606 - false_positives: 435.5151 - loss: 0.3884 - precision: 0.7847 - recall: 0.8446 - true_negatives: 1918.0605 - true_positives: 1626.8636\n",
      "Epoch 301: loss did not improve from 0.38792\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8261 - auc: 0.9095 - false_negatives: 316.7794 - false_positives: 448.7059 - loss: 0.3885 - precision: 0.7847 - recall: 0.8444 - true_negatives: 1974.8235 - true_positives: 1673.3677\n",
      "Epoch 302/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8342 - auc: 0.9143 - false_negatives: 295.1212 - false_positives: 415.4394 - loss: 0.3779 - precision: 0.7994 - recall: 0.8416 - true_negatives: 1938.1364 - true_positives: 1639.3030\n",
      "Epoch 302: loss improved from 0.38792 to 0.38293, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8342 - auc: 0.9142 - false_negatives: 303.5882 - false_positives: 428.3676 - loss: 0.3780 - precision: 0.7992 - recall: 0.8418 - true_negatives: 1995.1617 - true_positives: 1686.5588\n",
      "Epoch 303/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8312 - auc: 0.9120 - false_negatives: 308.1940 - false_positives: 421.7910 - loss: 0.3823 - precision: 0.7948 - recall: 0.8408 - true_negatives: 1967.2836 - true_positives: 1654.5074\n",
      "Epoch 303: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8312 - auc: 0.9120 - false_negatives: 312.5147 - false_positives: 428.2647 - loss: 0.3824 - precision: 0.7947 - recall: 0.8408 - true_negatives: 1995.2646 - true_positives: 1677.6323\n",
      "Epoch 304/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8228 - auc: 0.9062 - false_negatives: 337.8209 - false_positives: 427.9851 - loss: 0.3950 - precision: 0.7920 - recall: 0.8203 - true_negatives: 1961.0896 - true_positives: 1624.8806\n",
      "Epoch 304: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8228 - auc: 0.9062 - false_negatives: 342.4853 - false_positives: 434.4559 - loss: 0.3950 - precision: 0.7919 - recall: 0.8204 - true_negatives: 1989.0735 - true_positives: 1647.6617\n",
      "Epoch 305/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8363 - auc: 0.9155 - false_negatives: 290.3788 - false_positives: 414.4849 - loss: 0.3758 - precision: 0.7972 - recall: 0.8524 - true_negatives: 1939.0909 - true_positives: 1644.0454\n",
      "Epoch 305: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8362 - auc: 0.9154 - false_negatives: 298.9853 - false_positives: 427.5882 - loss: 0.3761 - precision: 0.7970 - recall: 0.8523 - true_negatives: 1995.9412 - true_positives: 1691.1617\n",
      "Epoch 306/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8336 - auc: 0.9140 - false_negatives: 308.8657 - false_positives: 413.5075 - loss: 0.3782 - precision: 0.7996 - recall: 0.8394 - true_negatives: 1975.5671 - true_positives: 1653.8358\n",
      "Epoch 306: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8336 - auc: 0.9139 - false_negatives: 313.0588 - false_positives: 419.8088 - loss: 0.3783 - precision: 0.7995 - recall: 0.8395 - true_negatives: 2003.7206 - true_positives: 1677.0883\n",
      "Epoch 307/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8365 - auc: 0.9151 - false_negatives: 311.9105 - false_positives: 407.3134 - loss: 0.3756 - precision: 0.8055 - recall: 0.8380 - true_negatives: 1981.7612 - true_positives: 1650.7910\n",
      "Epoch 307: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8364 - auc: 0.9151 - false_negatives: 316.4265 - false_positives: 413.7647 - loss: 0.3758 - precision: 0.8053 - recall: 0.8380 - true_negatives: 2009.7646 - true_positives: 1673.7206\n",
      "Epoch 308/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8294 - auc: 0.9120 - false_negatives: 311.0454 - false_positives: 425.5909 - loss: 0.3838 - precision: 0.7905 - recall: 0.8440 - true_negatives: 1927.9849 - true_positives: 1623.3788\n",
      "Epoch 308: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8292 - auc: 0.9118 - false_negatives: 320.8676 - false_positives: 438.8382 - loss: 0.3841 - precision: 0.7903 - recall: 0.8436 - true_negatives: 1984.6912 - true_positives: 1669.2794\n",
      "Epoch 309/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8358 - auc: 0.9136 - false_negatives: 300.0597 - false_positives: 423.8209 - loss: 0.3799 - precision: 0.7987 - recall: 0.8477 - true_negatives: 1965.2538 - true_positives: 1662.6418\n",
      "Epoch 309: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8357 - auc: 0.9135 - false_negatives: 304.4559 - false_positives: 430.3529 - loss: 0.3800 - precision: 0.7985 - recall: 0.8476 - true_negatives: 1993.1765 - true_positives: 1685.6912\n",
      "Epoch 310/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8318 - auc: 0.9130 - false_negatives: 317.3182 - false_positives: 399.4243 - loss: 0.3814 - precision: 0.8022 - recall: 0.8295 - true_negatives: 1954.1515 - true_positives: 1617.1061\n",
      "Epoch 310: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8318 - auc: 0.9130 - false_negatives: 326.1912 - false_positives: 411.5882 - loss: 0.3815 - precision: 0.8021 - recall: 0.8297 - true_negatives: 2011.9412 - true_positives: 1663.9559\n",
      "Epoch 311/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8394 - auc: 0.9162 - false_negatives: 282.6364 - false_positives: 410.6060 - loss: 0.3759 - precision: 0.7993 - recall: 0.8582 - true_negatives: 1942.9697 - true_positives: 1651.7878\n",
      "Epoch 311: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8393 - auc: 0.9161 - false_negatives: 291.2353 - false_positives: 423.4118 - loss: 0.3761 - precision: 0.7992 - recall: 0.8580 - true_negatives: 2000.1177 - true_positives: 1698.9117\n",
      "Epoch 312/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8297 - auc: 0.9114 - false_negatives: 333.1642 - false_positives: 406.4627 - loss: 0.3839 - precision: 0.8037 - recall: 0.8214 - true_negatives: 1982.6119 - true_positives: 1629.5374\n",
      "Epoch 312: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8297 - auc: 0.9113 - false_negatives: 337.8235 - false_positives: 412.7647 - loss: 0.3840 - precision: 0.8035 - recall: 0.8215 - true_negatives: 2010.7646 - true_positives: 1652.3235\n",
      "Epoch 313/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8283 - auc: 0.9096 - false_negatives: 301.4030 - false_positives: 448.5224 - loss: 0.3903 - precision: 0.7835 - recall: 0.8554 - true_negatives: 1940.5522 - true_positives: 1661.2985\n",
      "Epoch 313: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8282 - auc: 0.9096 - false_negatives: 305.8971 - false_positives: 455.0294 - loss: 0.3904 - precision: 0.7835 - recall: 0.8552 - true_negatives: 1968.5000 - true_positives: 1684.2500\n",
      "Epoch 314/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8267 - auc: 0.9120 - false_negatives: 319.2537 - false_positives: 425.2985 - loss: 0.3840 - precision: 0.7894 - recall: 0.8385 - true_negatives: 1963.7761 - true_positives: 1643.4478\n",
      "Epoch 314: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8267 - auc: 0.9119 - false_negatives: 323.6471 - false_positives: 431.6618 - loss: 0.3840 - precision: 0.7894 - recall: 0.8385 - true_negatives: 1991.8677 - true_positives: 1666.5000\n",
      "Epoch 315/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8319 - auc: 0.9101 - false_negatives: 312.1493 - false_positives: 423.8507 - loss: 0.3872 - precision: 0.7953 - recall: 0.8423 - true_negatives: 1965.2239 - true_positives: 1650.5522\n",
      "Epoch 315: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8318 - auc: 0.9101 - false_negatives: 316.6618 - false_positives: 430.2206 - loss: 0.3874 - precision: 0.7952 - recall: 0.8422 - true_negatives: 1993.3088 - true_positives: 1673.4854\n",
      "Epoch 316/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8321 - auc: 0.9134 - false_negatives: 300.6119 - false_positives: 433.2388 - loss: 0.3806 - precision: 0.7902 - recall: 0.8531 - true_negatives: 1955.8358 - true_positives: 1662.0896\n",
      "Epoch 316: loss did not improve from 0.38293\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8321 - auc: 0.9133 - false_negatives: 305.2353 - false_positives: 439.6471 - loss: 0.3807 - precision: 0.7901 - recall: 0.8529 - true_negatives: 1983.8823 - true_positives: 1684.9117\n",
      "Epoch 317/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8354 - auc: 0.9163 - false_negatives: 309.0757 - false_positives: 395.8182 - loss: 0.3750 - precision: 0.8036 - recall: 0.8380 - true_negatives: 1957.7576 - true_positives: 1625.3485\n",
      "Epoch 317: loss improved from 0.38293 to 0.37989, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8353 - auc: 0.9162 - false_negatives: 318.0147 - false_positives: 408.1176 - loss: 0.3751 - precision: 0.8034 - recall: 0.8380 - true_negatives: 2015.4117 - true_positives: 1672.1323\n",
      "Epoch 318/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8344 - auc: 0.9154 - false_negatives: 301.2537 - false_positives: 410.1343 - loss: 0.3756 - precision: 0.7967 - recall: 0.8477 - true_negatives: 1978.9403 - true_positives: 1661.4478\n",
      "Epoch 318: loss did not improve from 0.37989\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8344 - auc: 0.9154 - false_negatives: 305.6765 - false_positives: 416.0588 - loss: 0.3757 - precision: 0.7968 - recall: 0.8476 - true_negatives: 2007.4706 - true_positives: 1684.4706\n",
      "Epoch 319/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8359 - auc: 0.9165 - false_negatives: 298.7612 - false_positives: 408.2239 - loss: 0.3731 - precision: 0.8000 - recall: 0.8458 - true_negatives: 1980.8507 - true_positives: 1663.9403\n",
      "Epoch 319: loss did not improve from 0.37989\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8359 - auc: 0.9165 - false_negatives: 302.9265 - false_positives: 414.3971 - loss: 0.3732 - precision: 0.7999 - recall: 0.8458 - true_negatives: 2009.1323 - true_positives: 1687.2206\n",
      "Epoch 320/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8313 - auc: 0.9145 - false_negatives: 311.6866 - false_positives: 419.3433 - loss: 0.3777 - precision: 0.7950 - recall: 0.8408 - true_negatives: 1969.7313 - true_positives: 1651.0149\n",
      "Epoch 320: loss did not improve from 0.37989\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8313 - auc: 0.9145 - false_negatives: 316.2941 - false_positives: 425.3382 - loss: 0.3778 - precision: 0.7950 - recall: 0.8407 - true_negatives: 1998.1912 - true_positives: 1673.8529\n",
      "Epoch 321/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8372 - auc: 0.9181 - false_negatives: 296.6212 - false_positives: 399.8788 - loss: 0.3702 - precision: 0.8008 - recall: 0.8491 - true_negatives: 1953.6970 - true_positives: 1637.8030\n",
      "Epoch 321: loss did not improve from 0.37989\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8371 - auc: 0.9179 - false_negatives: 305.6324 - false_positives: 412.5882 - loss: 0.3706 - precision: 0.8007 - recall: 0.8489 - true_negatives: 2010.9412 - true_positives: 1684.5146\n",
      "Epoch 322/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8287 - auc: 0.9119 - false_negatives: 317.8333 - false_positives: 418.7727 - loss: 0.3826 - precision: 0.7937 - recall: 0.8355 - true_negatives: 1934.8030 - true_positives: 1616.5909\n",
      "Epoch 322: loss did not improve from 0.37989\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8286 - auc: 0.9118 - false_negatives: 326.9853 - false_positives: 431.6912 - loss: 0.3828 - precision: 0.7935 - recall: 0.8355 - true_negatives: 1991.8383 - true_positives: 1663.1617\n",
      "Epoch 323/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8353 - auc: 0.9160 - false_negatives: 297.0303 - false_positives: 395.5454 - loss: 0.3742 - precision: 0.8010 - recall: 0.8422 - true_negatives: 1958.0303 - true_positives: 1637.3939\n",
      "Epoch 323: loss improved from 0.37989 to 0.37629, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8354 - auc: 0.9159 - false_negatives: 305.2647 - false_positives: 408.0000 - loss: 0.3742 - precision: 0.8009 - recall: 0.8424 - true_negatives: 2015.5294 - true_positives: 1684.8823\n",
      "Epoch 324/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8394 - auc: 0.9222 - false_negatives: 296.4091 - false_positives: 388.6970 - loss: 0.3606 - precision: 0.8070 - recall: 0.8438 - true_negatives: 1964.8788 - true_positives: 1638.0151\n",
      "Epoch 324: loss improved from 0.37629 to 0.37132, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8394 - auc: 0.9221 - false_negatives: 304.6324 - false_positives: 400.8235 - loss: 0.3609 - precision: 0.8068 - recall: 0.8439 - true_negatives: 2022.7059 - true_positives: 1685.5146\n",
      "Epoch 325/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8271 - auc: 0.9114 - false_negatives: 308.2154 - false_positives: 402.8462 - loss: 0.3853 - precision: 0.7900 - recall: 0.8387 - true_negatives: 1915.3385 - true_positives: 1597.6000\n",
      "Epoch 325: loss did not improve from 0.37132\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8273 - auc: 0.9114 - false_negatives: 321.8824 - false_positives: 421.5588 - loss: 0.3854 - precision: 0.7902 - recall: 0.8387 - true_negatives: 2001.9706 - true_positives: 1668.2646\n",
      "Epoch 326/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8339 - auc: 0.9142 - false_negatives: 301.2154 - false_positives: 401.0000 - loss: 0.3784 - precision: 0.8018 - recall: 0.8363 - true_negatives: 1917.1846 - true_positives: 1604.6000\n",
      "Epoch 326: loss did not improve from 0.37132\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8338 - auc: 0.9140 - false_negatives: 314.4118 - false_positives: 419.9265 - loss: 0.3788 - precision: 0.8015 - recall: 0.8365 - true_negatives: 2003.6029 - true_positives: 1675.7354\n",
      "Epoch 327/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8382 - auc: 0.9180 - false_negatives: 299.1940 - false_positives: 392.3134 - loss: 0.3701 - precision: 0.8038 - recall: 0.8461 - true_negatives: 1996.7612 - true_positives: 1663.5074\n",
      "Epoch 327: loss did not improve from 0.37132\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8382 - auc: 0.9179 - false_negatives: 303.3235 - false_positives: 398.3235 - loss: 0.3703 - precision: 0.8038 - recall: 0.8461 - true_negatives: 2025.2059 - true_positives: 1686.8235\n",
      "Epoch 328/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8350 - auc: 0.9185 - false_negatives: 294.3881 - false_positives: 413.6866 - loss: 0.3695 - precision: 0.7952 - recall: 0.8521 - true_negatives: 1975.3881 - true_positives: 1668.3135\n",
      "Epoch 328: loss did not improve from 0.37132\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8350 - auc: 0.9184 - false_negatives: 298.6471 - false_positives: 419.7059 - loss: 0.3696 - precision: 0.7952 - recall: 0.8520 - true_negatives: 2003.8235 - true_positives: 1691.5000\n",
      "Epoch 329/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8399 - auc: 0.9182 - false_negatives: 286.6060 - false_positives: 398.3636 - loss: 0.3702 - precision: 0.8032 - recall: 0.8516 - true_negatives: 1955.2122 - true_positives: 1647.8182\n",
      "Epoch 329: loss did not improve from 0.37132\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8397 - auc: 0.9181 - false_negatives: 295.2353 - false_positives: 410.8824 - loss: 0.3704 - precision: 0.8030 - recall: 0.8515 - true_negatives: 2012.6471 - true_positives: 1694.9117\n",
      "Epoch 330/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8401 - auc: 0.9226 - false_negatives: 287.3333 - false_positives: 391.1970 - loss: 0.3603 - precision: 0.8038 - recall: 0.8520 - true_negatives: 1962.3788 - true_positives: 1647.0909\n",
      "Epoch 330: loss improved from 0.37132 to 0.37017, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8401 - auc: 0.9224 - false_negatives: 295.5882 - false_positives: 403.7206 - loss: 0.3606 - precision: 0.8037 - recall: 0.8520 - true_negatives: 2019.8088 - true_positives: 1694.5588\n",
      "Epoch 331/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8339 - auc: 0.9186 - false_negatives: 301.3582 - false_positives: 419.4179 - loss: 0.3681 - precision: 0.7961 - recall: 0.8467 - true_negatives: 1969.6567 - true_positives: 1661.3433\n",
      "Epoch 331: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8339 - auc: 0.9185 - false_negatives: 305.5000 - false_positives: 425.5735 - loss: 0.3682 - precision: 0.7961 - recall: 0.8467 - true_negatives: 1997.9559 - true_positives: 1684.6471\n",
      "Epoch 332/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8455 - auc: 0.9227 - false_negatives: 293.2537 - false_positives: 388.6418 - loss: 0.3599 - precision: 0.8141 - recall: 0.8495 - true_negatives: 2000.4329 - true_positives: 1669.4478\n",
      "Epoch 332: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8454 - auc: 0.9226 - false_negatives: 297.3971 - false_positives: 394.7059 - loss: 0.3601 - precision: 0.8139 - recall: 0.8495 - true_negatives: 2028.8235 - true_positives: 1692.7500\n",
      "Epoch 333/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8395 - auc: 0.9215 - false_negatives: 300.2388 - false_positives: 397.2985 - loss: 0.3620 - precision: 0.8059 - recall: 0.8459 - true_negatives: 1991.7761 - true_positives: 1662.4626\n",
      "Epoch 333: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8395 - auc: 0.9214 - false_negatives: 304.3088 - false_positives: 403.3235 - loss: 0.3622 - precision: 0.8058 - recall: 0.8460 - true_negatives: 2020.2059 - true_positives: 1685.8383\n",
      "Epoch 334/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8306 - auc: 0.9144 - false_negatives: 325.2727 - false_positives: 402.7273 - loss: 0.3767 - precision: 0.7987 - recall: 0.8317 - true_negatives: 1950.8485 - true_positives: 1609.1515\n",
      "Epoch 334: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8305 - auc: 0.9142 - false_negatives: 334.7059 - false_positives: 415.1471 - loss: 0.3771 - precision: 0.7986 - recall: 0.8317 - true_negatives: 2008.3823 - true_positives: 1655.4412\n",
      "Epoch 335/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8285 - auc: 0.9092 - false_negatives: 278.5606 - false_positives: 445.2576 - loss: 0.3907 - precision: 0.7805 - recall: 0.8610 - true_negatives: 1908.3182 - true_positives: 1655.8636\n",
      "Epoch 335: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8285 - auc: 0.9091 - false_negatives: 287.0735 - false_positives: 458.3088 - loss: 0.3907 - precision: 0.7807 - recall: 0.8607 - true_negatives: 1965.2206 - true_positives: 1703.0735\n",
      "Epoch 336/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8390 - auc: 0.9187 - false_negatives: 306.2686 - false_positives: 392.1791 - loss: 0.3688 - precision: 0.8073 - recall: 0.8422 - true_negatives: 1996.8955 - true_positives: 1656.4329\n",
      "Epoch 336: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8390 - auc: 0.9186 - false_negatives: 310.5147 - false_positives: 398.0147 - loss: 0.3688 - precision: 0.8072 - recall: 0.8422 - true_negatives: 2025.5146 - true_positives: 1679.6323\n",
      "Epoch 337/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8406 - auc: 0.9210 - false_negatives: 284.2239 - false_positives: 411.7910 - loss: 0.3638 - precision: 0.8007 - recall: 0.8587 - true_negatives: 1977.2836 - true_positives: 1678.4777\n",
      "Epoch 337: loss did not improve from 0.37017\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8405 - auc: 0.9208 - false_negatives: 288.6618 - false_positives: 417.9265 - loss: 0.3640 - precision: 0.8006 - recall: 0.8585 - true_negatives: 2005.6029 - true_positives: 1701.4854\n",
      "Epoch 338/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8453 - auc: 0.9247 - false_negatives: 281.7015 - false_positives: 396.2090 - loss: 0.3563 - precision: 0.8089 - recall: 0.8579 - true_negatives: 1992.8657 - true_positives: 1681.0000\n",
      "Epoch 338: loss improved from 0.37017 to 0.36983, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8452 - auc: 0.9246 - false_negatives: 285.8088 - false_positives: 402.1176 - loss: 0.3565 - precision: 0.8088 - recall: 0.8578 - true_negatives: 2021.4117 - true_positives: 1704.3383\n",
      "Epoch 339/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8401 - auc: 0.9230 - false_negatives: 274.7164 - false_positives: 415.1343 - loss: 0.3607 - precision: 0.7978 - recall: 0.8623 - true_negatives: 1973.9403 - true_positives: 1687.9851\n",
      "Epoch 339: loss improved from 0.36983 to 0.36883, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8400 - auc: 0.9229 - false_negatives: 278.8971 - false_positives: 421.0882 - loss: 0.3608 - precision: 0.7979 - recall: 0.8621 - true_negatives: 2002.4412 - true_positives: 1711.2500\n",
      "Epoch 340/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8343 - auc: 0.9145 - false_negatives: 300.4030 - false_positives: 410.8657 - loss: 0.3805 - precision: 0.8009 - recall: 0.8396 - true_negatives: 1978.2090 - true_positives: 1662.2985\n",
      "Epoch 340: loss did not improve from 0.36883\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8344 - auc: 0.9145 - false_negatives: 304.6618 - false_positives: 416.7500 - loss: 0.3805 - precision: 0.8008 - recall: 0.8397 - true_negatives: 2006.7794 - true_positives: 1685.4854\n",
      "Epoch 341/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8469 - auc: 0.9221 - false_negatives: 292.8209 - false_positives: 378.0149 - loss: 0.3620 - precision: 0.8200 - recall: 0.8448 - true_negatives: 2011.0597 - true_positives: 1669.8806\n",
      "Epoch 341: loss did not improve from 0.36883\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8468 - auc: 0.9220 - false_negatives: 296.8676 - false_positives: 383.7059 - loss: 0.3621 - precision: 0.8198 - recall: 0.8449 - true_negatives: 2039.8235 - true_positives: 1693.2794\n",
      "Epoch 342/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8407 - auc: 0.9202 - false_negatives: 277.8657 - false_positives: 416.0895 - loss: 0.3657 - precision: 0.8009 - recall: 0.8582 - true_negatives: 1972.9851 - true_positives: 1684.8358\n",
      "Epoch 342: loss did not improve from 0.36883\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8407 - auc: 0.9201 - false_negatives: 281.7647 - false_positives: 422.2794 - loss: 0.3658 - precision: 0.8009 - recall: 0.8582 - true_negatives: 2001.2500 - true_positives: 1708.3823\n",
      "Epoch 343/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8425 - auc: 0.9252 - false_negatives: 280.6716 - false_positives: 398.4328 - loss: 0.3542 - precision: 0.8059 - recall: 0.8546 - true_negatives: 1990.6418 - true_positives: 1682.0299\n",
      "Epoch 343: loss improved from 0.36883 to 0.36429, saving model to resultsESF/lstm_time_series/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8425 - auc: 0.9251 - false_negatives: 284.7059 - false_positives: 404.3676 - loss: 0.3543 - precision: 0.8059 - recall: 0.8546 - true_negatives: 2019.1617 - true_positives: 1705.4412\n",
      "Epoch 344/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8434 - auc: 0.9229 - false_negatives: 286.0895 - false_positives: 394.0597 - loss: 0.3603 - precision: 0.8115 - recall: 0.8476 - true_negatives: 1995.0149 - true_positives: 1676.6119\n",
      "Epoch 344: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8433 - auc: 0.9229 - false_negatives: 290.1912 - false_positives: 399.9412 - loss: 0.3604 - precision: 0.8114 - recall: 0.8476 - true_negatives: 2023.5883 - true_positives: 1699.9559\n",
      "Epoch 345/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8415 - auc: 0.9222 - false_negatives: 295.5224 - false_positives: 394.0448 - loss: 0.3607 - precision: 0.8087 - recall: 0.8472 - true_negatives: 1995.0299 - true_positives: 1667.1791\n",
      "Epoch 345: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8415 - auc: 0.9222 - false_negatives: 299.4706 - false_positives: 400.2500 - loss: 0.3609 - precision: 0.8086 - recall: 0.8473 - true_negatives: 2023.2794 - true_positives: 1690.6765\n",
      "Epoch 346/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8404 - auc: 0.9217 - false_negatives: 294.6970 - false_positives: 383.5757 - loss: 0.3625 - precision: 0.8068 - recall: 0.8473 - true_negatives: 1970.0000 - true_positives: 1639.7273\n",
      "Epoch 346: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8404 - auc: 0.9216 - false_negatives: 303.2353 - false_positives: 395.3824 - loss: 0.3627 - precision: 0.8067 - recall: 0.8473 - true_negatives: 2028.1471 - true_positives: 1686.9117\n",
      "Epoch 347/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8348 - auc: 0.9165 - false_negatives: 299.0298 - false_positives: 410.3881 - loss: 0.3744 - precision: 0.7956 - recall: 0.8513 - true_negatives: 1978.6865 - true_positives: 1663.6716\n",
      "Epoch 347: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8348 - auc: 0.9165 - false_negatives: 303.3088 - false_positives: 416.3088 - loss: 0.3745 - precision: 0.7956 - recall: 0.8512 - true_negatives: 2007.2206 - true_positives: 1686.8383\n",
      "Epoch 348/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8375 - auc: 0.9193 - false_negatives: 290.1818 - false_positives: 404.0303 - loss: 0.3672 - precision: 0.8009 - recall: 0.8492 - true_negatives: 1949.5454 - true_positives: 1644.2424\n",
      "Epoch 348: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8375 - auc: 0.9192 - false_negatives: 298.9412 - false_positives: 415.8235 - loss: 0.3674 - precision: 0.8009 - recall: 0.8491 - true_negatives: 2007.7059 - true_positives: 1691.2059\n",
      "Epoch 349/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8360 - auc: 0.9172 - false_negatives: 309.1940 - false_positives: 399.4328 - loss: 0.3730 - precision: 0.8098 - recall: 0.8291 - true_negatives: 1989.6418 - true_positives: 1653.5074\n",
      "Epoch 349: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8359 - auc: 0.9172 - false_negatives: 313.4706 - false_positives: 405.5735 - loss: 0.3731 - precision: 0.8097 - recall: 0.8293 - true_negatives: 2017.9559 - true_positives: 1676.6765\n",
      "Epoch 350/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8439 - auc: 0.9172 - false_negatives: 292.0757 - false_positives: 373.9243 - loss: 0.3730 - precision: 0.8175 - recall: 0.8395 - true_negatives: 1979.6515 - true_positives: 1642.3485\n",
      "Epoch 350: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8439 - auc: 0.9171 - false_negatives: 300.1912 - false_positives: 385.7206 - loss: 0.3730 - precision: 0.8172 - recall: 0.8399 - true_negatives: 2037.8088 - true_positives: 1689.9559\n",
      "Epoch 351/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8423 - auc: 0.9193 - false_negatives: 278.9552 - false_positives: 415.9851 - loss: 0.3678 - precision: 0.7998 - recall: 0.8657 - true_negatives: 1973.0896 - true_positives: 1683.7462\n",
      "Epoch 351: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8422 - auc: 0.9193 - false_negatives: 283.3235 - false_positives: 422.0588 - loss: 0.3679 - precision: 0.7998 - recall: 0.8655 - true_negatives: 2001.4706 - true_positives: 1706.8235\n",
      "Epoch 352/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8369 - auc: 0.9153 - false_negatives: 316.8507 - false_positives: 401.9403 - loss: 0.3756 - precision: 0.8085 - recall: 0.8341 - true_negatives: 1987.1343 - true_positives: 1645.8507\n",
      "Epoch 352: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8368 - auc: 0.9152 - false_negatives: 321.4853 - false_positives: 407.9412 - loss: 0.3758 - precision: 0.8083 - recall: 0.8341 - true_negatives: 2015.5883 - true_positives: 1668.6617\n",
      "Epoch 353/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8367 - auc: 0.9199 - false_negatives: 311.3433 - false_positives: 394.5672 - loss: 0.3662 - precision: 0.8073 - recall: 0.8349 - true_negatives: 1994.5074 - true_positives: 1651.3582\n",
      "Epoch 353: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8367 - auc: 0.9198 - false_negatives: 315.6029 - false_positives: 400.4853 - loss: 0.3663 - precision: 0.8073 - recall: 0.8350 - true_negatives: 2023.0441 - true_positives: 1674.5441\n",
      "Epoch 354/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8396 - auc: 0.9181 - false_negatives: 293.7910 - false_positives: 407.1642 - loss: 0.3699 - precision: 0.8060 - recall: 0.8461 - true_negatives: 1981.9104 - true_positives: 1668.9104\n",
      "Epoch 354: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8395 - auc: 0.9181 - false_negatives: 297.8088 - false_positives: 413.2059 - loss: 0.3700 - precision: 0.8059 - recall: 0.8462 - true_negatives: 2010.3235 - true_positives: 1692.3383\n",
      "Epoch 355/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8353 - auc: 0.9156 - false_negatives: 310.3182 - false_positives: 399.5000 - loss: 0.3762 - precision: 0.8085 - recall: 0.8304 - true_negatives: 1954.0758 - true_positives: 1624.1061\n",
      "Epoch 355: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8353 - auc: 0.9155 - false_negatives: 318.6912 - false_positives: 411.7794 - loss: 0.3763 - precision: 0.8082 - recall: 0.8309 - true_negatives: 2011.7500 - true_positives: 1671.4559\n",
      "Epoch 356/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8399 - auc: 0.9152 - false_negatives: 320.1045 - false_positives: 376.6269 - loss: 0.3771 - precision: 0.8190 - recall: 0.8262 - true_negatives: 2012.4478 - true_positives: 1642.5970\n",
      "Epoch 356: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8398 - auc: 0.9152 - false_negatives: 324.4706 - false_positives: 382.5294 - loss: 0.3771 - precision: 0.8188 - recall: 0.8263 - true_negatives: 2041.0000 - true_positives: 1665.6765\n",
      "Epoch 357/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8297 - auc: 0.9142 - false_negatives: 313.2090 - false_positives: 420.5970 - loss: 0.3768 - precision: 0.7934 - recall: 0.8384 - true_negatives: 1968.4777 - true_positives: 1649.4926\n",
      "Epoch 357: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8297 - auc: 0.9142 - false_negatives: 317.8235 - false_positives: 426.6029 - loss: 0.3769 - precision: 0.7934 - recall: 0.8384 - true_negatives: 1996.9265 - true_positives: 1672.3235\n",
      "Epoch 358/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8340 - auc: 0.9138 - false_negatives: 312.0149 - false_positives: 411.6418 - loss: 0.3787 - precision: 0.8029 - recall: 0.8346 - true_negatives: 1977.4329 - true_positives: 1650.6865\n",
      "Epoch 358: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8340 - auc: 0.9137 - false_negatives: 316.3971 - false_positives: 418.1029 - loss: 0.3788 - precision: 0.8028 - recall: 0.8347 - true_negatives: 2005.4265 - true_positives: 1673.7500\n",
      "Epoch 359/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8322 - auc: 0.9120 - false_negatives: 314.1493 - false_positives: 406.6119 - loss: 0.3831 - precision: 0.8082 - recall: 0.8212 - true_negatives: 1982.4626 - true_positives: 1648.5522\n",
      "Epoch 359: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8322 - auc: 0.9120 - false_negatives: 318.1324 - false_positives: 413.0000 - loss: 0.3831 - precision: 0.8080 - recall: 0.8216 - true_negatives: 2010.5294 - true_positives: 1672.0146\n",
      "Epoch 360/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8321 - auc: 0.9137 - false_negatives: 330.3030 - false_positives: 385.9546 - loss: 0.3838 - precision: 0.8167 - recall: 0.8091 - true_negatives: 1967.6212 - true_positives: 1604.1212\n",
      "Epoch 360: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8320 - auc: 0.9135 - false_negatives: 339.0882 - false_positives: 399.0147 - loss: 0.3840 - precision: 0.8160 - recall: 0.8099 - true_negatives: 2024.5146 - true_positives: 1651.0588\n",
      "Epoch 361/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8386 - auc: 0.9186 - false_negatives: 308.7463 - false_positives: 395.3881 - loss: 0.3683 - precision: 0.8088 - recall: 0.8383 - true_negatives: 1993.6865 - true_positives: 1653.9552\n",
      "Epoch 361: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8385 - auc: 0.9185 - false_negatives: 313.0294 - false_positives: 401.5735 - loss: 0.3685 - precision: 0.8087 - recall: 0.8383 - true_negatives: 2021.9559 - true_positives: 1677.1177\n",
      "Epoch 362/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8326 - auc: 0.9090 - false_negatives: 304.6269 - false_positives: 417.9403 - loss: 0.3915 - precision: 0.7985 - recall: 0.8384 - true_negatives: 1971.1343 - true_positives: 1658.0746\n",
      "Epoch 362: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8326 - auc: 0.9090 - false_negatives: 308.8971 - false_positives: 424.1471 - loss: 0.3915 - precision: 0.7984 - recall: 0.8385 - true_negatives: 1999.3823 - true_positives: 1681.2500\n",
      "Epoch 363/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8393 - auc: 0.9227 - false_negatives: 259.0303 - false_positives: 434.3030 - loss: 0.3625 - precision: 0.7905 - recall: 0.8753 - true_negatives: 1919.2727 - true_positives: 1675.3939\n",
      "Epoch 363: loss did not improve from 0.36429\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8391 - auc: 0.9224 - false_negatives: 267.4706 - false_positives: 447.7647 - loss: 0.3631 - precision: 0.7904 - recall: 0.8748 - true_negatives: 1975.7646 - true_positives: 1722.6765\n",
      "Epoch 363: early stopping\n",
      "Restoring model weights from the end of the best epoch: 343.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x278a59c11f0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting\n",
    "model.fit(g,\n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          callbacks=my_callbacks, \n",
    "          shuffle=False,\n",
    "          class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee2d1045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b38a088ca65ed389\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b38a088ca65ed389\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6001;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir ./tensorboard/ESFlogs --port=6001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab6d369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions \n",
    "# ypred = model.predict(g_, verbose=False) \n",
    "\n",
    "ypred = np.where(model.predict(g_, verbose=False) > 0.5, 1, 0)\n",
    "ypred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a860af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predictions\n",
    "df1 = df.Close[-(len(Xtest)-seqlen):]\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize=(20,10))\n",
    "fig.suptitle('Test data with signals', size=18)\n",
    "axs[0].plot(df1.index, df1)\n",
    "axs[1].plot(df1.index, ypred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c2153dd-4f58-451e-8518-8decfca03175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ LSTM1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ LSTM1 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)              │           \u001b[38;5;34m7,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM2 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │           \u001b[38;5;34m1,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Drouput2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ LSTM3 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m840\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,013</span> (39.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,013\u001b[0m (39.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,011</span> (39.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,011\u001b[0m (39.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_metrics, 74.21%\n"
     ]
    }
   ],
   "source": [
    "# load model - os.path.abspath(model_path)\n",
    "model = load_model(results_path / 'model.h5')\n",
    "\n",
    "# summarize model\n",
    "model.summary()\n",
    "\n",
    "# evaluate the model\n",
    "score = model.evaluate(g_, verbose=0)\n",
    "print(f'{model.metrics_names[1]}, {score[1]*100:.4}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b6218-3a7c-4845-ae2a-1024d1812958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
